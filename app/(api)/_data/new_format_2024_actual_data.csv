Project Title,Table Number,Submission Url,Project Status,Judging Status,Highest Step Completed,Project Created At,About The Project,"""Try it out"" Links",Video Demo Link,Opt-In Prizes,Built With,Submitter First Name,Submitter Last Name,Submitter Email,Notes,Track #1 (Primary Track),Track #2,Track #3,Team Colleges/Universities,Additional Team Member Count,Team Member 1 First Name,Team Member 1 Last Name,Team Member 1 Email
DCM Donation List,19,https://hackdavis-2024.devpost.com/submissions/510793-dcm-donation-list,Submitted (Gallery/Visible),Pending,Submit,04/27/2024 17:06:57,"Inspiration

TBA

What it does

We populate a database with the current inventory which contains the item name, the current amount, and an overall goal amount for a later implementation for a priority system 

How we built it

First we split up into designated tasks which included Figma design, backend, and frontend.
We then used MongoDB to create the backend database which we made CRUD routes to connect to the front end for the site to display the items and their respective priority with their current account. 

Challenges we ran into

TYPE errors,
CSS and HTML styling,
Being new to frontend

Accomplishments that we're proud of

Set up the backend along with their CRUD route and was able to be displayed on the screen

What we learned

Frontend development takes a lot of patience ... 

What's next for DCM Donation List

Ironing out the priority system, and creating Hi-fi version of the frontend
","https://github.com/Rani-Codes/HackDavis24, https://www.figma.com/file/DxpK3wg9J1xmLnxLzVK0um/Prototyping-in-Figma?type=design&node-id=0%3A1&mode=design&t=3yificzNeCqDxrmt-1",,"Best Beginner Hack, Best Hack for DCMH","next, react, express.js, typescript, javascript, mongodb, figma",Rani,Saro,pro4saro@gmail.com,,Best Hack for DCMH,Best Beginner Hack,Most Technically Challenging Hack,University of California - Davis,3,Greg,Chang,chang.j.gregory@gmail.com
FitnessTracker,106,https://hackdavis-2024.devpost.com/submissions/510794-fitnesstracker,Submitted (Gallery/Visible),Pending,Submit,04/27/2024 17:08:27,"Inspiration

We love working out so we decided to create this program to help other people!

What it does

This program recommends personal workouts

How we built it

We used Java and PApplet graphical user interface.

Challenges we ran into

We are not experienced programmers so we had lots of trouble getting started.

Accomplishments that we're proud of

We are proud of making something.

What we learned

We learned that there is much more to learn!

What's next for FitnessTracker

We will be working on this project as we continue to improve!
",http://github.com/AvinRai/Suru/,https://youtu.be/Gh6SxUgBA4I,Best Beginner Hack,"javascript, react, java",Avin,Rai,avinrai7@gmail.com,,Best Beginner Hack,Best Health Hack,Best Hack for Social Justice,"De Anza College, University of Michigan - Ann Arbor, San Jose State University, University of California - Davis",3,jadenho10,Ho,jaden.ho@gmail.com
AggieShift,62,https://hackdavis-2024.devpost.com/submissions/510803-aggieshift,Submitted (Gallery/Visible),Pending,Submit,04/27/2024 17:23:00,"About the Project: AggieShift

Inspiration

The inspiration behind AggieShift stemmed from the need to streamline the volunteer management process at Aggie House, a non-profit organization. We wanted to provide a convenient solution for volunteers to clock in and out seamlessly, while also offering administrators real-time insights into volunteer activities.

What We Learned

Throughout the development of AggieShift, we gained invaluable experience in integrating various technologies to create a dynamic web application. From React for frontend interactivity to Tailwind CSS for responsive design, each component added to our understanding of modern web development practices.

How We Built It

We meticulously crafted AggieShift to cater to both web and mobile screen sizes, ensuring accessibility across devices. The frontend was built using React, HTML, CSS, and Tailwind CSS, allowing for a dynamic and visually appealing user interface. For the backend, we employed MongoDB and Mongoose to handle user authentication, data storage, and real-time updates.

Challenges Faced

One of the main hurdles we encountered during the development of AggieShift was the seamless access and transmission of information between the frontend and backend systems. Specifically, we faced challenges with retrieving user clock-in and clock-out data from the frontend and accurately sending it to the database for storage and processing.

The complexity arose from ensuring that user actions on the frontend interface were promptly captured and transmitted to the backend server without delays or data loss. We had to devise efficient mechanisms for handling asynchronous data flow and implementing error handling procedures to address any unforeseen issues during transmission.

Additionally, ensuring the security and integrity of the transmitted data posed a significant challenge. We implemented stringent data validation and encryption protocols to safeguard sensitive information and prevent unauthorized access or tampering.

Despite these challenges, our team persevered through rigorous testing and iterative improvements to overcome these obstacles. Through collaboration and innovation, we successfully implemented robust solutions to streamline the information access and transmission process, ultimately enhancing the reliability and performance of AggieShift.

What's Next

Looking ahead, we have ambitious plans to further enhance AggieShift's functionality and user experience. One of our primary goals is to implement notifications for volunteers, allowing them to receive alerts for upcoming volunteer shifts and events. This feature will ensure better engagement and participation among volunteers, ultimately benefiting Aggie House's mission. We aim to introduce a feature on the admin page where administrators can view who is currently clocked in. This enhancement will provide administrators with real-time insights into volunteer activities, facilitating better management and coordination of resources.
",https://github.com/harshitjaglan/HackDavis2024,,"Best Interdisciplinary Hack, Best Hack for AggieHouse","react, mongodb, html, tailwind, css, javascript",Shuhaib,Walahi,sharkjaws1234@gmail.com,,Best Hack for AggieHouse,Best Overall Design,Best Interdisciplinary Hack,"Ohlone College, University of California - Davis, California State University - East Bay",3,Alison,Rader,amrader@ucdavis.edu
Touch Grass Discord Bot,23,https://hackdavis-2024.devpost.com/submissions/510809-touch-grass-discord-bot,Submitted (Gallery/Visible),Pending,Submit,04/27/2024 17:47:02,"Inspiration

We know that Discord users often play games or other sedentary activities for long stretches of time, so this Discord bot provides a way to tell Discord users to take breaks at regular intervals, hopefully improving health and overall quality of life. 

What it does

This bot allows users to set a timer that will alert them to take a break at a certain interval. It also provides a habit tracking functionality. 

How we built it

We used Replit as the IDE, as it allowed us to work collaboratively without having to set up the dependencies on our local machines. We used Python and the library discord.py to build the bot and interface with Discord. 

Challenges we ran into

Neither of us had built a Discord bot before, so there was a learning curve to using the library and getting things to work. 

Accomplishments that we're proud of

We are proud to have made a functioning Discord bot despite our lack of prior experience.

What we learned

We gained experience with writing a Discord bot using discord.py and with asynchronous functions in Python. 

What's next for Touch Grass Discord Bot

We can implement more advanced functionality, like making custom habit to track.
",https://github.com/erin-le/hackdavis-2024/tree/main,,"Best Health Hack, Most Creative Hack, Best User Research","python, discord.js",Erin (Jianghua),Le,jianghuale@gmail.com,,Best Health Hack,Best User Research,Most Creative Hack,University of California - Davis,1,Sophia,Tzonev,sophiasvilen2@gmail.com
HAMM,154,https://hackdavis-2024.devpost.com/submissions/510835-hamm,Submitted (Gallery/Visible),Pending,Submit,04/27/2024 18:37:47,"Inspiration ü©∫üíª

Healthcare disparities have been a prolonged issue such that underserved/minority populations are not able to get equal healthcare access. Some social determinants that prevent patients from getting quality treatments are language barriers, economic status, insurance status, education levels, transportation, etc. Based on these factors, we think language barriers are one of the leading factors in health disparities. By implementing various tech stacks and an AI model we envision our project to be able to annotate language in real-time, and schedule reoccurring notifications or text alerts for ongoing medication treatments or follow-up appointments (for lab results and regular clinic visits) due to varying circumstances. In return, this enables doctors to treat their patients accordingly without a need to converse in another language and increase efficiency with healthcare management. 

What is üçñHAMMüçñ?

HAMM is a website that acts as a medical scribe and translator to minimize the language barriers and second brain for doctors and patients. By having a scribe tool that can take notes automatically after the input of audio, we implement text alerts functions for those that ‚Äúfollow-up appointments‚Äù or ‚Äúmedication refills‚Äù are mentioned during the meetings.
HAMM works as:


A Medical Scribe: take notes on the meeting.
A Translator: translate notes into different languages that fit the preferences of the patients.
An EMR (electrical medical record): stores the generated notes for admins and patients to review afterwards.
A Case Manager: Keep track and send text alerts to patients that need follow-up appointments and medication refills.


How we built it üë®üèª‚Äçüíª üë©üèª‚Äçüíª

Technologies that was used: 

Frontend: TypeScript, Next.js, React, Tailwind CSS, shadcn/ui, and Drizzle ORM.
Backend: Python, FastAPI, Deepgram, Twilio, OpenAI, and Upstash QStash. 


We also used SQLite (Turso) and PropelAuth on both the frontend and the backend.


Challenges we ran into ‚ùå

The major challenge that we ran into was the scale of the project, we needed to narrow down the scale because of the time limits of 24 hours and funding. There were functionalities that we wanted to do but were limited because of the time and funding issues, such as Zoom API and Twilio two-way communications.

Accomplishments that we're proud of üëç


Implemented and fine-tuned a model, benefiting underserved communities and advocating for populations that experience healthcare disparities. 
Bridged the gap between AI and healthcare management systems, making huge improvements in healthcare management workflow efficiency.


What we learned  üìö

One technical thing that we learned throughout this hackathon is the Zoom API. Starting off, we wanted to use the Zoom API to create plugins on the Zoom App Marketplace so that we could further manipulate the audio file to our objective. While we managed to login to Zoom from our hackathon website,  we were unable to further get the recordings from Zoom as it requires a payment plan. Through this technical experience, we learned how to configure the Zoom API for login purposes. 

Another thing that we learned throughout this hackathon is how to acknowledge everyone's strengths and weaknesses. Throughout this hackathon, we've gained insight into the importance of recognizing both strengths and weaknesses within our team. Comprised of individuals from diverse disciplines, we've discovered the connections between different fields and the vital role communication plays in driving substantial societal advancements.

What's next for üçñHAMMüçñ?

The next challenge that we would like to accomplish is to generate translations and notes during live meetings via zoom API, and be able to let patients connect to our medical AI that can answer their general questions.
","https://github.com/maxxfuu/HAMM, https://hammsandwich.tech/",,"Best Interdisciplinary Hack, Best Health Hack, Best AI/ML Hack, Best Use of PropelAuth","python, deepgram, next.js, react, sqlite, turso, tailwindcss, propelauth, shadcn-ui, drizzle-orm, twilio",Monica,Chao,pycmonica@gmail.com,,Best Interdisciplinary Hack,Best Use of PropelAuth,Best Health Hack,"University of California - Davis, University of California - Merced, UC Merced",3,Andre,Lew,me@aelew.com
affirmi,65,https://hackdavis-2024.devpost.com/submissions/510843-affirmi,Submitted (Gallery/Visible),Pending,Submit,04/27/2024 18:47:50,"Inspiration

As students, we understand the challenges and pressures that come with pursuing a higher education. From academic stress, to social pressures and personal responsibilities, the journey through college can often feel overwhelming. These moments of stress highlight the lack of mental health support within academia. Mental health issues affect more than the individuals,  impacting academic performance, relationships, and overall quality of life. Driven by a desire to support those in need and promote mental well being on a larger scale, affirmi aims to lessen mental pressures by actively listening and supporting users through AI-generated affirmations. 

What it does

Affirmi has journaling, personalized advice, and mood tracking features that nurture the mental well-being of students, creating a safe space where students can find encouragement, and support on their mental health journey. 

How we built it

We first wireframe Affirmi using Figma. The frontend is built with React.js and CSS to create a user-friendly interface. The backend uses Node.js to handle OpenAI API requests and data management. More specifically, we used OpenAI‚Äôs chat completions API to parse users‚Äô input about their feelings and return a model generated message with affirmations and advice. Firebase Realtime Database is integrated to authenticate users and enable real-time data synchronization and storage of mood logs. To incorporate aspects of IoT and immerse the user into the application, we utilized the beginner Grove Arduino Kit to read the duration of light exposure the user experiences, as well as trained a model on Google‚Äôs Teachable Machine to detect noises of distress coming from the user.

Challenges we ran into

One of the primary challenges we faced was implementing the chatbot feature using the OpenAI API. As it was our first time working with AI technology and integrating an external API, we encountered difficulties in understanding the API documentation and configuring the chatbot to provide relevant and helpful responses. Additionally, we also struggled in maintaining consistency with our initial Figma model. With the hardware, we ran out of time connecting it to our application. With the model, we ran into a server-side error that inhibited the usage of the model.

Accomplishments that we're proud of

Despite the challenges, we successfully achieved several milestones that we're proud of. Firstly, we implemented a robust user authentication system, ensuring secure access to affirmi's features through email and password verification. Furthermore, we successfully obtained our DotTech domain name. Our greatest accomplishment was integrating the OpenAI API to develop the chatbot feature, allowing us to provide personalized feedback and affirmations to users, enhancing the overall user experience. This hackathon was a great method of exposure to many fields and technologies in CS. We may not have been able to complete the app fully, but we were able to grow and experiment with new tools.

What we learned

Our journey with affirmi provided us with invaluable learning experiences. Working with AI technology for the first time deepened our understanding of its potential applications and challenges. We gained proficiency in integrating external APIs into web applications, honing our skills in documentation interpretation and API utilization. Furthermore, navigating the complexities of user authentication and real-time data synchronization broadened our knowledge of backend development and database management. We were able to work with hardware and learning models to make our app more engaging and accessible.

What's next for affirmi

In the future, we aim to refine affirmibot's capabilities with specific instructions to specialize its interactions for diverse user needs and preferences. We would also like to expand affirmi's capabilities to store and remember user's data and information from previous responses to better personalize the user's experience. With the mission of making affirmi interactive, we plan to further train and implement the sound detection system, collecting user data to predict trends of distress. With this, we hope to send a notification at those points of the day to lighten their mood. In addition, our rudimentary hardware can be scaled to a larger ecosystem, providing the user with ambient lighting and detecting user habits to make them more aware of possible life improvements.
",,https://youtu.be/mQbFNIwgOaI,"Best Health Hack, Best UI/UX Prototyping, Best User Research, Best Use of .Tech Domain Name, Best Interactive Media Hack","firebase, openai, react-native, javascript, css, html, arduino",Jimmy,Vu,jimmyvu1357@gmail.com,,Best Use of .Tech Domain Name,Best User Research,Best Health Hack,San Jose State University,3,Natalie,Kao,natkao3011@gmail.com
FindRPet,57,https://hackdavis-2024.devpost.com/submissions/510844-findrpet,Submitted (Gallery/Visible),Pending,Submit,04/27/2024 18:51:03,"Inspiration

The motivation behind building this website was a love for pets and animals. Everyday, hundreds of cats and dogs, young and old, healthy and disabled, become euthanized because local shelters don't have the capacity to sustain so many creatures. Thus, we wanted to provide different means for everyone to save the lives of animals in their local community.

What it does

There are three features our app accomplishes: Find, Feed, and Adopt. Finding allows pet owners to locate their lost pets by posting an alert to the site and allowing other users to contact the owner. Feed allows the local community to pitch in and help out stray animals in their area. Finally, adopt allows users to browse through animals living in local shelters, making it easy and convenient to adopt a pet.

How we built it

We used Django, a Python web-framework, as our server for the website and primarily used Tailwind CSS, HTML, JS for our UI/UX. To save the user data, missing pet posts, and location coordinates, we used a PostgreSQL database and deployed the site to production using Heroku. Additionally, we integrated Google's Geolocation and Autocomplete API for our Feed Feature.

Challenges we ran into

Embedding the Google Map API. Specifically getting the marker to indicate the user's location and having the set locations display the pop up description. 

Accomplishments that we're proud of

Initially, we only thought we could do one of these features in the time frame given, but we wanted to go for more complexity and challenge our time management and programming skills. Additionally, the Google Maps integration was a highlight for our project: not only for its difficulty but also because we think it can genuinely improve the living conditions of stray animals in our community. 

What we learned

How to use the Google Maps API for the location tracking and Tailwind CSS for our design instead of Bootstrap. In terms of project timeline, we learned how to work within a constricted time period and to not pull all-nighters without coffee :)

What's next for FindRPet

Making UI/UX a little more interactive and making it have a more international reach - currently the API calls only work within the US. 
","https://findrpet-396758554580.herokuapp.com/, HTTPS://github.com/boyuan12/findrpet, http://findrpet.tech",,"Best Use of .Tech Domain Name, Best Use of TinyMCE, Best Interactive Media Hack, Best Hack for Life of Kai","python, django, google-geocoding, google-autocomplete, tinymce, postgresql, .tech, tailwind",Logan,Wong,j007wo2@gmail.com,,Best Hack for Life of Kai,Best Hack for Social Justice,Best Use of .Tech Domain Name,Pleasant Grove High school,1,boyuan12,Liu,boyuanliu6@yahoo.com
Sum,150,https://hackdavis-2024.devpost.com/submissions/510848-sum,Submitted (Gallery/Visible),Pending,Submit,04/27/2024 19:02:00,"Inspiration

We both volunteered in the past for community organizations that help the homeless get food, showers, and toiletries. What we noticed was that a lot of the food would go to waste because there would either too much or the client would be particular about their food, and people would often not know of the resources around them in regards to shelters, showers, or food. We also noticed that a lot of the homeless would have access to smartphones or computers during the day, so we thought that if they had a common portal outlining the resources around them, then they would be less ostracized from society since they would have access to the basic needs that the housed do. We were also inspired by the problems statements of DCMH and AggieHouse and realized to better serve the homeless, the clients, organizations, and case workers have to be on the same page. Sum in Latin means ""to be"", so we felt that the homeless would feel human again knowing that they have access to those resources. Sum also sounds like the Cantonese word for ""heart"", representing the heart of these organizations and case workers to help the homeless.

What it does

Sum provides a common portal for case workers, community organizations, and clients to keep track of the essentials that the clients need, the supplies that the organizations need to support them, and the progress of each case worker's clients. Each client can either pull up their profile on their phone or have a printed badge with unique, AI generate artwork of their choice and a QR code. They can also select their needs for that particular day and have it sent to a nearby organization for fulfillment. Volunteers at those organizations can then scan the client's QR code to update their inventory of supply and verify the client's request. Clients also can schedule appointments with their case worker, for showers, or for regular checkups. Case workers can keep digitized notes on each client and track their progress.

How we built it

We built this site with a JavaScript frontend and Django backend. We also integrated PropelAuth for user verification and liked the ability to assign roles to each member in the organization, which would work well with giving clients, volunteers, and case workers their own view of the application.

Challenges we ran into

The Django/Python implementation for PropelAuth was relatively recent, so there was very little documentation on it from other users. Also, since we are both beginners, and since we are working in a team of 2, we definitely bit off more than we can chew in regards to the site functionality.

Accomplishments that we're proud of

We are proud of participating in our first hackathon, and although it was exhausting and stressful at times, we were able to make something that works somewhat and were able to make a good looking concept.

What we learned

We learned a lot about the pipeline for building an app, especially one on extremely short notice. We also learned to keep trying even if we're new and even if the prospect of making a somewhat functioning app was incredibly daunting.

What's next for Sum

Fleshing out the rest of the site is definitely a need, as well as developing both an Android and iOS version of the app. Since most homeless individuals have cheaper Android phones, the Android implementation is more pressing than the iOS one.
",https://github.com/weng4913/sum,,"Best Beginner Hack, Best User Research, Best Use of PropelAuth","python, django, javascript, html5, css3, adobe-illustrator, figma, bootstrap",William,Eng,weng4913@gmail.com,,Best Use of PropelAuth,Best User Research,Best Beginner Hack,,1,kayana,leung,kayanasueleung@gmail.com
Neosurf,,,Draft,Pending,Project overview,04/27/2024 19:04:55,,,,,,raccoonhands1,Cruse,reptile12456@gmail.com,,,,Best UI/UX Design,De Anza College,2,Elijah,,elijah0904@gmail.com
FitMe,114,https://hackdavis-2024.devpost.com/submissions/510852-fitme,Submitted (Gallery/Visible),Pending,Submit,04/27/2024 19:17:27,"Inspiration

The inspiration behind FitMe stems from recognizing the financial and practical barriers individuals face in accessing quality fitness coaching and guidance. Through personal experiences and observing others, we've noticed many people investing significant amounts in personal training sessions, gym memberships, equipment, and supplements, only to find themselves frustrated by the lack of results. We believe that the root of this problem lies not in the resources individuals have access to, but rather in the way they approach their training.

FitMe aims to break down these barriers by providing comprehensive coaching and support, free of charge. Our motivation is to democratize fitness knowledge and empower individuals to achieve their goals without financial constraints. By leveraging technology, we're able to offer personalized advice and guidance based on user input, ensuring that everyone, regardless of their budget or experience level, can access expert training recommendations. From providing tips on proper exercise form to suggesting instructional videos, FitMe is dedicated to helping users optimize their workouts and maximize their results.

What it does

Serving as your virtual gym companion, FitMe aims to break down the barriers between proper fitness knowledge and accessibility by offering personalized workout plans, real-time feedback, exercise demonstrations, and expert guidance to optimize your fitness journey. Whether you're a beginner or a seasoned gym-goer, FitMe uses AI to ensure effective and enjoyable workouts tailored to your goals and needs.

How we built it

We set up our app using Next.js. This project uses Javascript.

What we learned

Since this was our first hackathon, we learned a lot about working on projects as a team and how to navigate through the challenges of building something significant.

What's next for FitMe

We hope to add more features that allow the user to customize their experience with the bot and expand its knowledge.
",,,,"npm, node.js, next.js",emerald,trinh,emeraldtrinh05@gmail.com,,Best Beginner Hack,Best Health Hack,Best Hack for Social Justice,University of California - Santa Cruz,1,Vincent,Ngo,ngovincent9593@gmail.com
Safe Drive AI,15,https://hackdavis-2024.devpost.com/submissions/510859-safe-drive-ai,Submitted (Gallery/Visible),Pending,Submit,04/27/2024 19:32:28,"HackDavis 2024

Our Github

Mission: Reduce car related injuries and deaths

Use OpenCV, PyTorch, and Intel Developer Cloud to create and optimize Lane Detection, Driver Alertness Detection, Blind Spot Monitoring, and Proximity Sensing to make the cars on the road safer.

Our project for https://hackdavis.io/event 2024.

Parts of the whole system

Lane Detection

Use a forward facing camera and OpenCV to recognize lanes and alert the driver if they do not stay within their lane.

Driver Alertness Detection

Use a driver facing camera and OpenCV to detect if the driver is awake and paying attention to the road

Blind Spot Detection

Use PyTorch and Intel Developer Cloud Notebook to detect pedestrians walking infront and next to the car and alert the driver if they get too close. We were able to use Intel's ipex, PyTorch plugin, and bfloat16 to reduce the training time by 4 entire minutes. We used ipex from Intel AI and the Intel PyTorch plugin to leverage Intel AMX.

ipex example usage
import torch
import intel_extension_for_pytorch as ipex
from engine import train_one_epoch, evaluate
import datetime

# ...

params = [p for p in model.parameters() if p.requires_grad]
optimizer = torch.optim.SGD(
    params,
    lr=0.005,
    momentum=0.9,
    weight_decay=0.0005
)

lr_scheduler = torch.optim.lr_scheduler.StepLR(
    optimizer,
    step_size=3,
    gamma=0.1
)

model = get_model_instance_segmentation(num_classes)

model, optimizer = ipex.optimize(model, optimizer=optimizer, dtype=torch.float32)
model = model.to(device)

Optimization Experiment:
Start time: 2024-04-27 16:27:36.983459
End time: 2024-04-27 16:47:38.238154

datetime.timedelta(seconds=1201, microseconds=254695)
Start time: 2024-04-27 17:46:16.191538
End time: 2024-04-27 18:02:06.233684

datetime.timedelta(seconds=950, microseconds=42146)
Start time: 2024-04-27 17:02:22.302090
End time: 2024-04-27 17:18:17.402227

datetime.timedelta(seconds=955, microseconds=100137)

As you can see, intel ipex and bfloat16 saved us 4 entire minutes for this model. Imagine a much larger model and the type of time and compute cost savings that could be achived.

Intel LeaderBoard

We submitted a custom bfloat16 model to the intel leaderboard. Here is the model fine tuned from Gemma





Use of LLMs and implications of hallucinations

We used LLMs to generate and extend data that we used to fine tune our text directions Gemma model. Hallucinations for directions in this case could cause people to go to places that do not exist. This could be fixed by using existing databases of locations (Like a mapping API) to insure that the LLM is always directing someone to a real place.

Proximity Alert

Use an Arduino and an ultrasonic distance sensor to alert the driver if they are too close to anything, including another car. We alert the driver by playing sounds and showing lights so they can take action.

Using Intel Developer Cloud for our PyTorch Model for Blind Stop Detection









OpenCV Person Detection



OpenCV Lane Detection



Original Image



Black and White



Canny Processing



Applying a crop to area of interest



Final by averaging out differences



Driver Alertness Detection

The driver is not looking at the road



The driver is looking at the road


",https://github.com/JakeRoggenbuck/hackdavis-2024,,"Best AI/ML Hack, Best use of Intel¬Æ Developer Cloud, Most Technically Challenging Hack, Best Hardware Hack","intel, pytorch, python, arduino, opencv, tkinter",JakeRoggenbuck,Roggenbuck,jakeroggenbuck2@gmail.com,,Best use of Intel¬Æ Developer Cloud,Best Hardware Hack,Best AI/ML Hack,"University of the Pacific, University of California - Davis",3,Ferhawn,S.,ferhawn.shaheen04@gmail.com
Untitled,,,Draft,Pending,Manage team,04/27/2024 19:35:50,,,,,,Jacob,Marinas,jacob1marinas@gmail.com,,,,Most Technically Challenging Hack,University of California - Davis,0,,,
Untitled,,,Draft,Pending,Manage team,04/27/2024 19:36:05,,,,,,Jacob,Marinas,jacob1marinas@gmail.com,,,,Best AI/ML Hack,University of California - Davis,1,Juan,Alvarez,killopillers@hotmail.com
Doggo AI,134,https://hackdavis-2024.devpost.com/submissions/510863-doggo-ai,Submitted (Gallery/Visible),Pending,Submit,04/27/2024 19:53:50,"

Inspiration

What it does

Doggo AI is a companion to children in hospitals. Children can interact with Doggo AI naturally through conversation. Doggo AI will tell stories and teach children who feel isolated and give them the attention they need.

There are 3 main functions:


Responsive AI - Doggo AI can converse in real time, responding naturally to interruptions, questions, and statements
Emotion Detection - Doggo AI can observe emotions and respond accordingly
Dashboard - Parents and caretakers can view information, such as a live conversation transcription and the emotions Doggo AI detects in real time.


All of this is bundled into a soft, fluffy plush to encourage kids to hug and interact with Doggo AI!

The Design Process

We went a comprehensive review of the design process


Research

We conducted secondary research on existing options and competitors  and what they had to offer. We noticed that there was no option that offered fully interactive, responsive, and adaptive companions for children in hospitals


We collected responses from 4 patients and caretakers who shared one thing in common: all of them were frustrated by the lack of access to caretakers and a desire for connection 


With this information, we formulated a comprehensive problem statement

We developed 2 user personas of the 2 core stakeholders on our platform: long-term patients and caretakers


Designing Solutions

We ideated solutions and prioirtized features that would deliver the highest impact is.


We designed a  user flow of the main use case and game loop of the platform between the community platform and the live interactive platform with the teddy bear


We designed low fidelity wireframes to conceptualize the idea


Then we moved to final high fidelity prototypes to envision a simple and intuitive interface for all children to access


How we built it


Extensive multi-threading, multi-processing, and asyncio code


To optimize and create the natural chat-like interruptions, we utilized multi-processing, multi-threading, and asyncio tasks to enable Doggo AI to simultaneously converse, respond, and detect emotions.
Here is the system design we underwent:


Hume EVI API


To detect emotions and talk emotionally, we used the Hume EVI api

GPT 4


Generate the conversation and interactions

WebSockets


Real-time Communication between Plush and Frontend was accomplished through WebSockets and a WebSocket server hosted thorugh FastAPI.

Next.js, TypeScript, ShadCN, Tailwind, Figma


The frontend dashboard, designed by Jasmine using Figma

Raspberry Pi and Hardware


Our hardware includes a webcam, a dedicated microphone, and a small speaker we stuffed into the plush. Also, the plush as a power bank stuffed inside it as well.
We originally had a Raspberry Pi, but unfortunately we pushed it too hard and it got way too hot... D:

Artisan Craftmanship


The plush's hat is hand-sewn by hand, utilizing the best merch out there: Hack Davis 2024. Notice the exquisite Hack Davis patch on the plush's head!



Accomplishments that we're proud of

What we learned

What's next for Doggo AI
","https://github.com/IdkwhatImD0ing/DoggoAI, https://www.figma.com/proto/xdmjDFd9PHNXUa3biN1l69/DavisHacks-2024-Mockups?page-id=0%3A1&type=design&node-id=49-4198&viewport=325%2C-113%2C0.15&t=KOdgw4KPSphZz0fW-1&scaling=scale-down&starting-point-node-id=49%3A4198&mode=design",,"Best use of Intel¬Æ Developer Cloud, Best UI/UX Prototyping, Best Overall Design, Best Interactive Media Hack","fastapi, hume, gpt-4, python, typescript, tailwind, shadcn, websockets, next.js",Kevin,Wu,kevinwu098@gmail.com,,Best Overall Design,Best use of Intel¬Æ Developer Cloud,Best UI/UX Prototyping,"University of California - Irvine, University of Southern California",3,Bill,Z,billzhangsc@gmail.com
Fetal Head Mesurements,75,https://hackdavis-2024.devpost.com/submissions/510870-fetal-head-mesurements,Submitted (Gallery/Visible),Pending,Submit,04/27/2024 20:09:42,"Inspiration

We were inspired to figure out more about fetal heads during pregnancy since there did not seem to be a lot of research using computer vision and A.I. doing so. We realized that we could try putting more interest on it, since looking at early signs of fetal heads and figuring out whether there could be future complications are important.

What it does

The code parses through over 300 images of different prenatal photos using computer vision technology. We are able to identify prenatal heads.

How we built it

We built it using python and Open CV. We were able to blur and sharpen the images in order to hone in on the specific portions we wanted to find in order to attempt to measure the babies head shapes.

Challenges we ran into

The main challenge we ran into was trying to quantify the babies heads for measurements, so we could start training our A.I. model using tensor flow.

Accomplishments that we're proud of

We are proud of the fact that we were able to identify the fetal heads while they were in the womb, even with the image quality being so low.

What we learned

We learned about Computer Vision and its many facets regarding blurring, sharpening, and different ways to find edge values.

What's next for Fetal Head Measurements

We hope to continue to work on this project in order to quantify the fetal head shapes so we can train our A.I. model so in the near future it will be able to predict if the baby may have possible complications for the head size being too big or small.
",https://github.com/NocturnalKing/HackDavis24,,"Best Health Hack, Most Creative Hack, Best AI/ML Hack, Most Technically Challenging Hack","python, imutils, opencv, numpy, argsparse",Eeshan,Khullar,fake.hack376@gmail.com,,Best Health Hack,Most Technically Challenging Hack,Most Creative Hack,"University of California - Merced, University of California - Davis",1,Samarth,Sridhara,samarth.sridhara@gmail.com
AggieAcres,101,https://hackdavis-2024.devpost.com/submissions/510871-aggieacres,Submitted (Gallery/Visible),Pending,Submit,04/27/2024 20:10:17,"Inspiration

Many UCD students wish to move out of dorms after their first year but struggle with the current housing search tools. Traditional methods require checking multiple websites and making complex comparisons based on different criteria.

What it does

Our search web form, AggieAcres, addresses this by providing a streamlined, user-friendly platform where students can specify their needs and instantly receive tailored housing options in Davis, California. The user just has to input their preferred number of bedrooms and monthly rent pricing. Some tailored apartment listings are then provided to the user based on those preferences.

How we built it

Backend: We used Python server scripts to fetch and process data from different APIs.
Frontend: We used a program (""Screenshot-to-Code"") that uses large multimodal models like GPT-4 to autogenerate templates of our HTML webpages, then designed them with Tailwind CSS.

Challenges we ran into


Fetching and integrating housing data from multiple different websites was a problem since we were newbies learning about web scraping on the fly.
We had an issue getting the screenshot-to-code model to boot up in our terminals (both on Windows and Ubuntu) since it requires a lengthy process of executing commands.
Editing HTML elements to realize our design goals for the webpages was difficult given our minimal knowledge base.


Accomplishments that we're proud of


The two of us who worked on the backend side successfully web scrapped hundreds of apartment listings along with their pricing & bedrooms info
Being able to use the GPT-4 vision models through Ubuntu to scan screenshots of example websites and generate a new template.
A unique, cute logo for AggieAcres :)


What we learned

For those of us on the frontend side, we learned a decent amount about editing webpages with HTML code and Tailwind CSS! The backend crew learned plenty about Python web-scrapping, aggregating web data, and converting them into .csv data.

What's next for AggieAcres

Plenty. We want our web form to take in housing data from many reliable websites (e.g. Zillow, Rent.com, etc., etc.) and turn our webpages into a beautiful, UC Davis-themed website. We also want to include more user preferences such as commuting distance.
",https://github.com/bayquen/AggieAcres/,,,"python, gpt-4, html, tailwindcss, spring-boot, .csv",Brandon,Bayquen,brandonbayquen@gmail.com,,NA,Best Beginner Hack,Best Entrepreneurship Hack,University of California - Davis,3,Ethan,N,mouseclicks25@gmail.com
Untitled,,,Draft,Pending,Manage team,04/27/2024 21:15:46,,,,,,Chen,Liu,bzdliu@ucdavis.edu,,,,Hacker's Choice Award,University of California - Davis,0,,,
CheckThat!,115,https://hackdavis-2024.devpost.com/submissions/510891-checkthat,Submitted (Gallery/Visible),Pending,Submit,04/27/2024 21:30:39,"Inspiration

We learned that companies lost for $101 billion dollars from return fraud in 2023. Additionally, 60% of these fraud losses are unrecovered for small businesses. As they have no method of verifying if the product is really the one that they shipped, they lose thousands every where from these malicious buyers. As small business owners ourselves, we understand how hard of a hit that can be as we are often working day and night to make incremental profits.

What it does

Using your phone or web camera, we use our computer vision software to automatically detect the returned items. Then, using our advanced fraud recognition algorithm, integrated with Chat GPT 4 Turbo's image recognition perks, we check whether the condition of item based on: authenticity, Included packaging and accessories, and visible damage. Using all these factors we determine whether the item is returnable based on our proprietary measurement scale: SCRC (Suitable Return Confidence Rating).  

*We train and improve: * As the small business continues to use our program, the computer vision program trains itself. We start recognizing individual product from the small business better and faster, and are able to analysis damaged areas at a much higher precision. 

How we built it

We started with building a rough diagram of how we were going to implement this code. We created rough diagrams of napkins to illustrate the process and how we connect the detection of the computer vision script to our dashboard.

As we effectively brainstormed the whats, we hastily moved into operation. Cody worked on the computer vision script using Yolov5 and Chat GPT 4 while Arjun worked on the integrations with the dashboard using Next.js. We worked simultaneously, building the groundworks of the software. Here's a basic rundown of how it works:


The computer vision script analyzes photos and detects whether the target object (what the user returned) is in the frame.
Once the item is seen, we process multiple snapshots and send them to Chat GPT 4 Turbo and, using prompt engineering and multimodal detection, we analyze if the item is in the correct condition to be returned.
After we processed this information, we relay it to our backend, MongoDB, which updates our Dashboard instantly to allow the small business to see real-time updates regarding their returns. Here, the business can make real-time and data driven decisions to what they would do with the processed return.


Challenges we ran into

The computer vision script was very intensive on our systems, so managing with our analysis algorithm led to many abrupt crashes. We realized that the video the computer vision script was taking, and the snapshots that were being sent to our image analysis algorithm was way too GPU intensive. To fix this, we optimized our code to use more CPU and adjusted the intervals that the snapshots were taken to account for our size. 

Accomplishments that we're proud of

We are proud of the computer vision script to AI integration. In 24 hours, we didn't think that we would be able to create a system that checks fraudulent returns from real ones - especially since neither of us are computer science majors.

What we learned

We learned so much about computer vision, various open source AI integrations and how to use them effectively, Intel' Developer Platform, data streaming, connecting python scripts with a Next.js project (something we have never known was possible) and how to effectively use MongoDB.

What's next for CheckThat!

As our detection improves per use, we plan on training to improve the confidence of its detection. 

Check out Our Hugging Face Link - Intel Developer Cloud

https://huggingface.co/CodyLiu/checkThat_YOLOv5

Get Started With our Model. It trains after every iteration and ""check"". Here we used the Intel Developer Cloud to make this happen.
import torch
import intel_extension_for_pytorch as ipex
from models.common import DetectMultiBackend
from utils.general import non_max_suppression, scale_boxes
from utils.torch_utils import select_device
from utils.dataloaders import LoadImages
from pathlib import Path

def run_inference(weights, source, imgsz=(640, 640), conf_thres=0.25, iou_thres=0.45):
    # Initialize device and model
    device = select_device('')
    model = DetectMultiBackend(weights, device=device, dnn=False)
    model = ipex.optimize(model, dtype=torch.float32)  # Optimize model

    # Load image
    dataset = LoadImages(source, img_size=imgsz, stride=model.stride, auto=model.pt)
    path, img, im0s, _ = next(iter(dataset))

    # Inference
    img = torch.from_numpy(img).to(device)
    img = img.float()  # uint8 to fp32
    img /= 255  # 0 - 255 to 0.0 - 1.0
    if len(img.shape) == 3:
        img = img[None]  # expand for batch dim

    with torch.cpu.amp.autocast():  # Enable mixed precision
        pred = model(img, augment=False, visualize=False)

    # Apply non-max suppression
    pred = non_max_suppression(pred, conf_thres, iou_thres)

    # Scale boxes to original image size and display or save
    for i, det in enumerate(pred):  # detections per image
        if len(det):
            det[:, :4] = scale_boxes(img.shape[2:], det[:, :4], im0s.shape).round()

    return det  # Return detections

if __name__ == '__main__':
    weights_path = 'path/to/yolov5s.pt'
    image_path = 'path/to/image.jpg'
    detections = run_inference(weights_path, image_path)
    print(f'Detections: {detections}')
",https://github.com/arjundabir/checkthat,https://youtu.be/svJXbFq5Oes,"'	Best Hack for Social Justice, Best AI/ML Hack, Best use of Intel¬Æ Developer Cloud, Best Use of .Tech Domain Name, Best Finance & Tech, Best Entrepreneurship Hack","python, yolov5, cloudflare, mongodb, openai, next.js, react, intel, amazon-web-services, tailwind",Arjun,Dabir,arjunadabir@gmail.com,,Best Hack for Social Justice,Best use of Intel¬Æ Developer Cloud,'	Best Hack for Social Justice,"University of California - Irvine, University of California - Davis",2,Cody,Liu,codliu@ucdavis.edu
test 1,,,Draft,Pending,Additional info,04/27/2024 22:43:41,"Inspiration

What it does

How we built it

y

Challenges we ran into

Accomplishments that we're proud of

What we learned

What's next for test 1
",,,"Best Beginner Hack, Best Interdisciplinary Hack, Best Health Hack, Best Hardware Hack",python,Anjali,Jain,anjjain@ucdavis.edu,,Best Beginner Hack,Best Hardware Hack,Best Interdisciplinary Hack,University of California - Davis,0,,,
test2,,,Draft,Pending,Additional info,04/27/2024 23:34:47,"Inspiration

What it does

hy

How we built it

Challenges we ran into

Accomplishments that we're proud of

What we learned

What's next for test2
",,,"'	Best Hack for Social Justice, Most Creative Hack, Best AI/ML Hack, Best DEI Hack Sponsored by Fidelity",java,Anjali,Jain,anjjain@ucdavis.edu,,Best DEI Hack Sponsored by Fidelity,Best Hack for Social Justice,'	Best Hack for Social Justice,University of California - Davis,0,,,
Image Classification Test,,,Draft,Pending,Additional info,04/27/2024 23:36:37,"Inspiration

hi

What it does

hi

How we built it

Challenges we ran into

Accomplishments that we're proud of

What we learned

What's next for Image Classification
",,,,html,Brandon,Wong,brandonw504@outlook.com,,Best use of Intel¬Æ Developer Cloud,Best AI/ML Hack,Best Interdisciplinary Hack,University of California - Davis,0,,,
test3,,,Draft,Pending,Additional info,04/27/2024 23:37:23,"Inspiration

nhg

What it does

How we built it

Challenges we ran into

Accomplishments that we're proud of

What we learned

What's next for test3
",,,"Best use of Intel¬Æ Developer Cloud, Most Technically Challenging Hack, Best UI/UX Prototyping, Best User Research",c,Anjali,Jain,anjjain@ucdavis.edu,,Best use of Intel¬Æ Developer Cloud,Best UI/UX Prototyping,Most Technically Challenging Hack,University of California - Davis,0,,,
test4,,,Draft,Pending,Additional info,04/27/2024 23:41:37,"Inspiration

What it does

nbvgh

How we bguilt it

Challenges we ran into

Accomplishments that we're proud of

What we learned

What's next for test4
",,,"Best Overall Design, Best Use of .Tech Domain Name, Best Use of Kintone, Best Use of TinyMCE",c++,Anjali,Jain,anjjain@ucdavis.edu,,Best Use of .Tech Domain Name,Best Use of Kintone,Best Overall Design,University of California - Davis,0,,,
Audio Project Test,,,Draft,Pending,Additional info,04/27/2024 23:42:26,"Inspiration

What it does

How we built it

Challenges we ran into

Accomplishments that we're proud of

What we learned

What's next for Audio Project Test

Test
",,,"Sauce Labs Raffle, Best Interactive Media Hack, Best Finance & Tech, Best Entrepreneurship Hack",tesseract,Brandon,Wong,brandonw504@outlook.com,,Best Interactive Media Hack,Sauce Labs Raffle,Best Finance & Tech,University of California - Davis,0,,,
Untitled,,,Draft,Pending,Manage team,04/28/2024 00:28:29,,,,,,Victor,Vu,vuvictor2003@gmail.com,,,,Best User Research,San Jose State University,0,,,
BeeOnTime,39,https://hackdavis-2024.devpost.com/submissions/510964-beeontime,Submitted (Gallery/Visible),Pending,Submit,04/28/2024 01:21:42,"Inspiration

While a majority of our inspiration for the app‚Äôs function came from the research conducted about Aggie House‚Äôs current schedule management systems, we referenced time management programs and other apps to formulate an effective user interface. More specifically, the Dutch Bros app‚Äôs badge rewards inspired the function of our gamification system and Notion‚Äôs simplistic UI influenced our minimalist layout.

For the graphics included in BeeOnTime, we were inspired by the minimalist illustrations of characters and flowers by Filipino artist, Blok Magnaye, to match the simple and modern look of our app layout. Each badge illustration references common flora and fauna, as well as a few badges taking inspiration from microscopic images of pollen.

What it does

BeeOnTime aids volunteers with timekeeping, scheduling shifts, and sending shift reminders, as well as inspiring motivation with a badge-earning system.

How we built it

Research: 
At the Aggie House sponsor booth, we met with Resident Co-President Virginia Moore, discussing the scheduling systems and resources volunteers use. Currently, the organization uses two Google Forms and a Google Sheets calendar to keep track of volunteer attendance, shift schedules, and tasks completed during each shift, as well as Discord, a website, and a Google Drive for shift swapping, contact information, and any volunteer instructions. Additionally, we conducted a competition analysis with Trojan Shelter‚Äôs website, a sister shelter to Aggie House, which also uses the same Google Form-based scheduling format.

When checking in to the first Google form, volunteers are asked basic identification information and reminded to complete shift tasks. When checking out with the second form, volunteers are again asked for identifying information, the chores completed, what supplies are in need of restocking, and any resident or volunteer questions/concerns/comments.

Separate from these check-in forms, the Google Sheet contains the master calendar of volunteer shifts, ordered by week over the quarter. Each shift goes from 7 PM to 8:30 AM with the two scheduled volunteers listed, as well as a space for back-up volunteers to list their name.
Interview

Going forward, we decided to interview Olivia Hurley, a previous Aggie House volunteer, to gain more insight into what assets would be most helpful for volunteers to readily access. In our conversation, we learned that volunteers complete around 5-6 shifts each quarter and may leave early from their designated shift time.

To further optimize our app‚Äôs function, we created a fictional user persona based on Hurley‚Äôs experience volunteering with Aggie House. This persona let us explore the perspective of Aggie House volunteers and flesh out the user interaction with the different app assets, as well as forming a story to guide us through the app demo.

Ideation: 
Upon finishing our research, we decided the best solution to Aggie House‚Äôs prompt is an app that centralizes volunteer shift management systems, sends out automatic shift reminders to volunteers, and uses gamification elements like badges based on volunteer hours. With this app, volunteers would be able to manage their schedules more efficiently, be kept accountable for clocking in and remembering their shifts, and be encouraged to continue volunteering with Aggie House.

Final Design Process/Implementation: 
At the start of our design process, we first wireframed a sitemap draft on a whiteboard and then created the official sitemap for volunteers on Figma. Based on the views, we ideated a color palette and style guide for the entire app, settling on a design direction based on worker bees and hives.

From here we created lo-fi paper sketches of the volunteer view based on the site map, drawing out the main features and notifications. Using the sketches, we then created mid-fi iterations on Figma and continued to refine the volunteer view. While working on the different site views, we used Illustrator to make a vector logo and illustrations for the characters and badges. Next, we proceeded with elevating our mid-fi iterations into a hi-fi prototype: editing text size, switching layouts, and fine-tuning the visual rhetoric of the app. To finalize our prototype, we added moving animations and interactive software from Figma, rendering it into full functionality.

Challenges we ran into

One of the main challenges that we faced was the time constraint of the sprint, it specifically effected the number of pages we wanted to implement in the final design. Other smaller challenges we ran into was figuring out the current systems Aggie House was using for their volunteers, cutting down the amount of views we had initially thought of in our ideation, and adding in animations to our final prototype, all of which we were able to work out within our design process.

Accomplishments that we're proud of

We believe that we were responsible with the limited amount of time that we had, effectively splitting up the work between the team. We're proud of our overall communication and drive to ideate, create, prototype, research, and design that helped us complete our goal for this project. The gamification system and the UI implemented for our project were especially our biggest accomplishments throughout the project.

What we learned

We learned how to manage our time throughout a 24-hour design sprint and how to add gamification elements into a time management app. The prototyping and moving effects were also skills we honed in on throughout the process of creating this project.

What's next for Bee On Time

Past the 24-hour design sprint, our next steps would be to expand upon volunteer facets and add features for Aggie House‚Äôs residents and staff. Our main ideas for future add-ons would be: 


Additional limited-edition holiday badges to encourage volunteers to pick up shifts during holiday breaks when volunteering is low. 
An option for residents to sign in and access their Aggie House resources, check the volunteer schedule, request any basic needs, check-in for dinner, and track their attendance. 
Creating the admin app view for staff to manage volunteer schedules, send out mass notifications, be notified when a volunteer no-shows, and access a master list of volunteer contact information.


Since Aggie House is part of a larger network of shelters under Student Mojo, we‚Äôre also considering expanding the app to be used by other sister shelters. Even now, the app‚Äôs function could be utilized by other volunteer-based communities to improve time-keeping, shift scheduling, and volunteer encouragement.
",https://www.figma.com/proto/JLhSjBwzsqGmUIgyp8sbnz/HACK-DAVIS-2024?page-id=2%3A3&type=design&node-id=189-1715&viewport=-2712%2C2631%2C0.52&t=NfKGOeyoNqnrb4eE-1&scaling=scale-down&starting-point-node-id=189%3A1715&mode=design,https://youtu.be/vEI1CU3DL9Y,"Most Creative Hack, Best UI/UX Prototyping, Best Overall Design, Best User Research, Best Hack for AggieHouse","figma, adobe-illustrator, notion",Shaelyn,Smith,shaelynspsmith@gmail.com,,Best Overall Design,Best UI/UX Prototyping,Most Creative Hack,"University of California - Davis, Saint Mary's College of California",3,Alexander,Linshits,alinshits@ucdavis.edu
Untitled,,,Draft,Pending,Manage team,04/28/2024 01:54:19,,,,,,Abhishek,Yadav,abhiishek340@gmail.com,,,,Best MedTech Hack,Northern Kentucky University,0,,,
√úConnect,149,https://hackdavis-2024.devpost.com/submissions/510987-uconnect,Submitted (Gallery/Visible),Pending,Submit,04/28/2024 02:12:27,"Introduction

College students are often limited by their immediate peers and resources. While campuses work hard to give students opportunities to connect with their peers with similar goals through classes and clubs, students should have more opportunities to build their skills outside of school-associated activities. Students can benefit from having done one or more independent projects before graduation in order to prepare them for the workforce but are often limited to their immediate peers.

Inspiration


Unless you already have peers at other UC campuses, the opportunities to get to know them are typically limited. For example, even students such as transfers who are now part of their respective campuses are limited by their immediate resources ‚Äì the UC system is ‚Äúa public land-grant research university system‚Äù and provides its students with ample opportunities, but as students in an increasingly online world we have the ability to reach for more than what is just right in front of us. 
As designers who transferred into the UC system in our third years, we‚Äôve had to balance adapting to new environments, class schedules, and more. A platform like this would be beneficial ‚Äì being able to independently work and gain experiences with other students outside of the classroom, even outside of our own campuses can help us hone valuable, transferable skills.


Goals


Fostering more confidence in student populations that otherwise would not have felt empowered to make time for portfolio-building activities outside of school
Widening user‚Äôs networks 


Research


We surveyed 78 students and the input we received heavily informed our design decisions while creating the features for the app. We were able to adapt common functions people used in competing apps, such as Linkedin, Instagram, and Handshake. This includes messaging features, friend lists, and recommendations for potential friends based on common interests. 
In our user research, over 67% of students surveyed would be either entirely unlikely or very unlikely to pursue extracurriculars if they do not fit their schedules.
-Our competitive audit helped us analyze competing applications and helped us identify needs that were not being met within already existing apps. From this, we decided that creating a friendlier, but focused environment for students to collaborate in was a niche that we could fill.
Google form survey
Competitive analysis


What it does

UConnect is an online platform that connects students part of the University of California higher education system with like-minded individuals to work on independent/extracurricular projects ‚Äì Our focus is to foster cross-campus camaraderie and connection between students who otherwise would not have been able to find each other.

How we built it

After ideating, Melody started by drawing out low fidelity workflow models on paper, showing user behavior/user journey/scenarios. We worked in tandem with one another where Melody drew out the low fidelity models on paper showing a typical user journey through the application. While she did this, the rest of our group (Lauren, Meredith, Alexis) worked on the the high fidelity models in Figma.

Challenges we ran into

As a group of beginner Figma users, two of us using it for the first time within the week leading up to HackDavis, we were learning each step of the way for the duration of our Hack/project. When we ran into features we weren‚Äôt sure how to use, taking time to figure things out slowed down our workflow.

Accomplishments that we're proud of

For all of us, figuring out Figma along the way was a productive, fun time. Individually, here‚Äôs what we felt the best about. 


Melody ‚Äì felt very happy that we followed her models, and learning features on Figma
Meredith ‚Äì figuring out the scrolling on Figma and figuring out user flow
Lauren ‚Äì drawing the logo, creating/animating figures, and figuring out user flow
Alexis ‚Äì working on the logo, and conceptualizing


What we learned

Over the course of the project, we learned how to prototype, acquired more in depth knowledge about conducting user research through surveying and reaching out to diverse groups of people within our college student demographic. 
In addition to this, we also workshopped prototyping and developing high fidelity models. 

What's next for √úConnect


We‚Äôd like to explore more in-depth user flow for interactions including reposting, commenting and uploading
User Flow for composing a message 
Adapting the scale (implementing other California schools (California State schools, California Community Colleges into the app) 

",https://www.figma.com/file/KnbIctnAZH6TXtHli2XDMQ/HACKDAVIS-24!?type=design&node-id=0%3A1&mode=design&t=WyLqhEr6HzMXxFTx-1,https://youtu.be/95EOV8DeLDE,"Best Beginner Hack, Best UI/UX Prototyping, Best Overall Design, Best User Research",figma,Meredith,Whisman,mwhismain@gmail.com,,Best Beginner Hack,Best User Research,Best UI/UX Prototyping,University of California - Davis,3,Alexis,Paneda,ampaneda@ucdavis.edu
Speech-To-Text,,,Draft,Pending,Project details,04/28/2024 02:40:39,"Inspiration

The audio transcription app was developed with the aim of helping provide valuable insights from lengthy audio files, helping those individuals who have hard of hearing, ADHD, or limited time. It delivers accurate transcriptions and includes the summaries and key points of the audio content, making the information accessible and helping people gain meaningful insights quickly.

What it does

Our audio transcription service uses AI technology to transcribe audio using Whisper AI, converting audio recordings to written text. Using multiple Python libraries, we were able to preprocess the text, generate a summary, and extract key sentences. Afterwards, the results are displayed on the next page for easy access.

How we built it

Our app was developed using React Native for the frontend and Flask in Python for the backend. We used Supabase to store our audio files and Heroku as our platform for our Flask application. For our development environment, we used VSCode as our IDE.

Challenges we ran into

Accomplishments that we're proud of

What we learned

What's next for Speech-To-Text
",https://github.com/kaitlynlie/hackdavis24,,,"flask, react-native, supabase, heroku",kaitlyn,li,kaitlynli0903@gmail.com,,,,Best UI/UX Design,University of California - Davis,2,NotJhan,,johntran.mehs@gmail.com
EcoSnap,147,https://hackdavis-2024.devpost.com/submissions/511013-ecosnap,Submitted (Gallery/Visible),Pending,Submit,04/28/2024 03:13:38,"Inspiration

Our project, EcoSnap, started from a simple but powerful idea: even though everyone wants a clean environment, not everyone knows how to help achieve it. Many places, especially remote or forgotten areas, don‚Äôt get enough attention from existing waste management systems. This can lead to harmful effects on the environment. We created EcoSnap to change this situation by using artificial intelligence, or AI, to make everyone an active part of solving the problem. With EcoSnap, anyone with a smartphone can easily report trash and pollution. This turns every phone user into a vital player in keeping their surroundings clean. Our app is designed to be easy to use, making taking care of the environment a rewarding experience for everyone. This way, EcoSnap doesn‚Äôt just help clean up‚Äîit builds a community of people who care about and actively contribute to a cleaner, healthier planet.

What it does

EcoSnap revolutionizes the way we manage waste by making it easy for anyone with a smartphone to get involved. Here‚Äôs how it works: users take a photo of waste they come across and upload it through our app. Our advanced AI technology analyzes these images to figure out what kind of waste it is, how urgently it needs to be cleaned up, and the impact it could have on the environment. The app then offers step-by-step guidance on how the user can safely clean it up themselves, if they choose to. If the waste needs professional attention, EcoSnap automatically informs local authorities with all the details they need to handle it. Additionally, to make taking action even more appealing, users earn points for every report and cleanup they contribute to. These points can lead to rewards, encouraging a community spirit and a friendly competition to keep our environment clean. This system not only improves waste management but also involves the community in a meaningful way, making our surroundings cleaner and safer for everyone.

How we built it

To build EcoSnap, we combined cutting-edge technology with user-friendly design. We started with React to develop a dynamic and responsive front end, ensuring that our app is easy to navigate whether on a desktop or a mobile device. For our backend, we chose FastAPI because of its high performance and ability to handle large volumes of requests efficiently‚Äîcrucial for a scalable solution. To analyze the waste images uploaded by users, we integrated the Gemini Pro API, which allows our app to quickly assess waste type and urgency. User authentication is managed through Propel Auth, providing secure and seamless access either through passwordless entry or Google login options. This robust combination of technologies ensures that EcoSnap is not only effective in engaging users but also reliable and secure, making environmental action accessible to everyone, everywhere.

Challenges we ran into

Our journey was filled with challenges, including difficulties in integrating Gemini API, issues with Propel Auth during user authentication, and hurdles in fine-tuning the AI for accurate waste recognition classification. 

Accomplishments that we're proud of

We are proud of our AI integration that accurately classifies types of waste, our seamless user interface that encourages user engagement, and our effective collaboration with local authorities to enhance cleanup efforts. Developing a reward system that motivates continuous user participation and achieving a scalable solution for backend management are among our key successes.

What we learned

This project taught us about the complexities of integrating various technologies for a unified purpose, the importance of user-centered design, and the challenges of handling real-time data and privacy concerns responsibly. We gained insights into effective project management and the agile adaptation of plans to overcome unforeseen difficulties.

What's next for EcoSnap

Looking ahead, we plan to expand the AI's capabilities, increase our geographic coverage, and integrate with smart city projects. We aim to enhance our app's features to support community clean-up events and develop partnerships with local businesses for a more impactful reward system. EcoSnap will continue to evolve to meet the challenges of sustainability and environmental responsibility.
",https://github.com/audsostrom/garbage-collector-ai,https://youtu.be/AM657TiZwV4?si=7uxtA6TEZNyt6orQ,"Best Health Hack, Most Creative Hack, Best AI/ML Hack, Best UI/UX Prototyping, Best Overall Design, Best Use of PropelAuth","react, javascript, python, fastapi, propelauth, llm, geminiapi, postgresql",Utkarsh,Shah,utkarshshah1995@gmail.com,,Best Health Hack,Best Use of PropelAuth,Most Creative Hack,"San Jose State University, Charusat University",3,Aagam,Shah,aagamshah0812@gmail.com
VR Robotic Arm Controller,30,https://hackdavis-2024.devpost.com/submissions/511014-vr-robotic-arm-controller,Submitted (Gallery/Visible),Pending,Submit,04/28/2024 03:14:22,"Inspiration

As society trends towards greater efficiency, cost-saving measures, and productivity, there arises a need for innovative tools. Our robot arm, controlled through Meta Quest 2, offers intuitive control, surpassing traditional button-based interfaces. This achievement enables a user-friendly interface, significantly reducing training costs and time. Moreover, the rapid development of internet networks instills confidence in achieving true remote capabilities, regardless of distance. We expect it to integrate with trending fast internet technology to achieve low-to-none latency.

What it does

Precisely and responsively interact with a robotic arm using the Meta Quest 2. The robotic arm and the Meta Quest 2 can be paired over the Internet through computers across the ocean!

How we built it

We utilized HTML, CSS, and JavaScript for our full-stack application with Firebase for server side hosting. To achieve the peer-to-peer telecommunication, we use WebRTC to establish connection in between computers. We used Interbotix and Ros to control the movements of the robotic arm.

Challenges we ran into


WebRTC Integration
Programming robotic arm movements
Creating JavaScript sockets
Lack of design


Accomplishments that we're proud of


Amazing supportive teamwork
Using WebRTC for the first time
Overcoming road blocks with programming the robotic arm movements


What we learned


WebRTC Integration
Learned design principles and how to set up backend with Firebase


What's next for VR Robotic Arm Controller


Introduce some sorts of threshold to filter out ""noisy"" hand actions. More specifically, the robot arm would act more stable to shaky hand.
More robotic arm movements, more joints, more human-like grabbing.
Seamless integration with other VR headsets, better to be adaptable for cheaper VR gears.
Bridge with faster internet agreement such as 5G or futuristic 6G.

",https://github.com/KaoushikMurugan/MostEpicHack,https://youtu.be/bpgiIuRWoKk,"Most Creative Hack, Most Technically Challenging Hack, Best Hardware Hack, Best Interactive Media Hack","webrtc, python, javascript, html, css, interbotix, ros",Brian,Li,brianli4824@gmail.com,,Best Hardware Hack,Most Technically Challenging Hack,Most Creative Hack,University of California - Davis,3,Lishen,Liu,llsliu@ucdavis.edu
Davis Community Meals and Housing Redesign,90,https://hackdavis-2024.devpost.com/submissions/511016-davis-community-meals-and-housing-redesign,Submitted (Gallery/Visible),Pending,Submit,04/28/2024 03:19:10,"Inspiration

Davis Community Meals and Housing is a non-profit organization that focuses on ""Instilling Hope and Saving Lives"" of homeless and low-income families and individuals by providing them with housing, food, and human services to help them rebuild their lives. We were inspired and honored to redesign DCMH since they wanted both a tech aspect and design aspect, a good blend of our team, as well as a good social cause we were happy to help.

What it does

A brand redesign and a more user friendly experience for DCMH that would show visitors which items are more in need for them to donate as well as to learn about DCMH's mission statement and what they do. 

How we built it

We have redesigned their website to a more modern and simple color palette that is both eye-catching and comforting to look at. We started with research about the current website and ideas that we liked/didn't like about it and drew out ways we could improve their website before deciding on an idea and putting it onto Figma. We had a second team working on the front end of the website with HTML, CSS, and JS and they tried to work on a database through Python that would track their inventory in real time that would also tell people who would like to donate which items are more in need presently. 

(Fun Fact: we had our coders learn HTML in two days and try to recreate the website on Figma, our designers are also MEGA rusty in Figma üòé)

Challenges we ran into

Some challenges we ran into were the varying experiences of our team. This was the first time for our coder team to do front-end but they still managed to develop this website and database (woooo!!!) while we had two (rusty and/or beginner) designers that don't understand the pain of coding (only one does). It was hard trying to make on Figma, two views, one for admin view to see the inventory and one for public view to see what items we needed the most. We weren't able to get the second part of the website fully updated that we would like in the time span.

(Fun Fact: Also one of our teammates ditched us for his Sunday Shift as Latitude and the other one left us to go to Berkeley for a work meeting womp womp)

Accomplishments that we're proud of

This was all of our first hackathons so we're proud of ourselves for that! 

We (the designers) liked the final design and the coloring of the prototyped website as well as we believed how it effectively showed the mission and goals of DCMH.

""I learned a lot"" - Coder

What we learned

We learned that how much we had to communicate with each other to make sure that our product is up to our standards. We had our programmers learn basic web developing tools in two days and our designers were new to Figma or rusty at Figma so relearning/learning these tools was an experience.

What's next for Davis Community Meals and Housing Redesign

If we are allowed to continue working on the website, we would like to create a way for the admin and public view to be different and be able to work more on the website to include more of the original website and navigations. In the future, we would also like to create a mobile web design for DCMH!
","https://www.figma.com/proto/7FMEuXkKFM4V42k7hFRjYJ/HackDavis?page-id=0%3A1&type=design&node-id=1-8&viewport=-476%2C132%2C0.32&t=nAwD1gjUmljAVjtX-1&scaling=min-zoom&starting-point-node-id=23%3A194&mode=design, https://github.com/lctnguyen/DCMHRedesignedHackDavis24.github.io, https://lctnguyen.github.io/DCMHRedesignedHackDavis24.github.io/",,"Best Beginner Hack, Best Interdisciplinary Hack, Best Overall Design, Best Hack for DCMH","python, html, figma, adobe-firefly, adobe-creative-sdk, css, javascript",Katelin,Tan,katelin291491@gmail.com,,Best Hack for DCMH,Best Interdisciplinary Hack,Best Beginner Hack,University of California - Davis,3,Khanh,Nguyen,khanh.nguyenv2@gmail.com
FaceChat.ai,55,https://hackdavis-2024.devpost.com/submissions/511032-facechat-ai,Submitted (Gallery/Visible),Pending,Submit,04/28/2024 03:55:30,"Inspiration

With the introduction of the federal government's Autism CARES Act, autism and communication problems are receiving more attention nowadays. According to the Centers for Disease Control and Prevention (CDC), approximately one in 46 children in the United States faces communication barriers. We are passionate about mental health awareness and were inspired to develop an emotion detection system. We want to create an AI-powered emotional chat tool to facilitate better communication. Many children desire more communication and companionship. We believe that FaceChat.ai will help build the bridges across to worldwide.

What it does

FaceChat utilizes remote video emotion analysis supported by artificial intelligence and computer vision to provide a platform for individuals facing communication barriers. This service offers enhanced features that effectively improve communication. Through virtual interactions, users can employ sentiment analysis to determine whether their language might be hurtful to others.

How we built it

We first start with a video stream, building a socket server to establish the interactive system. We use React.js as the framework for our website development, incorporating internal components ""styling"" accordingly. After a user completes a sentence, we call the emotion detection API to analyze the emotional impact on the other party. Meanwhile, we use the audio processing interface to convert speech into text. Combining these two interfaces, we import the data into our emotion analysis ChatGPT model to provide user feedback. Based on feedback, users can make improvements and apply them to subsequent conversations.

Challenges we ran into

We are particularly proud to have implemented the ""video on the web"" module. Our team's expertise was crucial in understanding web sockets and the HTTP protocol. Our biggest allies in this process have been Chrome's developer tools, which we used to build the foundational framework of the web.
We are also proud of the algorithms that connect the emotion detection and speech conversion modules. We use a delay method to ensure the correct sequence of these modules. A significant challenge in this process is balancing achieving better performance without wasting computing power. After hours of debugging and programming iterations, we refined the data structure to produce a more intuitive output. Another challenge is debugging large language models. We need to set different conditions to ensure that the production of GPT does not deviate. By controlling the word count, we achieve the right amount of information. Through 'core sampling,' we can distinguish the correct topics. Simultaneously, we set the 'frequency penalty' and 'presence penalty' to keep the text within a reasonable range.

What's next to do

We are all very excited about the development of this app. In terms of future technological advancements, we believe the following steps will elevate our application to a new level.
Implementing a remote sign language module for contactless conversion into text.
Introducing multi-channel video calling.
Enhancing security features.
",https://github.com/JZwlth/Davis_Hack,,,"node.js, react, javascript, html, css, chatgpt",Jack,Z,edjazy87@gmail.com,,Best Beginner Hack,Best Hack for Social Justice,Hacker's Choice Award,"De Anza College, California State University - Fullerton",3,Tree,Z,siyuantreez@gmail.com
Aggie House Volunteer Portal,26,https://hackdavis-2024.devpost.com/submissions/511035-aggie-house-volunteer-portal,Submitted (Gallery/Visible),Pending,Submit,04/28/2024 04:02:20,"Inspiration

Our inspiration for the Aggie House Volunteer Portal was the interest in the mission of Aggie House themselves. It is a great opportunity to be a part of helping the community to tackle housing insecurity. By streamlining the volunteer management process, we aimed to create a centralized platform to facilitate sign-ups, shift management, announcements, and other communication.

What it does

The Aggie House Volunteer Portal is a platform for volunteers and admins alike. Volunteers can use the portal to sign up for shifts, manage their schedule, receive announcements, and even receive SMS reminders for upcoming shifts. It is important communication is built with the SMS system to confirm shift attendance. Admins have access to additional functionalities such as adding or removing shifts, sending messages to specific volunteers, and creating announcements.

How we built it

We started by designing the front end interface of the website with Figma to ensure a user-friendly experience. This involved creating components and layouts with React in our frontend code when moving from the design phase to the implementation. We also began implementing backend functionality using PropelAuth for user authentication. However, due to challenges in setting up PropelAuth and navigating the directory for the tool, we encountered obstacles in completing this portion of the backend development. We are also exploring AWS for SMS system.

Challenges we ran into

PropelAuth Integration: Setting up PropelAuth for user authentication was more difficult than we had anticipated. It posed a significant challenge, as we faced difficulties in understanding its implementation of locating the correct directory and files in the code.

Learning AWS: Despite having some experience with AWS, we still needed to learn the tool since AWS has many different features and none of the members have experience with interactive SMS messaging through AWS.

React Learning Curve: Some team members had to learn or review React and it was important to synchronize the style at which we were coding at which can be to find the right pace within 24 hours.

What we learned

First and foremost, working and building team synchronization within 24 hours is very important but also very difficult in the short time period. Planning a little more ahead of time to divide the workflow and understanding the team‚Äôs dynamic will make it easier when reaching the actual hackathon. We need effective project management in allocating resources and prioritizing tasks to maximize productivity and overcome challenges. Synchronizing our downloads for PropelAuth and React was really important to make sure our codes were doing the same thing.

Also, on the technical aspect, we had to work around and learn about the tools we were using and a lot of debugging was done while working together on live share coding as well as working on different branches of code and pushing and pulling on GitHub. It was really important to know what each of us were doing on the code as soon as possible to create a continuous working environment.

What's next for Aggie House Volunteer Portal

Moving forward, our focus will be on making the backend functionality of the portal. This includes completing the integration of PropelAuth for user authentication so both the volunteer and administrator can have their accounts and purpose. Implementing the AWS in full and preparing what will be sent through the portal to phone messaging. We would also have to implement a way to use PropelAuth within our website rather than just using their login/signup page so the design follows through. With dedicated time and effort, we are confident in delivering a fully functional and efficient volunteer management platform for Aggie House.
","https://github.com/kalechip22/the-barn, https://www.figma.com/proto/mj0NOwBDa2ZyvPpLmex6nP/HackDavis-2024?type=design&node-id=30-77&t=nI5mJesJvX1jQJJx-1&scaling=contain&page-id=30%3A20&starting-point-node-id=30%3A77&mode=design",https://youtu.be/SXgRsS7Q948,"Best UI/UX Prototyping, Best Overall Design, Best Use of PropelAuth, Best Hack for AggieHouse","react, propelauth, amazon-web-services, javascript, css",Emily,Loh,ejxloh@ucdavis.edu,,Best Hack for AggieHouse,Best Overall Design,Best UI/UX Prototyping,University of California - Davis,3,Jillian,Lim,ajlim@ucdavis.edu
Aggie Hub,99,https://hackdavis-2024.devpost.com/submissions/511037-aggie-hub,Submitted (Gallery/Visible),Pending,Submit,04/28/2024 04:06:48,"Inspiration

The inspiration behind Aggie Hub stems from our own experiences as students navigating the bustling campus life at UC Davis. We observed firsthand the struggle many of our peers faced in filtering through the multitude of events to find those that truly resonated with their interests and passions. The overwhelming array of activities both on campus and in the surrounding Davis area often left students feeling lost in the sea of options. Additionally, we noticed the significant challenge clubs and organizations encountered in effectively advertising their events, resulting in low attendance and limited visibility. Motivated by these observations, we set out to create Aggie Hub, a solution designed to simplify event discovery for students and bridge the gap between clubs and their potential attendees. All of the events for students are filtered as per the their preferences and put in one centralized ""for you"" page. Our goal is to empower students to pursue their interests and find their community while ensuring that every event receives the attention and participation it deserves.

What it does

Aggie Hub is dedicated to connecting UC Davis students with events that match their interests, both on and near campus. Our app ensures personalized event recommendations by first authenticating students through their school email and password, confirming their status as UC Davis students. Upon login, students are prompted to answer a series of questions about their likes, hobbies, personality traits, major, and current classes. This information allows Aggie Hub to tailor event suggestions to each student's preferences and schedule. Additionally, the app provides a platform for both students and clubs to post events, with customizable filters to target the right audience. By facilitating this personalized approach, Aggie Hub fosters a vibrant campus community where students can easily discover and engage with events that resonate with them.

How we built it

To create Aggie Hub, we're using Swift for the frontend and Firebase for the backend. Swift ensures a smooth user experience, while Firebase provides a reliable infrastructure. Due to time constraints, we've focused on building a prototype using Justinmind for rapid iteration. This approach allows us to gather feedback and refine our ideas efficiently, moving us closer to our goal of revolutionizing event discovery for UC Davis students.

Challenges we ran into

Crafting an app to cater to the social needs of UC Davis students was a big task. We aimed to create a platform where students could easily connect with others who shared their interests and personalities, fostering genuine friendships. However, as we dove into development, we realized that our grand vision had to be scaled back due to time and resource limitations. We had to refocus our efforts on one core aspect: helping students find events and organizations on campus based on their interests. This shift required some tough decisions and careful planning to ensure our app could still make a meaningful impact. Despite the challenges, our team remained determined and innovative, pushing forward to create a solution that stays true to our original goal while adapting to the constraints we faced.

Accomplishments that we're proud of

We are proud of our accomplishment in pivoting our app's development journey. Transitioning from a broad, multi-feature concept to focusing on a specific task was a challenging. Despite the time constraints, we managed to streamline our vision and create a base prototype that exemplifies our core objective. We had to be adaptable, creative, and committed to delivering a valuable solution to UC Davis students.

What we learned

Our journey taught us some key lessons about teamwork. We learned that reaching our final prototype required us to face many challenges and make a lot of mistakes along the way. Each setback was a chance for us to learn and improve. We also realized the importance of being adaptable and realistic about our time constraints. We had to be practical about what we could achieve in the time we had. Moving forward, we know we need to strike a balance between our ambitions and what's feasible, staying flexible while keeping our project's limitations in mind.

What's next for Aggie Hub

Looking ahead, our next step for Aggie Hub is to bring our prototype example to life by building and deploying the app. We're excited to move from concept to reality and provide UC Davis students with a valuable tool for connecting with their community. In addition to our core feature of personalized event recommendations, we aim to enhance the app by incorporating features that leverage students' preferences and personality types to facilitate meaningful connections. We envision a platform where students can find and connect with others who share their interests and traits, fostering friendships. Furthermore, we plan to implement a scheduling feature that allows students to upload their schedules, enabling the app to suggest events based on their availability. By combining personalized recommendations with scheduling capabilities, we strive to make event discovery not only tailored but also practical and convenient for our users. With these exciting developments on the horizon, we're eager to continue our journey towards creating a vibrant and inclusive community on campus through Aggie Hub.
",,,"Best UI/UX Prototyping, Best Overall Design","swift, firebase, justinmind",Logain,Abdelhafiz,logain.gharib@gmail.com,,Best Overall Design,Best UI/UX Prototyping,Best Interdisciplinary Hack,"University of California - Davis, Moorpark College",3,Shredder,Muzoglu,adamuzoglu@gmail.com
Volunteer Hub,105,https://hackdavis-2024.devpost.com/submissions/511045-volunteer-hub,Submitted (Gallery/Visible),Pending,Submit,04/28/2024 04:33:22,"Inspiration

Driven by our passion for community service, we were frustrated by the challenge of consistently finding volunteering opportunities due to the scattered nature of event information across various organizations.

What it does

VolunteerHub serves as a seamless mobile solution, empowering users to effortlessly sign up for events while enabling organizations to efficiently post their events and opportunities. 

How we built it

Leveraging SwiftUI for the frontend, we crafted an intuitive user interface that ensures a delightful experience. Our backend, built with Objective-C, features a robust database architecture powered by CoreData, providing secure and efficient user authentication and user data storage.

Challenges we ran into

As newcomers at our first hackathon, mastering SwiftUI in a short span was a daunting task. Constructing the backend database and implementing user authentication from scratch required intense effort. Despite encountering prolonged debugging sessions, the journey was rewarding, brimming with learning experiences. We also ran into plenty of problems with GitHub. Some members of our team were unable to commit and push because of account authorization issues so oftentimes during the event not all of us could be working at once. 

Accomplishments that we're proud of

Amidst countless trials and errors, we achieved the remarkable feat of delivering a fully functional and polished mobile application ready for submission.

What we learned

The intensive 24-hour sprint taught us not only the intricacies of SwiftUI and Objective-C but also the invaluable lessons of perseverance and collaboration in the face of challenges.

What's next for Volunteer Hub

With a solid foundation in place, our focus shifts to incorporating user feedback to enrich the application further. Our ultimate goal is to launch VolunteerHub as the go-to platform for volunteering opportunities, fostering stronger community engagement.
",,https://www.youtube.com/watch?v=DMyH9YHG64A,"Best Beginner Hack, Best Overall Design, Best Entrepreneurship Hack, Best Hack for AggieHouse","swift, objective-c",DzinhP,Pham,phamdzinh@gmail.com,,Best Beginner Hack,Best Hack for Social Justice,Best Overall Design,"University of California - Berkeley, University of California - Santa Cruz",2,Ben Hoang,Pham,benpham0707@berkeley.edu
Davis Community Meals & Housing,98,https://hackdavis-2024.devpost.com/submissions/511053-davis-community-meals-housing,Submitted (Gallery/Visible),Pending,Submit,04/28/2024 04:57:59,"What's the problem?

After conducting research and discussing with DCMH's Tracy Fauver, we found that the current DCMH brand and website design was not ""user-friendly"" and was very ""outdated"". 

DCMH requested a redesign that reflected ""kindness"", ""compassion"", and ""community"", while appealing to two main audiences: individuals who are seeking support (through shelter and/or meals) and donors. 

The Logo Redesign

We simplified the logo to reflect housing elements, as DCMH's goal is to emphasize their shelter-providing services. We incorporated blue and pink to evoke a sense of trustworthiness, safety, and human kindness. 

The Website Redesign

We simplified the website by condensing information and providing clear overviews of DCMH's different programs and how they address different needs. We also emphasized call-to-actions to encourage people to seek help and contact DCMH if they need support, and also to encourage people to donate money or items to the organization. 
",https://www.figma.com/proto/CLZpf3GhcN9mwoA0jFegZ6/hacking-2024?page-id=0%3A1&type=design&node-id=55-1131&viewport=2427%2C-4291%2C0.39&t=GhWfCWOHl0zUD3xt-1&scaling=min-zoom&starting-point-node-id=55%3A1131&mode=design,,"Best UI/UX Prototyping, Best Overall Design, Best User Research, Best Hack for DCMH",figma,Kaitlyn,Lam,kylam@ucdavis.edu,,Best Hack for DCMH,Best Overall Design,Best UI/UX Prototyping,University of California - Davis,2,Winnie,Sich,wsich@ucdavis.edu
SoundSoothed,78,https://hackdavis-2024.devpost.com/submissions/511056-soundsoothed,Submitted (Gallery/Visible),Pending,Submit,04/28/2024 05:01:17,"Inspiration & Origin üé∂üå±

SoundSoothe was conceived from a deep love for music and an insight into its transformative power. Recognizing music as a responsive ally, we created a platform that tailors musical experiences to individual emotional states, aiming to provide comfort and uplift well-being through personalized soundscapes.

What SoundSoothe Does üöÄüéß

SoundSoothe listens to your voice, deciphers your emotional and musical needs, and responds with a tailored music experience. Here's the process:


Voice Interaction: Users verbalize their current mood or desired music.
Speech to Text: This audio input is processed using VertexAI to convert spoken words into text.
Understanding Intent: Gemini is employed to interpret these texts and formulate precise music generation prompts.
Generating Music: Utilizing Meta's open-sourced musicGen model, run locally via a Flask API, the system crafts music based on the prompts.
In essence, SoundSoothe delivers the perfect tune for your mood, precisely when you need it.


Construction of SoundSoothe üîßüíª

Our tech framework includes: Meta AI's musicGen and audioGen models, utilized for generating music and processing audio, optimized using Intel's Developer Cloud for peak performance.
VertexAI for robust speech-to-text capabilities, enabling our system to interpret verbal user requests.
Gemini to translate emotional nuances into actionable music generation instructions.
We use Next.js for our dynamic front-end, featuring multiple interactive sections for a comprehensive user engagement.

Challenges Overcome üòµüí™
We navigated through technical challenges related to music generation quality and computational demands, which we mitigated by refining our models and transitioning to more potent computing solutions via Google Compute Engine. These improvements significantly boosted the responsiveness and fidelity of our music outputs.

Proud Achievements üî•‚ú®


Seamless System Integration: Merging complex technologies‚Äîfrom voice recognition to emotional * interpretation to AI-driven music creation‚Äîinto a unified and operational platform.
Innovative Technical Development: Fine-tuning AI models to not only understand but also musically respond to human emotions.
Focus on User Experience: Crafting a Next.js interface that‚Äôs intuitive, engaging, and deeply interactive.


Lessons Learned üß†üìò

This project expanded our expertise in AI applications, cloud technologies, and user-centric design. We explored the depths of AI-driven music synthesis, engaged with cutting-edge NLP and AI tools, and pushed the boundaries of personalized media innovation.

Improvements

As SoundSoothe continues to evolve, enhancing its social impact remains a priority. We plan to expand accessibility by introducing multilingual support, making our app available to diverse linguistic communities and ensuring broader accessibility. Collaborations with mental health organizations will integrate SoundSoothe into therapeutic settings, leveraging personalized music therapy to aid individuals dealing with stress, anxiety, and depression. Additionally, we aim to deploy SoundSoothe in educational environments, particularly in low-income areas, to help students manage stress and improve concentration through calming music. Finally, developing a community-driven platform will allow users to share their therapeutic music experiences, fostering emotional support and enabling crowd-sourced feedback to refine the music generation process. These steps will demonstrate the transformative potential of AI in enhancing societal well-being.
",,https://www.youtube.com/watch?v=6b4XP0T4OGg,"Best Interdisciplinary Hack, Best Health Hack, Best AI/ML Hack, Best use of Intel¬Æ Developer Cloud","next.js, python, ai, large-language-models, multimodal-ai, meta, musicgen, google-compute-engine",Andrew,Kuang,andrewkuang11@gmail.com,,Best Health Hack,Best AI/ML Hack,Best Interdisciplinary Hack,"University of California - Davis, Sacranento City College, Canyon Crest Academy",3,Alexander,Le,league.cynosure3@gmail.com
Bridge,96,https://hackdavis-2024.devpost.com/submissions/511063-bridge,Submitted (Gallery/Visible),Pending,Submit,04/28/2024 05:19:25,"Inspiration

Our group was inspired to create Bridge after noticing that many of our friends and fellow students (us included) feel that we do not keep in touch with our parents enough in college. We miss them a lot, but because of our busy schedules and their busy schedules, it's often hard to find time to call or update them as much as we want. We can keep in touch with our friends and see what they're up to through social media, but it's not common for parents to use social media. Additionally, the major social media platforms today may not be as user friendly towards our parents' generations as they are towards ours. There are no apps out there geared toward increasing interactions between parents and their children, so we hope to ‚ú®bridge‚ú® that gap:)

What it does

Bridge's main page is a thread shared exclusively between you and your parents. There are three main features you can use; post messages, post pictures, and post voice memos. Bridge will give a daily prompt for both kids and parents to follow. The prompt will require you to answer it with one of three methods: a text message, a voice message, or an image. The rest of the app will lock down until the prompt is completed within the hour to entice the user to actually follow it (similar to BeReal). Prompt examples could be ""share a picture of what you ate today"" or ""share your favorite recipe recently"".

How we built it

The frontend is created with React Native and Expo. The backend was created with Firebase.

Challenges we ran into

We ran into issues trying to merge the backend and frontend together. Also one of our team members spilled a $9 double torture from Dutch bros that we had to clean up

Accomplishments that we're proud of

For 3/4 of our team, this was our first hackathon, so it was a really fun learning process!

What we learned

We learned how to use React Native and for some of our team members, it was also their first time working on fullstack development. 

What's next for Bridge

We thought about making a thread for extended family as well. That could be something we implement next.
",https://github.com/slothcoder21/bridge,,,"react-native, firebase",amber,Zhang,amber.zhang321@gmail.com,,Most Creative Hack,Best User Research,Best Hack for Social Justice,"University of California - Davis, University of California - Berkeley, San Jose State University",3,Adrian,Lam,adrianlam2003@gmail.com
Untitled,,,Draft,Pending,Manage team,04/28/2024 05:29:39,,,,,,Nicholas,Chan,nicchan@ucdavis.edu,,,,Hacker's Choice Award,University of California - Davis,0,,,
Aggie Collab,58,https://hackdavis-2024.devpost.com/submissions/511115-aggie-collab,Submitted (Gallery/Visible),Pending,Submit,04/28/2024 07:51:11,"Inspiration

Our passion for community service and technology inspired us to create ""Swipe for a Cause."" Recognizing the gap between potential volunteers and local organizations, we aimed to simplify and gamify the process of finding volunteer work, making it as engaging as using a popular social app.

What it does

""Swipe for a Cause"" is a volunteer matching platform where users input their interests to find local volunteering opportunities. On our platform, users can swipe right to accept or left to reject opportunities, streamlining the process of connecting with causes they care about.

How we built it

We developed the platform using Flask and SQLAlchemy for the backend, with Python managing server-side logic. Our frontend integrates HTML, CSS, and JavaScript to create a responsive and intuitive user interface. We focused on seamless integration between the frontend and backend to ensure smooth functionality, particularly for the swiping feature.

Challenges we ran into

Implementing a responsive and reliable swipe feature presented significant challenges, requiring us to optimize JavaScript and enhance database interactions for quick response times. Additionally, ensuring data security, especially with personal information like interests and locations, was crucial and demanded strict security practices in our Flask application.

Accomplishments that we're proud of

We are particularly proud of creating a functional and visually appealing platform that truly simplifies the process of finding volunteer opportunities. Our success in implementing a swipe feature similar to those found in popular apps stands out as a testament to our team's problem-solving and development skills.

What we learned

This project deepened our understanding of full-stack development, from managing databases with SQLAlchemy to creating dynamic interfaces with JavaScript. We also learned valuable lessons in UI/UX design, ensuring that user interactions are intuitive and enjoyable.

What's next for Aggie Collab

Looking forward, we plan to expand ""Swipe for a Cause"" by incorporating more personalized matching algorithms, enhancing user profiles for better customization, and building partnerships with a wider range of volunteer organizations to increase the diversity of opportunities available.
",https://github.com/TriNguyen360/DavisHacks,https://youtu.be/2g-2pebBzAw,"Best Beginner Hack, 	Best Hack for Social Justice, Most Creative Hack, Best UI/UX Prototyping, Best Overall Design, Best Hack for AggieHouse","flask, python, sqlalchemy, javascript, html5, css",Brian,Huang,brian.yao.huang@gmail.com,,Best Beginner Hack,Best Hack for AggieHouse,Best Hack for Social Justice,University of California - Davis,3,Tri,Nguyen,ng.tri360@gmail.com
Pantry Patrol,80,https://hackdavis-2024.devpost.com/submissions/511117-pantry-patrol,Submitted (Gallery/Visible),Pending,Submit,04/28/2024 08:10:35,"Inspiration

Before the hackathon started, we really struggled to decide on a specific project. With so many ideas and technologies, we just weren't sure what to develop.

However, we were able to talk to an individual representing Davis Community Meals & Housing (DCMH) and inquire about their initial application ideas. From there, we ideated, discussing potential new features and ultimately, we decided on our project: Pantry Patrol.

What it does

Pantry Patrol is an inventory management application designed specifically for DCMH's specifications. They wanted an application that facilitated inventory management to assist with managing donations that came in. Additionally, they wanted a user interface that allowed individuals to understand what products they had on their ""wish list"" and the number of such products, such that potential donors don't ""over-donate"" on certain products.

Pantry Patrol handles all of this and MORE. For example, one of the priorities of DCMH was being reachable to donors and incentivizing donations. To account for this, we added an email blast feature that emails individuals subscribed to the organization's mailing list, such that they would periodically receive assistance emails when products are low in stock. This way, donors are hopefully more inclined to donate to the organization as they are being reached out to directly.

How we built it

We deployed a NextJS application, written in Typescript and styled using Tailwind, DaisyUI, ShadCN, and Aceternity. We strove to have a beautiful, yet intuitive UI for the members at DCMH to manage inventory easily using a visually appealing application.

To handle authentication, we utilized PropelAuth. Initially, we were super skeptical of the service because, at past hackathons, we used solutions like Auth0. However, as our team read PropelAuth's documentation, we realized that PropelAuth was intuitive and a strong provider of authentication services, despite being so new to us. We employed PropelAuth to create admin roles, and quickly set up authenticated routes, and admin-based actions and pages; this efficiency came largely due to using PropelAuth's services.

Finally, to store data (inventory data), we created a cluster on MongoDB Atlas and easily handled CRUD operations to this cloud database using the Prisma ORM and, occasionally, MongoDB Compass.

Challenges we ran into

Initially, we had trouble envisioning what we wanted the application to look like. With so many public UI libraries and CSS frameworks, we realized we could take millions of directions to design and style our application. Ultimately, we chose to blend various components from different libraries. However, this would lead to some issues in styling across different devices.

Accomplishments that we're proud of

We're truly proud to have created a solution for DCMH; it's an organization whose message and ideals we truly stand behind, and to create an application that we believe could help them means a lot to us. Prior to the hackathon, we directly spoke to representatives of DCMH as to how we could implement our application to cater to their specific use case; thus, many of the completed features, including ""real-time inventory updates"", were taken directly from feedback by DCMH. We wanted to design a fully-fledged application FOR the organization; we're happy to have accomplished that at HackDavis. 

What we learned

We learned that sometimes, AI doesn't fit in an application. One of our group members spent hours trying to figure out how to train and integrate an LLM-based chatbot into our application. After spending these hours, however, we realized that the chatbot truly just didn't align with the direction and purpose of the application. As with many applications, an inventory management application doesn't need AI, and simply forcing it into the applications doesn't make the application better. We realized that our ""integration"" of a chatbot didn't make sense with what DCMH wanted, so we geared our efforts away from AI.

What's next for Pantry Patrol

We'd like to communicate with DCMH to see how plausible our application is in their efforts.
","https://github.com/Luceium/Homelessness, https://www.pantrypatrol.tech/, https://docs.google.com/presentation/d/1qw-yf7oYVcS5HgtIz-I1GvGdov_5HPGfbvxXsqpBafo/",,"Best User Research, Best Use of .Tech Domain Name, Best Use of PropelAuth, Best Hack for DCMH","next.js, tailwind, aceternity, propelauth, mongodb, prisma, shadcn, resend, typescript, daisyui, bun",Steven,Le,stevenleusa79@yahoo.com,,Best Hack for DCMH,Best Use of PropelAuth,Best User Research,"San Jose State University, Oakland Technical High School",3,Kevin,Huang,kevinzj710@gmail.com
CommunityCache,124,https://hackdavis-2024.devpost.com/submissions/511136-communitycache,Submitted (Gallery/Visible),Pending,Submit,04/28/2024 08:55:32,"Inspiration

We were inspired by Davis Community Meals and Housing's (DCMH) passion and dedication to supporting low-income and unhoused individuals. We understood their problem of not having an inventory tracking system and a transparent way of asking for highly needed donations. To contribute to their mission, we wanted to create an app that helps DCMH organize their inventory and get more donations from community members. 

What it does

Public users or donors see a home page where they can choose to make an online, monetary donation or an in-person, items donation. Types of in-person donations that donors can make are shown in filtered tables because it is important that the shelter does not get too much of one donation and they have enough space to store the donations. The table specifies the item name, the amount still needed, and a link to choose how many items you want to donate to DCMH.

Admin users or DCMH volunteers have a separate page where they can track the inventory of the items at the center and the stock of their inventory is shown to users so they can know exactly how much of each item DCMH needs. Admin also can notify users through email when there are items with a large amount of need.

How we built it

We used MongoDB, Express.js, and Node.js for the backend and React.js and Material UI for the frontend.

Challenges we ran into

We had challenges with thinking of a project idea and streamlining user and admin workflows.

Accomplishments that we're proud of

We're proud that one of our teammates redesigned a logo for DCMH and we were able to make and deploy a working prototype of our app. 

What we learned

We learned that delegating work, communicating, and staying organized is important.

What's next for DCMH Inventory Tracker

Next, we would like to work on adding an about page so donors know who they are donating to, making our page easier to understand for first-time users, and adapting our app to mobile devices. 
","https://github.com/ReehalS/dcmh_hackdavis, https://dcmh-hackdavis.vercel.app/home",https://vimeo.com/940497979?share=copy,"'	Best Hack for Social Justice, Best User Research, Best DEI Hack Sponsored by Fidelity, Best Hack for DCMH","javascript, html, css, mongodb, materialui, react, node.js, express.js",Natalie,Hoang,natalievhoang@gmail.com,,Best Hack for DCMH,Best DEI Hack Sponsored by Fidelity,'	Best Hack for Social Justice,University of California - Davis,3,Kaitlyn,Vo,kqvo@ucdavis.edu
FoodLoop,165,https://hackdavis-2024.devpost.com/submissions/511137-foodloop,Submitted (Gallery/Visible),Pending,Submit,04/28/2024 08:58:48,"Inspiration

We were inspired by some of our members volunteer work where we would pack/deliver extra food from huge supermarkets to people of less fortune(elderly homes, homeless shelters). Beyond this, we want to use technology to address both social and environmental problems, and food insecurity and hunger in local communities shows the disparity between those who have excess food and those who struggle to access nutritious meals. We also considered food waste's environmental impact and contribution to greenhouse gas emissions. FoodLoop has potential for local communities to come together to support each other fostering a sense of solidarity. By witnessing food waste firsthand and volunteering at food banks and shelters, we were inspired to create a platform to help eliminate food waste.

What it does

Our projects enables 3 groups of people to match with eachother to reduce food wastage: Volunteers, Donors, and Receivers. Donors will post about extra food that they have, Receivers will request for that extra food, and Volunteers will help deliver that food between the Donors(which could be supermarkets or just ordinary people with extra food) and Receivers(people of less fortune).

How we built it

We used Next.js and React for the front end alongside Figma for the UI/UX Prototyping and Wireframing. For the backend we used Flask alongside PostgreSQL, OpenCV, and Sockets to communicate with our database of users and food requests alongside helping communicate between people who are giving/deliverying/and receiving food from eachother and making sure that the food is upto good quality.

Challenges we ran into

Integrating the Figma Designs into the front end dynamically while also connecting to the Flask server API.  On the backend we had issues figuring out how to collect good data and train the model and also getting the sockets working in a multi-room type setting alongside persistent usernames and messages(even if 1 client disconnects).

Accomplishments that we're proud of

This was a very ambitious project as we were trying to integrate many technologies that we hadn't used extensively before and managed to pull it off collaboratively to a MVP level with 3 highly technical challenging features. 
On the UX Design end we are proud of getting our Wireframes and over 22 screens designed along with fully functioning high fidelity prototype.
We were able to successfully use Computer Vision to detect damaged poor quality vs clean and packaged high quality food with both video/single capture and user file import pictures of food. 

What's next for FoodLoop

Our main next steps are properly integrating the private messaging groupchat within the website as its base state right now and also fully integrating the food sanitary level classification. Beyond this, we need to fix some bugs that could potentially cause issues for users down the line and expand the technologies used such that they won't fail at a scalable level.
",https://github.com/cpun077/hackdavis24/tree/main,,"Best Interdisciplinary Hack, Best Health Hack, Most Creative Hack, Most Technically Challenging Hack, Best UI/UX Prototyping, Best Overall Design","socket, tcp, opencv, nextjs, javascript, typescript, figma, python, sql, supabase, react, html, css, flask",Lumijek,Lakhotia,lumijekpr@gmail.com,,Most Technically Challenging Hack,Most Creative Hack,Best Interdisciplinary Hack,"De Anza College, University of California - Davis, San Jose State University",3,vthennarasu,,vthennarasu0606@gmail.com
PupPatrol,100,https://hackdavis-2024.devpost.com/submissions/511152-puppatrol,Submitted (Gallery/Visible),Pending,Submit,04/28/2024 09:43:19,"Inspiration

Imagine a world where no pet owner has to endure the heartache of a missing pet. That's the vision behind PupPatrol, a revolutionary mobile application designed to be the ultimate guardian for our beloved furry companions. With PupPatrol, we're not just building an app; we're building peace of mind for millions of pet owners worldwide.

How we built it

To prototype the PupPatrol app, designers collaborated to define its purpose and features, then conducted research to understand user needs and existing solutions. Using Figma, they created wireframes to map out the app's structure and high-fidelity mockups to design its interface. These designs were then turned into interactive prototypes for testing and feedback. Usability testing helped identify areas for improvement, leading to iterative revisions. Through collaboration and iteration, the final design was refined and prepared for development, ensuring the app effectively alerts individuals of missing pets and facilitates their reunion with owners.

Challenges we ran into

One challenge we ran into was thinking about how jurisdiction is required to initiate a pet alert, and also the privacy laws, data protection, and legal authority involved. Our team was also debating over the features that the product would have, and we were able to come to an agreement that everyone was happy with.

Accomplishments that we're proud of

We're proud of the research we did on this project and the visual design of the final product.

What we learned

Our team gleaned valuable insights into the significance of prioritization and communication throughout our collaborative process. By meticulously assessing both strengths and weaknesses, we adeptly assigned tasks, leveraging each team member's competencies to optimize project efficiency. This approach facilitated seamless coordination and enabled us to allocate responsibilities with precision, ensuring a cohesive workflow and maximizing productivity.

What's next for PupPatrol

Our next steps involve several key objectives. Firstly, we will focus on implementing a user-friendly sign-in process, streamlining access to the platform. Following this, we'll develop a system for efficiently collecting comprehensive pet and owner information, crucial for facilitating reunions. Ensuring that notifications are enabled will be paramount to the app's functionality, guaranteeing timely alerts. Additionally, we aim to establish ""Meet Up,"" an innovative feature designed to foster community engagement. This feature will serve as a platform for organizing pet and owner gatherings in local parks, enhancing social interaction and further solidifying community ties. Through these initiatives, we aim to enhance the PupPatrol experience, effectively connecting pets with their owners while fostering a sense of community among users.
","https://www.figma.com/proto/9rJZN1WINChJLezEVSIsjm/HackDavis?type=design&node-id=81-406&t=MudVrM2Kl7m2RKDr-1&scaling=scale-down&page-id=13%3A75&starting-point-node-id=81%3A406&mode=design, https://docs.google.com/presentation/d/1iLg61zpLOHfrpOLW3L3lB6zN5IPRLx94kChnQBpFevo/edit?usp=sharing",,"Best Interdisciplinary Hack, Most Creative Hack, Best UI/UX Prototyping, Best Overall Design, Best User Research, Best Interactive Media Hack, Best Entrepreneurship Hack, Best Hack for Life of Kai",figma,Michelle,Aung,miaung@ucdavis.edu,,Best User Research,Best Overall Design,Best Interdisciplinary Hack,University of California - Davis,3,Sean,Tinio,smtinio@ucdavis.edu
UltraVioletText,129,https://hackdavis-2024.devpost.com/submissions/511167-ultraviolettext,Submitted (Gallery/Visible),Pending,Submit,04/28/2024 10:31:59,"Inspiration
Persuasive language is a 0-day vulnerability that everyone has. When people are aware that someone is trying to influence them, it is easy to step back and process things logically. However, when scrolling social media or reading a news article we consume content in a passive state. During this time persuasive language can exploit the backdoor into our psyche and cause us to form opinions without us even realizing. 
A 2022 NIH study analyzed the ability of social media as a persuasive platform to influence the behavior of young adults aged 18-24. This study concluded that social media was capable of significantly shaping their behavior. We set out to create a tool that can combat this critical vulnerability in the human psyche. 

What it does
    Our tool UVT or Ultra Violet Text is a chrome extension that aims to expand users‚Äô media literacy by highlighting persuasive language. By highlighting persuasive language, we empower our users to consume information responsibly and combat viral misinformation. The extension allows you to change the highlight color to better fit the page and blacklist words to flag them on any webpage. 

How we built it
When a user opens a webpage, our chrome extension immediately tokenizes the DOM using treewalkers and object iterators. Those sentences are then sent to a proxy server using HTTPS since Chrome extensions only allow HTTPS requests. Our proxy server uses ssh tunneling to expose a node with no public IP and forward all uncached sentences to our compute node. Intel Developer Cloud node uses torchserve, a torch-optimized REST server, to efficiently classify all sentences using a RoBERTa model. The proxy server caches the HTTP responses from the compute node and sends a secure HTTPS response to the client extension. Our Chrome Extension highlights potentially persuasive text using cached DOM references. 

Challenges we ran into
    Google Chrome Extensions require all data going in to them to be https when operating on a page fetched with HTTPS, we used Tech.domain, Certbot, and Digital Ocean to create a https proxy server that served as a go between for our extension and classification model. 
    Training set for the classification model had an uneven split of data of 70/30 preventing accurate classification. We trimmed the data set to 50/50.
    Tracking mutations throughout the webpage without overloading the server with requests. The observer would create feedback loops overloading Google Chrome numerous times. 
    Classifying each sentence sequentially lead to many sequential api calls. Rewriting the parsing code to be decoupled from the classification code allowed for batched inference. This reduced the time to process the page and the number of fetch requests by an order of magnitude.

Accomplishments that we're proud of
    We wrote a general purpose, webpage agnostic sentence tokenizer for web pages. This allowed us to group HTML elements on sentence boundaries, organize them into batches for efficient inference and low latency, them modify the DOM to highlight sentences based on the classifier.
    Building a minimally invasive user interface for the highlighting functionality of the chrome extension that parses the DOM recursively with customization.
    Jerry Rigging together an actual backend with only 7$, free software, ssh tunneling, and a lot of work. It was definitely a great learning experience since I'd never worked with any networking, and now I know how to use DNS records, SSL certificates
",https://github.com/townsag/UltraViolet,https://youtu.be/v9rgJgLD8DY,"Best Interdisciplinary Hack, 	Best Hack for Social Justice, Best AI/ML Hack, Best use of Intel¬Æ Developer Cloud, Most Technically Challenging Hack, Best UI/UX Prototyping, Best Overall Design, Best Use of .Tech Domain Name","hopes, dreams, ducttape, javascript, python, intel-developer-services-beta",Devin,Townsend,devin.townsend@sjsu.edu,,Best use of Intel¬Æ Developer Cloud,Most Technically Challenging Hack,Best Interdisciplinary Hack,San Jose State University,3,Ahmad,Gazali,gazali.contact@gmail.com
MƒÅtrƒÅ AI‚Äã,161,https://hackdavis-2024.devpost.com/submissions/511174-matra-ai,Submitted (Gallery/Visible),Pending,Submit,04/28/2024 10:40:32,"Inspiration

We live in a neighborhood where we meet a lot of Spanish Families. the often talked about problem is how kids face the difficulty to learn/understand languages being taught in classroom. One of our teammate was a kinder-garden teacher and he explored this problem, where he taught kids how to enjoy the process of learning the language by reading picture based short stories. We came across this problem back in India as well, where kids wanted to learn the language but didn't have proper resources to learn the right pronunciation which was fun and easy. We identified this problem, that irrespective of where the kids are from, the problem of learning a new language at a quite early age can be challenging. Solving this problem early on, makes the kids become confident orators. We took this as our inspiration to build an application with the current AI technology and make the process easy and fun to the leaders of our future.

What it does

The user selects a book of his favorite choice. The AI reads a sentence and prompts the user to read the next sentence, and the application then compares the audio files of both the actual sentence audio with the correct pronunciation and the one the user spoke, our AI analyzed both files and then gives the result of how correct the pronunciation of the words were. The user can choose any sentence to read and the AI will tell what was wrong with the pronunciation or give a positive feedback and move on to the next sentence.

How we built it

The backend is built using Flask and our beautiful frontend is made in React. The server is powered by chatgpt-3.5-turbo and uses ElevenLabs for Text-To-Speech to bring out the motherly, nurturing and caring voice of Sophia. For Speech-To-Text, we made use of Speechace API to get the statistics on the pronounced sentence by comparing it with actual sentence and this statistic is preprocessed in python and then fed to OpenAI to get response and suggestions on how to pronounce the words which were mispronounced. This response is then again converted into speech using Elevenlabs API for our Sophia to read it. and all of this database is saved in the Supabase

Challenges we ran into

We faced a lot of roadblocks while making this application. One of them being finding the APIs required for our exact use case. Initially, we tried to convert the speech to text and then compare it to actual text but every api auto-corrects the translation and it cannot be compared in terms of text. Fortunately, we found the an API which gives statistics on the pronounced word from the sound of phonetics, stress level, syllables and many more. The backend team was able to pre-process that and feed it to LLM for analysis with actual sentence to get us the suggestions we need for the app. We also faced many other challenges but I guess all we needed was huge load of research and many more shots of espresso.

Accomplishments that we're proud of

We are proud of building an end-to-end application from scratch within the allocated time. 
The application we have built now is far ahead of the existing applications out there. We achieved a human like audio. We learnt a lot about Speech-to-text and all the technologies we used to build, as we all team members were proactive in communicating what has been done and built, so we got a chance to learn each other's tech expertise. 

What we learned

This is our first hackathon ever. We finally were about to build a complete application, made new friends. 
Deciding early on what to work on, what goals and milestones to achieve, helped us divide the tasks. we faced quite a bit challenges, and we are glad we overcame them thanks to the mentors, who are always available to help us. 
Coming to the Technical details, we learned a lot about speech-to-text models, APIs and its integration, as it is overlooked compared to speech-to-text, we wanted to build an AI that sounds calm and  as human as possible. We thank hackdavis for this oppurtunity

What's next for MƒÅtrƒÅ AI‚Äã

We plan to take this product to different parts of the world. As we believe this product is scalable. We plan to include different languages where kids can learn other language pronunciation and from different parts of the world. We plan to build our own AI model to train the speech-to-text and text-to-speech where we can give better voice selection such as user's favorite voice character to read the books and overall accuracy of the analyze the AI does. we also plan to increase our database by including more books for different age group of kids, such as harry potter, the wizard of oz etc. 
",https://www.matraai.tech,,"Best Beginner Hack, 	Best Hack for Social Justice, Most Creative Hack, Best AI/ML Hack, Most Technically Challenging Hack, Best UI/UX Prototyping, Best Overall Design, Best User Research, Best Use of .Tech Domain Name, Best Interactive Media Hack, Best Entrepreneurship Hack, Best Statistical Model","supabase, flask, react, text-to-speech, speech-to-text, openai, elevenlabs, speechace, apis, python, heroku",Harsh Raj,J,harshraj201999@gmail.com,,Best Interactive Media Hack,Best AI/ML Hack,Best Beginner Hack,San Jose State University,3,Sai Naveen,Chanumolu,sainaveen1117@gmail.com
GetResearch,133,https://hackdavis-2024.devpost.com/submissions/511176-getresearch,Submitted (Gallery/Visible),Pending,Submit,04/28/2024 10:47:17,"Inspiration

GetResearch was inspired by our personal experiences as community college students eager to engage in academic research. We encountered numerous obstacles in finding suitable research opportunities‚Äînavigating complex school websites, sifting through outdated project listings, and repeatedly searching for specific research details. We also observed that many capable professors lacked visibility and access to a platform for recruiting team members. These challenges highlighted a gap in the academic research recruitment process that GetResearch aims to fill, making it easier for both students and professors to connect and collaborate on research projects.

What it does

Getresearch serves as a dynamic online platform tailored for academic research collaboration. It efficiently connects students seeking research opportunities with professors looking to recruit team members by: 
Real-Time Updates: Ensures all project listings and professor posts are current and relevant.
Dual Functionality: Allows students to find research projects and professors to post recruitment ads.
Streamlined Application Process: Enables professors to review applications seamlessly and make informed decisions on candidate selection.
Enhanced Visibility: Provides a platform for less renowned professors to gain recognition and attract potential research candidates.

How we built it

We utilized PropelAuth for user authentication and FastAPI for backend development, ensuring robust security. Our frontend was built using React, enhancing user interaction with its dynamic components. The backend was linked to a PostgreSQL database, structured for complex data management. Finally, we deployed the application on an AWS Cloud Server to benefit from its scalable infrastructure and reliable performance. Each technology was pivotal in creating a secure, efficient, and user-friendly application.

Challenges we ran into

In this competition, we encountered several significant challenges. Not every teammate was a computer science major, which meant that we had to find ways to effectively integrate diverse skill sets. Moreover, we faced countless technical issues ranging from database construction to cloud server deployment. The different states between local and remote environments required us to modify our code repeatedly to ensure functionality.

Accomplishments that we're proud of

We are particularly proud of our teamwork and the resilience we demonstrated throughout the competition. Despite the diversity in our academic backgrounds and the technical hurdles we faced, our cooperative efforts enabled the project to recover and improve after each setback. Our ability to resolve these issues and get the project to run perfectly in the end stands as a testament to our dedication and skills.

What we learned

The experience was profoundly educational, not just in terms of technical skills, but also in understanding the importance of perseverance and collaboration. The 24-hour endless testing phases underscored the significance of willpower in overcoming adversity. We also gained practical knowledge in technical areas like database and server management, which are crucial for our future endeavors in technology.

What's next for GetResearch

The future of GetResearch is focused on expanding our capabilities to ensure that we are not only simplifies the recruitment process but also fosters a vibrant academic community, encouraging knowledge sharing and innovation through following enhancements:
Networking Features: We plan to integrate networking functionalities, transforming GetResearch into a research-centric community platform similar to LinkedIn, where users can connect, share, and collaborate beyond mere recruitment.
Academic Information Hub: Aim to incorporate a feature that aggregates valuable academic content and updates, making it a go-to resource for academic news, publications, and events.
Global Expansion: We are looking to scale the platform to include institutions and users from around the globe, facilitating international research collaboration and diversity in academic projects.
Advanced Matching Algorithms: Develop sophisticated algorithms to match students and professors based on research interests, skills, and educational background to optimize team compositions.

Demo Website

GetResearch
","https://github.com/AGDholo/hack-davis, https://github.com/PangYuanbo/research.server, https://github.com/AGDholo/hack-davis-api, https://getresearch.tech",https://youtu.be/3TQtkGRWM0s,"Best UI/UX Prototyping, Best Overall Design, Best User Research, Best Use of .Tech Domain Name, Best Use of PropelAuth","react, python, c#, propelauth, vite, typescript, javascript, html5, css, asp.net, .netcore, techdomain, postgresql, amazon-web-services, fastapi",Aaron,Pang,yuanbopang@gmail.com,,Best UI/UX Prototyping,Best Use of PropelAuth,Best Overall Design,"deanza, De Anza College",3,Ji,Cecilia,ceciliaji6688@gmail.com
Freege Filler,128,https://hackdavis-2024.devpost.com/submissions/511177-freege-filler,Submitted (Gallery/Visible),Pending,Submit,04/28/2024 10:49:05,"Inspiration

Our inspiration stems from the creation of the Freedge, designed to combat food waste and promote food equality for all. This outdoor mini fridge enables community members to donate and receive food at any time. Despite its commendable mission, some may hesitate to use the Freedge due to concerns about the freshness and source of donated food. Common questions include:


How long has the food been stored?
Is it still safe to consume?
What specific items have been donated?
To address these concerns, we proudly introduce Freedge Filler: Elevating Food Accessibility, Convenience, and Equity within Our Community


What it does

Our project has multiple stages that work in cooperation with each other. The first part is the donator side - We want to encourage people to add items to the fridge by using a barcode scanner through a mobile app that anyone can access. Upon scanning an item, we use our simplified analysis of nutrition facts to return a score based on how healthy of the item is. Our system guarantees to award points regardless of type of food it is. 

Upon donating and scanning a food item, a point is added to the user's total score. Therefore, people who frequently donates increases their chance to be on the score leaderboard. When the scanned items get added to the corresponding freedge, any users can view the contents. However, what's displayed on the website might not correspond with what's actually inside these fridges. To address this, we also added a camera that one can use to check to make sure a certain item has not been removed yet. 

How we built it

Camera+Server
This was built using a Python program that uses a cheap web camera to capture an image given a certain framecap. It takes that image, and compresses it to base64 so it can be sent to the backend.

Backend
We use Firebase authentication for the sign-in process, Nest.js for storing real-time data, and Barcode and nutrition API to provide essential nutrition facts.

FrontEnd
We use Flutter framework to develop our solution. It has the ability to develop mobile app, web, and desktop in a single code base.

Challenges we ran into

The greatest challenge in our development was getting our scanner to work. A lot of the scanning API's and libraries were not upheld and therefore had severe version-mismatch problems. Not only that but the APIs for retrieving barcode data usually cost money or did not have a complete database. 

Accomplishments that we're proud of

We are very proud of how well our project integration turned out. From the very start, we had some trouble coming up with a concrete project that would not fall short of our hopes. Though we did not expect to finish all these different aspects, we managed to do so and even have time to add bonus features such as a leaderboard system.

What we learned

As a group, we have learned so much from the past 24 hours, that it's hard to know where to start. Most of our group was not familiar with web dev so creating a multi-device system was unfathomable. Despite this we managed to learn how to integrate the server-client connection with another server, some members learned dart from scratch, and we even figured out how to create a stream-like functionality using image capturing/encoding. 

What's next for Freege Filler

Though we all knew that the extent of what could be achieved was limited by the time restraint, we could not help but think of how we could take this project further. Among those ideas, we thought about improving the API we use to fetch data, an alert feature that would let certain people know when food gets added, and a proximity-based detection to prevent fraudulent uploads. Our current API is a very rudimentary one that works with most-but not all products. Using a more reliable one would yield more accurate data on the nutrition facts as well as allow consistent scanning.  In terms of an alert feature, it could reduce food waste by letting people know they can pick up a certain food. Finally, a large factor at play with projects such as these is public integrity. We can trust the public, but only so much. If we were to start having a reward system for people on the leaderboard we had to guarantee that they would honestly donate. For that reason we though about implementing a proximity-based system that only allows upload when one is within a certain radius of a Freege and a report system for those that scan multiple of the same object. 
",https://github.com/AkshatAdsule/HackDavis2024,,"Best Beginner Hack, 	Best Hack for Social Justice, Most Creative Hack, Best Interactive Media Hack","flutter, firebase, typescript, python",Alexandr,Volkov,avolkov@ucdavis.edu,,Best Hack for Social Justice,Most Creative Hack,Best Beginner Hack,University of California - Davis,2,Akshat,Adsule,akshat.adsule@gmail.com
ReminderSpreadsheet,112,https://hackdavis-2024.devpost.com/submissions/511181-reminderspreadsheet,Submitted (Gallery/Visible),Pending,Submit,04/28/2024 11:02:40,"Inspiration

The inspiration for this project was the prompt for AggieHouse during the opening ceremony of the hackathon.

What it does

It reads data off of the set google spreadsheets and sends automated text messages to volunteers who are signed up for a shift the next day.

How we built it

I built this using google spreadsheets and python.

Challenges we ran into

I ran into issues with the google service account.

Accomplishments that we're proud of

I am proud that this works.

What we learned

I learned that you can do a lot of cool things with google APIs.

What's next for ReminderSpreadsheet

I want to make the spreadsheet more flexible to changes, like allowing for multiple people scheduled at the same time (very important), or allowing for flexible time (currently set to 6:00~21:00)
",https://github.com/ritakura/ReminderSpreadsheet,https://www.youtube.com/watch?v=lsaQ_jxINB0,"Best Interdisciplinary Hack, Most Creative Hack, Best Hack for AggieHouse","python, google-spreadsheets",reina,i,reina.itk@gmail.com,,Best Hack for AggieHouse,Best Interdisciplinary Hack,Most Creative Hack,,0,,,
Untitled,,,Draft,Pending,Manage team,04/28/2024 11:05:28,,,,,,Eustache,Westphal,ewestphal@ucdavis.edu,,,,Best Entrepreneurship Hack,University of California - Davis,0,,,
Unwound,120,https://hackdavis-2024.devpost.com/submissions/511194-unwound,Submitted (Gallery/Visible),Pending,Submit,04/28/2024 11:22:17,"Inspiration

Inspiration to base our application around wounds stemmed from our friend, Eugene. When he got a small wound on his hip, he made an appointment with his doctor. However, it was a whole week away. In the meantime, he had to figure out how to care for his injury himself. With no clue of what his wound even was, he turned to dozens of Google results to finally learn how to treat it. The whole process was time-consuming and he was sure he could make it simpler. Incorporating AI and machine learning we set out to build that solution. 

What it does

Our application comes into play in the case of an accident. When someone gets hurt, they can use our app to quickly figure out the best course of action. Whether it is a minor scrape or a puncture wound, our program will be able to offer advice. 

How we built it

Our application blends React Native and Gifted Chat to display its straightforward and familiar user interface. Langchain provides us with methods to embed our data and provide the most relevant information to the LLM. Google Gemini powers our program‚Äôs chat interaction with the user. 

Challenges we ran into


Our intended database did not allow us to collaborate across devices and was inconsistent when creating our tables.
React Native gave us issues when our project had issues bundling. 
When interacting with the LLM there were issues with importing the required functions.
Our object detection model was not compatible when we were trying to deploy it on mobile devices so we opted to use Onnx instead.


Accomplishments that we're proud of


Creating a functional version of our project idea. 


We learned how to


Utilize RAG to generate responses from custom data.
Use React Native to capture images and upload them to a server.
Use YOLOv5 to detect multiple objects in an image


What's next for Unwound

We plan to make this object detention model run offline, so that users have access even when there is no internet connection. The current model can be polished by filtering the data being embedded. This is to ensure the information is accurate. At the same time, we want to add additional data so that the app can recognize and provide information for a larger scope of injuries.
",https://github.com/EugeneVuong/unwound,,Best Health Hack,"react-native, gifted-chat, langchain, gemini, python, javascript, node.js",Timothy,Do,timothy.dok2004@gmail.com,,Best AI/ML Hack,Most Creative Hack,Best Health Hack,"San Jose State University, California State University - East Bay",3,Eugene,Vuong,vuongeugene@gmail.com
EcoRadius,36,https://hackdavis-2024.devpost.com/submissions/511195-ecoradius,Submitted (Gallery/Visible),Pending,Submit,04/28/2024 11:24:30,"Inspiration

Climate change is an evergrowing problem and our planet is at risk in the very very near future. One way to combat global warming is through recycling by reducing greenhouse gas emissions due to landfills. However, as college students, we generate lots of waste and are sometimes too lazy to properly recycle it. Oftentimes, we can't find a recycling bin nearby and it can be difficult deciding how to properly sort our waste. So, we decided to build an app to ease and incentivize the recycling process on college campuses, aiming to increase global efforts against climate change.

What it does

We devised a prototype that scans your waste and uses a machine-learning model to help you make an informed decision to dispose of it. Furthermore, it will guide you to the nearest and most appropriate disposal site (recycling, compostables, and/or landfill).

How we built it

The application relies on React.js to dynamically render the various frontend components (live camera feed, live interactive map, etc.), and we utilized the Google Maps API to display an interactive map of nearby recycling/waste locations. To create the classification algorithm, we used a pre-trained Convolutional Neural Network (CNN) called MobileNetV2 and we further trained it using PyTorch and Google Colabs on the TrashNet dataset (TrashNet credits: Gary Thung and Mindy Yang, GitHub Repo: https://github.com/garythung/trashnet). Finally, we created a RESTful API using Django Rest Framework to connect our front end to the Python CNN.

Challenges we ran into

We've never used, let alone trained, a machine learning model before. When we came up with the project idea, the model was easily our most intimidating challenge. Luckily, the PyTorch module provides fantastic pre-trained models to choose from. Moreover, we found a fantastic dataset of common recyclable items (paper, plastic, glass, etc.) to train our model. Limited by time and hardware, Google Colab proved essential to quickly increasing the model's accuracy by providing high-end GPU/TPUs through the cloud. Altogether, we learned so much, and we won't forget the excitement we felt the first time it correctly classified one of our recyclable items.

Mapping nearby recycling locations was also difficult, but we created a custom KML (markup for maps) and added 37 recycling locations on campus tagged by types of waste (recycling, compostable, cardboard only, landfill, etc.). React also refused to work with the Google Maps components, but with patience, everything worked out. We resulted in parsing our custom KML file and a library called geolib to compute the nearest distances for the recycling locations and display them to the user.

Accomplishments that we're proud of

We are proud of actually training the model ourselves, rather than only using a pre-trained model, and analyzing its effectiveness using a confusion matrix. Through our training and use of different algorithms, we increased the accuracy from 40% to 73%. We are also proud of the concise code for our app using proper design patterns in React.

What we learned

We already knew a bit of React and Django coming into the competition, but we've never fully integrated a front and backend to make a full-stack application. Battling through the process taught us how to make careful design choices, like choosing the best stack for our use case. One thing we can improve on is time management and using Figma to plan out our UI and functionality rather than building it on the fly.

What's next for EcoRadius

The project was technically challenging for us, so we admit we neglected the UI. Now that we have more time, we want to improve the model's accuracy and train it on more diverse waste data. Finally, we intend to gamify recycling through a point-reward system where colleges can compete against one another. With our efforts, we aim to improve recycling initiatives and reduce waste mismanagement around the globe.
","https://ecoradius.vercel.app/, https://github.com/neil-dandekar/EcoRadius",https://youtu.be/HF3v9JASiaM,"Best Beginner Hack, 	Best Hack for Social Justice, Best AI/ML Hack","django, python, javascript, react, html, css, pytorch, collab, google-maps",Sam,Asbell,samtynanasbell@gmail.com,,Best Beginner Hack,Best Hack for Social Justice,Best AI/ML Hack,"University of California - Davis, Sierra College",1,Neil,Dandekar,neildandekar10@gmail.com
DavisDeals,77,https://hackdavis-2024.devpost.com/submissions/511196-davisdeals,Submitted (Gallery/Visible),Pending,Submit,04/28/2024 11:25:21,"Inspiration

Our story began a couple of months ago on a normal Sunday in Downtown Davis. We were at the nearby Tim's Hawaiian when one of our friends gave us a call, informing us about a special coupon code that could score someone a complimentary meal at a nearby restaurant. Skeptical about whether this was legitimate, we tried it and to our surprise, it was a great success. And as hungry college students, we pounced on the opportunity, ordering a bit more than advised and calling up as many friends as possible to spread the word. 

And that sparked the motivation for our project.

In Davis, food deals are not often available online, usually only noticed in person and sometimes through word of mouth. Noticing this massive issue as the day of the Hackathon approached,  our goal was to bridge this gap in knowledge, and DavisDeals was born. 

DavisDeals is an application that is accessible to students and businesses. Students are easily able to see and post to trending and popular deals. On the other hand, businesses can also post their deals for students to see, allowing them to gather data and insights on what works best. 

What it does

DavisDeals helps connect students with local food vendors, finding discounts, sales, specials, and more. It provides both a deal and a map page, where the user can view different deals at different locations.

How we built it

DavisDeals was developed as a full-stack application using Flutter, providing cross-platform functionality for Desktop, Android, and iOS environments. Firebase was employed as the backend solution, enabling real-time data storage and the ability for login authentication.

Challenges we ran into

We all ran into many, many, many challenges trying to learn full-stack development and Flutter for the first time. It was a struggle. Several members had not used JavaScript, and we worked day and night, sometimes to no avail, to try and make any progress.

Accomplishments that we're proud of

We are proud of the coding we learned along the way... a very bumpy way. Our teamwork, dedication, and work ethic helped us push through, even despite a lack of sleep

What we learned

We learned a lot about how full-stack development works, especially how rewarding it can be despite how hard it is.

What's next for DavisDeals

We hope to be able to develop our prototype into a fully-fledged application, increasing its functionality by adding more features for both businesses and students to use.
",https://github.com/leon-tanguay/HackDavis2024,,"Best UI/UX Prototyping, Best Entrepreneurship Hack","flutter, javascript, firebase, sqlite",Leon,Tanguay,lttanguay@ucdavis.edu,,Best Entrepreneurship Hack,Best UI/UX Prototyping,Best Hack for California GovOps Agency,University of California - Davis,3,Nicholas,Chan,nicchan@ucdavis.edu
CliQ,130,https://hackdavis-2024.devpost.com/submissions/511198-cliq,Submitted (Gallery/Visible),Pending,Submit,04/28/2024 11:27:36,"Inspiration

The inspiration behind CliQ emerged from the growing misinformation related to climate change. As inaccurate and misleading information about the environment became increasingly prevalent, the need for a reliable, scientifically-grounded source of weather data became clear. CliQ was developed to address this challenge by utilizing cutting-edge AI and statistical methods to provide users with the most accurate and up-to-date weather information. This platform aims to enhance everyday decision-making regarding weather conditions and fosters a better understanding of climate trends, empowering people to take informed actions in response to environmental changes. CliQ also focuses on transforming complex weather data into understandable insights for its users. By simplifying sophisticated data into user-friendly information, CliQ helps individuals make informed decisions based on reliable and accessible weather data and forecasts.

What it does

CliQ is a search engine that harnesses advanced artificial intelligence and statistical analysis methods to ensure that the most accurate numerical weather information is provided to its users. CliQ has an improved rate of accuracy than large language models like ChatGPT since it uses statistical testing in addition to artificial intelligence which ensures that the data given to the user is accurate. ChatGPT is more prone to hallucinations which makes it difficult to get accurate numerical data contrary to CliQ.
CliQ offers deep insights into long-term climate trends and plays a pivotal role in educating the public about the broader implications of climate change. This understanding is vital for developing strategies for mitigation and adaptation in response to ongoing environmental transformations in our world.

Furthermore, CliQ is dedicated to transforming intricate and often inaccessible weather data into straightforward, easy-to-understand insights. This makes CliQ especially valuable to users who may not have a background in science or data analysis but need to understand the implications of weather patterns and climate change on their lives. The platform's user-friendly interface ensures that complex information is presented in a clear, concise, and actionable format.

How we built it

We use Chat-GPT to analyze questions from users to understand what would be the best hypothesis testing for their questions. From there we run the chosen test and ask Chat-GPT to summarize the data that we've calculated for the user. 

Challenges we ran into

One of the major issues we ran into dealt with providing the correct prompts to pass in order to parse the correct value. We resolved this by hyper-specifying the format we desired. Secondly, it was difficult ensuring that the test were actually producing values that were accurate and worth reviewing. 

Accomplishments that we're proud of

We are proud of our ability to integrate each of our components. We were all capable of easily switching through rotations given our good version control practices and communication. 

What we learned

Our team learned more in depth how to build frontends using python and Reflex. In addition, how to use the ChatGPT's language model. It was also a good review of statistics and its application. 

What's next for CliQ

Ideally, this can be extrapolated out to larger and more datasets which could encompass various fields of research. In addition, different statistical testing can be done in order to provide more accurate answers for testing. We would also like to use more academic and source based LLM's to better fit the needs of researchers and students. 
",https://github.com/oderanwosu/aniq.git,,"Most Creative Hack, Best AI/ML Hack, Most Technically Challenging Hack, Best Statistical Model","python, reflex, chatgpt, matplot",Odera,Nwosu,oderanwosu.j@gmail.com,,Best Statistical Model,Best AI/ML Hack,Most Creative Hack,San Francisco State University,3,Shriya,Dandin,sdandin03@gmail.com
Cozy Doggo Day,45,https://hackdavis-2024.devpost.com/submissions/511205-cozy-doggo-day,Submitted (Gallery/Visible),Pending,Submit,04/28/2024 11:47:59,"Inspiration

Cozy pet care games that one can play to decrease stress!

What it does

You take care of a virtual pet. Bathe, feed and play with the dog!

How I built it

I used HTML, CSS and JavaScript to make a website game.

Challenges I ran into

As a beginner programmer, I faced challenges in animating the pet 

Accomplishments that  proud of

Being able to successfully create a website that is functional and fun!

What I learned

Lots of animation,  UI and general programming

What's next for Cozy Doggo Day

Programming more dogs and expanding the activities you can do!
",https://a9afcbd5-9154-4a25-a23b-e9b068222d92-00-2oj8daqajcfqu.worf.replit.dev/,,"Best Beginner Hack, Best Interdisciplinary Hack, Best Health Hack, Most Creative Hack, Best UI/UX Prototyping, Best Overall Design, Best User Research, Best DEI Hack Sponsored by Fidelity, Sauce Labs Raffle, Best Interactive Media Hack, Best Hack for Life of Kai","html, javascript, css",AparnaChatter,Chatterjee,chatterjeeaparna007@gmail.com,,Best Beginner Hack,Best Interdisciplinary Hack,Best Health Hack,,0,,,
PawPal,16,https://hackdavis-2024.devpost.com/submissions/511206-pawpal,Submitted (Gallery/Visible),Pending,Submit,04/28/2024 11:48:29,"Inspiration

We were inspired by Amber Alerts and wanted to implement and improve the lost pet finding process while encouraging community interactions. Currently, ‚ÄòThe Life of Kai‚Äô relies on a manually made map that the organization creates when a pet is lost. New sightings of the lost pet are manually added to the map while community members are encouraged to utilize other applications to help locate their lost pets. For HackDavis, we wanted to combine all of these steps and processes into one convenient application, PawPal. 

What it does

PawPal is a mobile application that utilizes community efforts to help locate lost pets. The user is able to create profiles of their pets and is able to interact with other app users through discussion posts and community forums. When a lost pet is reported, other users are alerted nearby are alerted and encouraged to report any sightings.

How we built it

We build our project using Figma for the mobile interface. We incorporated ‚ÄòThe Life of Kai‚Äôs‚Äô existing color scheme of yellow and teal from their website to uphold the organization‚Äôs brand. HTML was used to code the backend with the geo-locater and time stamp marker. A Google Maps API was used along with multiple API libraries, like Directions API and Geocoding API, to create routes and implement map functions. 

Challenges we ran into

Implementing the Google Cloud API was very confusing for me since the time marker function and geocode function required additional libraries that I was not aware of. I also had to worry about key restrictions while still allowing the API to work. 
Originally, I wanted to use Python to simulate the process of creating a user profile. However over time, I realized that I did not know how to combine Python and Figma into one cohesive application. We ultimately compromised by creating a Figma representation of a user profile.
When designing the Figma interface, we wanted to include several features that we did not explicitly know how to implement, like the alerts function and prototype. The design mentors were very helpful in guiding and providing feedback on our interface. 

Accomplishments that we're proud of

We are proud of our hard work and determination to create a user friendly and accessible application that interweaves community engagement and interactions. The map and community forum features are our personal favorites especially since we feel like it closely aligns with the brands' problem statement. We are very proud of our team and our product. 

What we learned

We were able to improve upon our coding knowledge, especially in HTML. As Python coders, front end HTML was a completely different side of coding, but we were able utilize mentors and online resources to successfully implement the HTML. Through implementing many features in our Figma prototype, we were able to improve as Figma designers and push our creative boundaries. We also learned more about each other and grew closer as a team and as friends :)!

What's next for Paw Pal

Implementing the rest of the frames which include chatting with other pet owners, being able to post questions, adding more information about shelters. 
","https://www.figma.com/proto/8v1PP3ey05JLaeT9e48uyN/life-of-kai-app?page-id=1%3A9&type=design&node-id=8-1476&viewport=364%2C423%2C0.28&t=DXwiwxt6RXlRJiCy-1&scaling=scale-down&starting-point-node-id=8%3A1476&show-proto-sidebar=1&mode=design, https://github.com/btntran/Paw-Pals",,"Best Interdisciplinary Hack, Best User Research, Best Entrepreneurship Hack, Best Hack for Life of Kai","html, figma, api, google-maps",Michelle,L.,mxsliu@ucdavis.edu,,Best Hack for Life of Kai,Best Entrepreneurship Hack,Best Interdisciplinary Hack,University of California - Davis,3,Linh-dan,Nguyen,hlnnguyen@ucdavis.edu
Recycle Me,76,https://hackdavis-2024.devpost.com/submissions/511208-recycle-me,Submitted (Gallery/Visible),Pending,Submit,04/28/2024 11:50:21,"Inspiration

I work as a barista and my store has a three-compartment garbage: recycling, compost, and waste. Every day I see people struggle with what goes where, a decision that seems like everyone should be confident in (I wasn't before making this game). The goal of my game, Recycle Me! is not only to make people more aware of what is recyclable and compostable but also to get them in the habit of throwing them in the right bins.

What it does

It is a video game that teaches the player where to throw compost recycling and trash! I intentionally made the game fast paced because I feel like fast-paced association aids in a person‚Äôs recollection when they're not under the pressure of getting a high score. The game has a loop, with an increasing difficulty the further they get, random number generation for replayability, and a scoring system. 

How I built it

I built the project in Unity, I imported Unities StarterAssets for a third person controller to get a baseline. I imported a cute simple small character and rigged it to fit the StarterAssets one. I then built my own stage using a city assets and a floating island asset. I built the bins using 3D flattened out cube shapes with their own collisionshapes, materials, etc. I also included a feature to make the lids close slowly every x amount of seconds, where x is based on a random value from 10-40. I created a playercontrollerextended script to handle more player controls, I created a characterheadcollision script to handle items crushing the player. One of my most robust scripts is the PickupObject script which handles all the logic for picking up, throwing, projecting trajectory of items. I created a killplane to destroy objects that fall off the map. I designed all of the UI for my game, including a credits and controls screen, title screen, all the buttons, etc. I also had to implement many other prefabs and scripts.

Challenges I ran into

The main challenge would have to be managing the time as a solo developer on a 24 hour hackathon. This was my first Hackathon and I was not sure what to expect, if I could even accomplish anything. I ended up blowing through my expectations and being highly productive. But the biggest challenge was having to create menus, scenes, and set up prefabs by myself. A lot of game development is super time consuming, and it can be extremely stressful working on it alone.

Accomplishments that I am proud of

I am really proud of myself for being able to complete a fun engaging game with a good social cause in 24 hours. Coming into this Hackathon, I was challenging myself to see if I could do it, and to have done it AND be proud of it is all I really wanted.

What I learned

I learned that I am capable of more than I expected when it comes to hackathons. I had no idea that I could lock in and code for 16 hours straight and 8 hours on and off without going insane.

What's next for Recycle Me

I plan on pushing more updates in the future, it is a really fun game and great concept and I am already thinking on future potential expansions for the game. I want to add more items from each category and implement a more robust complex algorithm for the difficulty curve.
","https://ikedyike.itch.io/recycle-me, https://ikedyike.itch.io/, https://github.com/ikedyike/Recycle-Me",https://www.youtube.com/watch?v=OC6Q8ofiM10&t=6s&ab_channel=IKE,"Best Beginner Hack, Most Creative Hack, Best Interactive Media Hack, Best Entrepreneurship Hack","c#, unity, webgl, shaderlab",Isaac,Craig,iccraig@ucdavis.edu,,Best Beginner Hack,Most Creative Hack,Best Interactive Media Hack,University of California - Davis,0,,,
"Nutra - Be Aware, Handle with Care: Pesticide Safety First",74,https://hackdavis-2024.devpost.com/submissions/511210-nutra-be-aware-handle-with-care-pesticide-safety-first,Submitted (Gallery/Visible),Pending,Submit,04/28/2024 11:54:27,"Inspiration

It has long been known that pesticides on food can cause problematic health outcomes for those who consume them. However, fewer people realize that the same rationale applies to the farmers who use them. As a team composed of agricultural enthusiasts, with some having direct ties to these communities, we know firsthand the impact of the use of these chemicals on farmers. Research from the National Institute of Health has also strongly linked several forms of cancer and neurological conditions to farmers due to their prolonged exposure to chemicals such as Chlorpyrifos (which was recently banned). Notably, increased risks have been identified for non-Hodgkin lymphoma, leukemia, and prostate cancer. With Nutra, we hope to mitigate this insidious part of the agriculture production pipeline by giving farmers a precise estimate of how much pesticides in tons they need for their crops, bringing more certainty to a process that many once considered an art form. 

What it does and how we build it

Nutra is an iOS application built to empower farmers with precision agriculture to give them estimates of the amount of pesticides they need for a given crop yield through machine learning. With this information, farmers can also receive notifications on when it is best to distribute said chemicals. The last component of our app is a list of suggestions on how to further reduce pesticide waste and exposure, thus safeguarding personal health. We created the farmer-facing part of the application in Swift because personal phones are one of the few things farmers may bring into the fields. When the grower first opens the app, they will be presented with a quiz, which is the necessary information to start our predictions. Our model uses a random forest regressor to predict the optimal pesticide use given the farmer‚Äôs unique farming circumstances. Sensors throughout the farm collect current data on weather and soil conditions to generate precise recommendations for pesticide application using the machine learning model trained from historical pesticide usage data. Data from sensors are stored in real time using the Kintone microcontroller and Kintone web database for easy IOT integration

Challenges we ran into

At first we ran into the problem of having too much data and that was really hard to comprehend in the 24 hours hackathon. This caused us to think on our feet and focus on models that had the key factors needed in predicting the amount of chemicals needed to reach a target yield instead of aiming to account for every possible environmental factor. Well also had issues integrating the custom model into iOS.

Accomplishments that we're proud of

We are really proud that we were able to build an app in Swift since many of the developers on our team were unfamiliar with the language. In addition that, we are also proud 
being able to implement our python base machine learning model into our application.

What we learned

The factors relating to the extent of pesticide dissemination in the environment and waste. Through this hackathon and subsequent research into our problem, we found that even the smallest aspects such as temperature and wind can affect the amount of pesticides needed for a given job. As a team, we also learned how to fail fast and build back better.

What's next for Nutra - Be Aware, Handle with Care: Pesticide Safety First

In the end, we would love to provide better predictions for our farmers for more plant species. In addition to that, we believe that farmers would find it helpful to be able to get the predicted cost for the pesticides that they use since it will allow them to budget for the future. Lastly, we envision that Nutria will work better with a family of sensors that will allow farmers to get live predictions. 
",https://github.com/Lukatastic/nutra,,"Best Health Hack, 	Best Hack for Social Justice, Most Creative Hack, Best AI/ML Hack, Best User Research, Best DEI Hack Sponsored by Fidelity, Best Use of Kintone","swift, python, kintone, flask",Matthew,Lok,mattlok08@gmail.com,,Best Health Hack,Best User Research,Best Hack for Social Justice,University of Southern California,2,Jones,Mays,jonesmaysce@gmail.com
TaskUp,3,https://hackdavis-2024.devpost.com/submissions/511220-taskup,Submitted (Gallery/Visible),Pending,Submit,04/28/2024 12:05:31,"Inspiration

The inspiration for ""TaskUp"" stems from a clear need among users for a more engaging, motivational, and intuitive tool for managing tasks. Recognizing the diverse ways people manage tasks and the specific challenges they face, ""TaskUp"" is envisioned as a solution that not only helps users organize their tasks more effectively but also enhances their productivity through motivational elements like gamification, rewards, and social features. The application aims to bridge the gap between traditional task management methods and modern, interactive technology to create a uniquely helpful and engaging user experience.

A Few common issues that we noticed through our User Research Survey were:
Procrastination: A common issue that might be addressed through motivational features.
Difficulty Prioritizing Tasks: Indicates a need for features that help users organize tasks based on priority.
Forgetfulness: This points to the necessity for reminders and possibly automated task scheduling.
Desired Features in Productivity Apps
Gamification Elements: Such as points and leaderboards, are favored by many users, indicating that incorporating these could enhance engagement and motivation.
Reminders/Notifications: Essential for helping users keep track of their tasks, especially those who struggle with forgetfulness.
Collaborative Features: Some users express a desire for apps that facilitate teamwork, suggesting that ""TaskUp"" could include features that support collaborative task management.
Motivation for Staying Productive
Rewards/Incentives: Users are motivated by tangible rewards, which can be integrated into the gamification aspects of the app.
Leaderboard Comparisons: Many users are interested in comparing their productivity with peers, which supports the inclusion of a competitive element in the app.
Preferences in App Design
Interactive and Engaging Designs: Preferred by most users, suggesting that a visually appealing and dynamic user interface could enhance user experience and adoption.

Hence, the inspiration for ""TaskUp"" stems from a clear need among users for a more engaging, motivational, and intuitive tool for managing tasks. Recognizing the diverse ways people manage tasks and the specific challenges they face, ""TaskUp"" is envisioned as a solution that not only helps users organize their tasks more effectively but also enhances their productivity through motivational elements like gamification, rewards, and social features. The application aims to bridge the gap between traditional task management methods and modern, interactive technology to create a uniquely helpful and engaging user experience.

What it does

""TaskUp"" is designed to be a comprehensive productivity tool that allows users to manage their daily tasks efficiently while providing an engaging and interactive experience. The application seamlessly integrates task management with gamification techniques and collaboration tools, catering to both individual users and teams.

Key Functionalities of ""TaskUp""

Create, Edit, and Delete Tasks
Users can easily add new tasks, modify existing ones, or remove completed or obsolete tasks.
Prioritization and Deadlines: Users can assign priorities and deadlines to tasks, which the app uses to prioritize users of approaching due dates and clashing deadlines, helping them to manage their time effectively.

Social Element - Gamification and Motivation
Points System: Users earn points for completing tasks
Leaderboards: Compete with friends or colleagues in a friendly leaderboard setup where users can compare their progress and achievements, spurring a healthy competitive spirit.

User Experience
Interactive Designs: The UI/UX is crafted to be engaging and easy to navigate, enhancing user satisfaction and retention.

How we built it

To create ""TaskUp,"" we employed a modern technology stack, focusing on delivering a robust, scalable, and engaging user experience. Here‚Äôs a detailed breakdown of how we built the application, using our combined expertise in software development:

Frontend Development
For the frontend, we chose React, a powerful JavaScript library known for its efficiency and flexibility in building interactive UIs. We integrated Material-UI to provide a consistent look and feel with responsive and accessible components, ensuring a smooth and intuitive user experience across all devices.

Backend Development
On the backend, we leveraged Node.js, providing us a powerful framework to handle our server-side logic. For database storing, we used MySQL, a relational database known for its reliability and robustness. We handled user authentication and session management using our system, which enabled us to implement secure and scalable authentication systems efficiently.

Gamification Elements
For implementing gamification elements such as points, leaderboards, and rewards, we created custom backend logic that tracks user activities and achievements. These features were designed not only to motivate users but also to create a more engaging and fun experience that stands out from typical productivity apps.

User-Centric Design
Finally, the design and flow of ""TaskUp"" were heavily influenced by the feedback we gathered from our initial user research. We iteratively refined our UI/UX to ensure that it not only looked good but was also practical and easy to use. Our goal was to create an application that users would love to use daily, which drove every decision we made from the layout of the interface to the interactions within the app.

Challenges we ran into

Initially, we used PropelAuth for user authentication, drawn by its ease of integration. However, it fell short in allowing us to retrieve and manage extended user-specific information. This limitation led us to develop our own custom authentication system. This shift not only provided us with the flexibility needed to handle user data but also deepened our understanding and implementation of security best practices.

We started with Firestore due to its real-time capabilities and scalability but soon realized that our application was better suited. Transitioning to a MySQL database, we restructured our database schema and updated our data interaction logic. This switch enhanced our ability to manage structured data for task management and user profiles more effectively.

Accomplishments that we're proud of

Our team's accomplishment with ""TaskUp"" was multifaceted, reflecting a deep commitment to innovation, collaboration, and problem-solving. Integrating gamification elements and social features, we transformed traditional task management into an engaging and interactive experience. Overcoming challenges such as transitioning authentication systems and adapting database structures showcased our adaptability and resilience. Leveraging a modern tech stack, including React and Node.js, we crafted a robust and scalable solution. Through iterative design and user feedback, we ensured a user-centric approach, delivering an intuitive interface that resonates with our audience. The result is a comprehensive productivity tool that empowers users to manage tasks effectively while fostering motivation and collaboration.

What we learned

Building ""TaskUp"" provided us with hands-on experience in utilizing specific technologies such as React and Material-UI for frontend development, Node.js for server-side logic, and MySQL for database management. Integrating Material-UI facilitated the creation of a visually consistent and responsive user interface, while Node.js empowered us to efficiently handle server-side operations. Leveraging MySQL enabled robust data storage and management, crucial for ensuring the reliability of our application. This project not only honed our skills in these technologies but also emphasized their importance in crafting scalable, engaging, and user-friendly software solutions.

What's next for TaskUp

Advanced Analytics and Reporting: We'll introduce analytics to help users identify productivity patterns, including peak productive times and task completion metrics, providing actionable insights for efficiency improvements.
AI-Driven Task Recommendations: Utilizing AI, we plan to deliver personalized task recommendations that adapt based on user behavior and preferences, helping optimize daily schedules.
Enhanced Rewards System
Tiered Rewards Structure: We will implement a tiered system where users progress through levels by completing tasks, and unlocking rewards such as premium features, unique badges, and more customizable options at each new level.
Enhancing Designs: Based on more user testing and feedback we will overhaul the designs as required for best user experience.
",https://github.com/vijitdua/TaskUp,https://youtu.be/FBppQfu-vvo,"Most Creative Hack, Best User Research, Best Use of .Tech Domain Name, Best Interactive Media Hack","mysql, node.js, express.js, react, docker, amazon-web-services, cloudflare, materialui, namecheap",Vijit,Dua,vijdua@ucdavis.edu,,Best User Research,Best Interactive Media Hack,Most Creative Hack,"University of California - Davis, UC Davis",3,Nandhana,Selvam,nandhanaselvam@gmail.com
privy,103,https://hackdavis-2024.devpost.com/submissions/511221-privy,Submitted (Gallery/Visible),Pending,Submit,04/28/2024 12:05:48,"Inspiration

In the news, we read a lot about companies experiencing data breaches, and if users knew what data companies stored, they could be more cautious when creating accounts on new websites. 

What it does

Our webapp takes in a privacy policy as input, and summarizes it into distilled, understandable information. It includes a slider that lets you choose how concise your output is.

How we built it

We built our frontend using HTML/CSS. Our backend is built using Node.JS and Express.JS. The frontend can send a POST request to the backend, which then makes an API call to Google Gemini. The backend receives data (in the form of JSON) and responds to the frontend by sending this data. 

Challenges we ran into

We struggled with building our backend Node.JS server and creating POST requests, as it was our first time working with these technologies.

Accomplishments that we're proud of

We created a finished, polished product with added user customization and gained valuable knowledge on creating full-stack infrastructure.

What we learned

This hackathon was a great learning experience for us all as it was our first hackathon. We learned technical skills, such as how to build node servers, communicate between the front-end application and back-end server, use other developed products through API calls, and navigate git and deal with merge conflicts. We also learned how to work in a cross-functional team of designers, front-end developers, and back-end engineers, as well as working under extreme time pressure to create a product we are proud of.

What's next for privy

We want to make it easier for users to quickly find out how safe a company is, and giving bullets may not always be the best way to do that. For that reason, we hope to assign each website a score by identifying 10 key features of a good and bad privacy policy, which will make it easier for users to understand at a glance the trustworthiness of a company.
",https://github.com/Atticus-Wong/hackdavis24,,"Best Beginner Hack, Most Creative Hack, Best AI/ML Hack, Best Overall Design","html, css, javascript, express.js, node.js",Reeti,Bandyopadhyay,rban@ucdavis.edu,,Best Beginner Hack,Best Overall Design,Most Creative Hack,University of California - Davis,3,Akhil,Guntur,asguntur@ucdavis.edu
test project,,,Draft,Pending,Project overview,04/28/2024 12:05:58,,,,Best Beginner Hack,"flutter, firebase",Kiruba,Karan,kirupakaran094@gmail.com,,,,Best Beginner Hack,University of Kelaniya,0,,,
House Cat,110,https://hackdavis-2024.devpost.com/submissions/511232-house-cat,Submitted (Gallery/Visible),Pending,Submit,04/28/2024 12:24:06,"Inspiration

While sites such as Apartments.com provides users with optimized and accessible ways of finding available housing options around them, it doesn't account for available sublease/lease takeover offers or requests. Especially among students and other community members, it is not entirely uncommon to want to find such options, whether it may be for a place to stay in over the summer or when unexpected housing situations arise. Because of this, users will most commonly resort to Facebook groups dedicated to essentially offering an online marketplace for these housing options. 

However, the natural design of Facebook and Facebook groups means that users have no way of filtering or sorting through these offerings in the context of their housing needs, and moderators have no way of implementing such features. Because of this, users are subject to endlessly scrolling through a large number of posts until they find a housing option that they like. This can easily become time-consuming and mentally draining very quickly.

What it does

HouseCat is a web-based database application that combines the flexibility of the design of Facebook groups and the convenience of database querying, and provides users accessible ways of easily navigating through available housing offers.

How we built it

Our applications follows the MERN (MongoDB, Express, React, Node) stack, which allows us to easily construct a three-tier architecture using JavaScript and JSON. Ideally, a MongoDB database stores all the information from housing Facebook groups with each post being its own record. Our Express.js framework in our Node.js server will then be able to interactively make requests from our MongoDB database, which can then connect to our React.js framework that renders the data into user-friendly designs. Github pages was used to host the frontend, while Heroku was used to host our backend server.

Challenges we ran into

We encountered a few challenges throughout the process of building our application. 

We first attempted to scrape the data from a public facebook group using python libraries Selenium and BeautifulSoup. However, the nature of Facebook does not allow us to scrape data and will block users who use an automated tool. Thus, our solution was to use a publicly available web scraper called Apify and return a csv file of several posts‚Äô information.
When creating the website application, we ran into issues of connecting our MongoDB database to the frontend. As this is our first time using React.js and Node.js, we needed more time to figure out how to query the database from the backend and translate it to the front end. Our solution was to create a prototype that shows the potential functions of the website, so we have an idea on what to work on later!
We attempted to program our interactive ChatBot by connecting it to OpenAI. We ran into the issue of needing a secure API key and ran out of time to authorize it through GoogleCloud. However, once this is done we will be able to implement an interactive chatbot that will allow users to ask about details for each apartment complex in Davis.

Accomplishments that we're proud of

Going into this project, we had zero experience with any frontend and backend frameworks and implementation, so a lot of the time we had was spent on simply trying to figure out how our whole application actually worked. Despite that, we still came out with a result that was so much better than what we expected, considering our background and technical skills beforehand. Because so much of the work poured into the project was simply spent learning, we had a better understanding of how to actually implement a functional website, and despite us not being able to fully complete it by the end, we still enjoyed and valued the learning experience and the work that we put into it.

What we learned

We learned several skills in the past 24 hours of HackDavis. In addition to the programming skills below, we learned about the necessity of clean data when creating a data powered web applicaiton, and the importance of a clear workflow for the project. 

New programming skills learned: 
JavaScript
How to use React.js and Node.js
How to create a database using MongoDB
How to use MongoDB, MongoDB Atlas and MongoDB Compass and connect it to React

What's next for House Cat

Going forward, we'd love to work on the functionality of our application, as we were ultimately unsuccessful in creating a fully functional application, such as making actual functioning querying buttons and an integrated chatbot. After that, we'd like to spend more time creating more features to make our application more accessible, and maybe even move away from the Facebook groups functionality into becoming our very own social media application where offers can be directly advertised, which can make the extreme potential ambiguity of Facebook posts much less of a headache to deal with which would let us better streamline the querying functions that we implement.
","https://allison2368.github.io/website_hackdavis/, https://github.com/jmudong/hackdavis2024, https://docs.google.com/presentation/d/1rRuVYWfIxcoN4k1xdEUvuymhcr4D4FYoHs_cT3mGFXQ/edit?usp=sharing",,"Best Beginner Hack, Best Interdisciplinary Hack, Most Creative Hack, Best User Research","mongodb, node.js, react, express.js",Jasper,Dong,jmudong@ucdavis.edu,,Best User Research,Best Beginner Hack,Best Interdisciplinary Hack,University of California - Davis,1,Allison,Peng,allisonpeng10@gmail.com
Clarity Cap,2,https://hackdavis-2024.devpost.com/submissions/511235-clarity-cap,Submitted (Gallery/Visible),Pending,Submit,04/28/2024 12:29:21,"Inspiration

Our team was inspired to build a hack that would allow those with Alzheimers and short term memory degradation to quickly remember people they have recently interacted with as well as the relationships they shared with them. ""Clarity Cap"" was built to be a portable memory aid that can be worn on the go and helps jog the memory of the wearer to provide context when it is needed.

What it does

Our device consists of (2) components. The first component is the hat with a webcam assembled on top which acts as the eyes and allows our device to see people around the wearer. The second component is the touchscreen wristband which provides text based output to display names and relationships as users interact with people in their environment.

How we built it

We used a Raspberry Pi 5 which was connected to an RP3508 Screen, and a Webcam. The Raspberry Pi and Webcam were mounted on a baseball hat with the display being glued onto a wristwatch to help in providing output. In terms of the tech stack, we used Flask to host a local web server and are using this along with facial recognition that breaks down each face into unique identifiers which helps it recognize old and new faces.

Challenges we ran into

During the project, the display screen that we were planning to use was not starting up. We overcome this challenge, by discussing the viability of a couple other screens that we had on hand. Additionally, we realized that our Raspberry Pi 5 was running very hot midway through the hackathon. We worked around this by implementing a heatsink and 3D Printed the appropriate housing structure that could fit the pi 5 as well as the heatsink.

Accomplishments that we're proud of

We were able to build a working prototype around halfway through the Hackathon! It was also the first time members of our team explored AI models such as Llama3.

What we learned

We learned that perseverance is key. Thinking about those who face difficulties daily with imapairments, we trucked on past all challenges until ""MyMemory"" was functional!

What's next for Clarity Cap

We would like to expand on the functionality of ""Clarity Cap"" by adding audio capabilities in which the text that is currently being displayed on the wrist can instead be outputted via audio.
",https://github.com/Patronics/clarityCap,https://youtu.be/bQBlTNLN3gQ,"Best Health Hack, Best AI/ML Hack, Most Technically Challenging Hack, Best Hardware Hack","flask, python, opencv",John,Schneider,jschneider2@student.sierracollege.edu,,Best Hardware Hack,Most Technically Challenging Hack,Best Health Hack,"University of California - Davis, Sierra College",3,Patrick,Leiser,patrick27leiser@yahoo.com
Unplug!,138,https://hackdavis-2024.devpost.com/submissions/511249-unplug,Submitted (Gallery/Visible),Pending,Submit,04/28/2024 12:52:18,"Inspiration

Our project was inspired by the growing concern over smartphone addiction and its impact on productivity, especially among students and professionals. We wanted to create a solution that helps people break free from this addiction and achieve deep focus in their study and work.

What it does

YouControl is a project focused on creating a human AI companion device aimed at mitigating smartphone addiction and promoting deep focus during study and work. It achieves this by providing essential features only and blocking distractions like social media. The device utilizes advanced technologies such as Facebook's Wav2Vec2 for speech-to-text conversion and OpenAI's GPT 3.5 for fetching relevant information. The project was inspired by the growing concern over smartphone addiction and the desire to create a solution that helps people prioritize important tasks while blocking out unnecessary distractions. Through the development process, the team learned about the harmful effects of smartphone addiction and gained insights into leveraging cutting-edge technologies to promote focus and productivity. Challenges faced during development included optimizing performance and integrating multiple APIs.

How we built it

We used an ESP 32 board, Arduino C++, Python, PyTorch, and multiple API calls to build it.

Challenges we ran into

One of the main challenges we faced was optimizing the performance of our speech recognition and natural language processing algorithms to ensure fast and accurate responses. We also had to overcome technical hurdles related to integrating multiple APIs and ensuring compatibility across different devices.

Accomplishments that we're proud of


Successful integration of advanced speech recognition and natural language processing technologies into the device, providing users with seamless interaction and access to information.
Creating a user-centric design that prioritizes essential features and minimizes distractions, effectively addressing the challenge of smartphone addiction and promoting deep focus.
Developing a reliable and efficient system for converting audio inputs to text, enabling users to interact with the device effortlessly and efficiently.
Implementing robust security measures to protect user data and ensure privacy, building trust and confidence among users.
Receiving positive feedback and recognition from users and stakeholders for the effectiveness and impact of the device in promoting productivity and focus.


What we learned

We learnt a lot about how to work with ESP32 hardware, and especially, how to use Arduino GFX Library among other things.

What's next for YouControl

User testing and getting feedback from our target audience :)
",https://github.com/Arnav33R/HackDavis2024,,"Most Creative Hack, Best AI/ML Hack, Most Technically Challenging Hack, Best Hardware Hack","python, arduino, gfx, pytorch, esp32, wav2vec2, api-creation",Shyam,Agarwal,shyagarwal@ucdavis.edu,,Most Technically Challenging Hack,Most Creative Hack,Best AI/ML Hack,University of California - Davis,2,Kevin,Kapoor,kjkapoor@ucdavis.edu
DCMH Redesign,44,https://hackdavis-2024.devpost.com/submissions/511254-dcmh-redesign,Submitted (Gallery/Visible),Pending,Submit,04/28/2024 13:06:47,"Inspiration

Since most of the team were beginners, we chose to work on something that already existed but can be improved upon.

What it does

Our project is a demo on what an inventory management system / wishlist system will look like for DCMH. It requires that someone be logged into the web page as an already pre-approved admin using the propel authenticator. Once they are logged in, they will be able to manage the inventory of the items.

How we built it

We built the site using the nextjs framework for the website

Challenges we ran into

There were many challenged along the way, most of us did not have much experience with web development before especially with the nextJS. Integration of the authenticator was pretty simple but coding the database logic was the hardest challenge as there was a lot of syntactical sugar we had to figure out, angry typescript error messages and fighting nextJS' server side and client side component conflicts.

Accomplishments that we're proud of

We are proud of having a working website with most of the functionality that we imagined being implemented. 

What we learned

We pretty much learned basic full stack development. Front end, databases, and authentication.

What's next for DCMH Redesign

We think that the aesthetics of the webpage can be improved upon with a little bit more content.
",https://github.com/pynappo/hackdavis2024,,"Most Technically Challenging Hack, Best Use of PropelAuth, Best Hack for DCMH","javascript, html, css, typescript, prisma, postgresql, vercel, nextjs, propelauth",David,Le,lehtien.david@gmail.com,,Best Hack for DCMH,Best Use of PropelAuth,Most Technically Challenging Hack,"San Jose State University, University of California - Davis",2,Mathmilian,,chchen2022a@gmail.com
Aggie Reminder,126,https://hackdavis-2024.devpost.com/submissions/511280-aggie-reminder,Submitted (Gallery/Visible),Pending,Submit,04/28/2024 13:24:34,"Inspiration

Creating a website specifically designed to manage and send reminders to volunteers can significantly enhance the organization and efficiency of volunteer-driven events or operations. Such a website can serve multiple purposes, from scheduling to communication, and ensure that volunteers are well-informed and engaged.

What it does

A website that is used only by the administrator of Aggie House. It can check and manage the hours of work for volunteers, and also help the staff communicate with volunteers by Sengrid email API. The second part of the project is the automatic reminder that implements the Javascript in App Script extension on Google Sheets that has the email sent to the volunteers automatically when it comes close to the day of the event.

How we built it

We set up the local server using node js. Then proceed to write the server logic to ensure the website has functionality that can work properly. Using CSS, Javascript, and HTML to organize the webpage into presentable project. For the automatic reminder, we implement it by using Javascript in the App Script extension on Google Sheets, setting a timer that the Google server can automatically check if it's 2 days close to the event then it would send the reminder to participants by their registered email.

Challenges we ran into

Setting up the server is complicated. APIs are usually restricted or not free.

Accomplishments that we're proud of

As a beginner, we are proud that we managed to finish our product, especially getting the server to work and being able to connect all of our components.

What we learned

After the project, we learned lessons of time management, collaborating with teammates efficiently, using more technologies, and putting our learning in class to build something helpful for society.

What's next for Aggie Reminder

Aggie Reminder still needs to be deployed online, and many quality-of-life additions can be added, such as accessing Google Sheets online instead of offline Excel files, easier setup process, and more.
",https://github.com/calvinhoang203/Aggie-Reminder/tree/main,,"Best Beginner Hack, Best Interdisciplinary Hack, Most Technically Challenging Hack, Best User Research, Best Hack for AggieHouse","html, css, sendgrid, api, node.js, postgresql, database, excel",KuyaBasti,Solon,enderbrine21803@yahoo.com,,Best Beginner Hack,Best Hack for AggieHouse,Best Interdisciplinary Hack,University of California - Davis,3,Hieu,Hoang,hiehoang@ucdavis.edu
Compakt,151,https://hackdavis-2024.devpost.com/submissions/511285-compakt,Submitted (Gallery/Visible),Pending,Submit,04/28/2024 13:25:55,"Inspiration

Often, the environment plays a big part in our unhealthy lifestyles, with trash polluting our soil, water, air‚Äîand ultimately, us. Recognizing that it's easy to overlook the nearest trashcan or to track when they're full, we decided to do something about it. We didn't just create an app to monitor trashcans around you; we went a step further. Our solution is a smarter trashcan that not only detects how full it is but also compresses its contents to save space. This way, we‚Äôre making it easier and more efficient to keep our environment clean.

What it does

We‚Äôve developed a trashcan that not only detects when it‚Äôs full and compresses the waste but also updates its status and location through our web application. Through the app, you can view nearby trashcans and, with a simple click, access detailed information about the trash's status and the can's location. Our innovative trashcan makes it possible to keep track of waste management efficiently, demonstrating our commitment to smarter environmental solutions.

How we built it

Hardware
To mimic our version of the smart trashcan we used an Arduino Uno to incrementally check if there was trash in the bin using a sonar sensor. If there is trash inside the bin above the threshold for a certain amount of time, the compressor is activated. Due to hardware constraints we were forced to use a stepper motor with low output. This made the process much harder and we had to pivot from using a gear based compression system to a pulley based one within the last couple hours. After the compressor finishes the sonar checks once again if the can is full and will send a signal to our website based on if the trash is still above the threshold or not.


Arduino, Stepper Motor, Sonar Sensor 


Software
Our application leverages TypeScript, NextJS, Python, and Firebase to create a robust environment. For the front end, we've utilized libraries such as MaterialUI for design components and the MapBox API for displaying interactive maps of trashcans in the area. This setup allows our front end to communicate seamlessly with Firebase, enabling us to retrieve and display real-time information on the status and location of all trashcans. In the backend we have C++ to write the Arduino code, as well as Python to monitor the signals coming from the Arduino to update our database.

Challenges we ran into

For many of us, diving into this project meant stepping into unknown territories‚Äîwhether it was the frontend, backend, or hardware side of things. The learning curve was steep, especially since we had just 24 hours to apply our knowledge. One major hurdle was the frontend environment; none of us had ever worked with NextJS before, so just setting up the basics like routing, components, and the UI was a bit of a scramble. We also hit a big snag with MapBox‚Äôs documentation‚Äîit was pretty lacking and ended up eating a huge chunk of our time as we tried to figure out how to adjust the maps and place the trash markers accurately. But the real challenge came with the hardware. Most of us hadn‚Äôt even touched hardware before, so trying to connect the Arduino with NextJS was a whole other level of tough. Even after learning how to use the hardware, the weak stepper motor continued to plague our build. Plus, even though we had a clear idea for our smart trashcan, we eventually realized we were missing some key materials to truly showcase what our hardware could do.

Accomplishments that we're proud of

After a sleepless night, we're proud of how much we achieved with this project, especially since each of us tackled something completely new. Our biggest challenge was establishing a reliable connection between our smart trashcan and the web application. Despite the initial hurdles, we managed to devise a system that kickstarted our concept. In the end, we successfully developed the application we had envisioned and integrated it with our self-built trashcan. While we didn't execute the smart trashcan prototype exactly as we had hoped, we're confident that with more time and better resources, we could refine our prototype significantly. Nonetheless, this project was a profound learning experience, proving that our ideas could indeed transform into reality, even when faced with daunting challenges.

What we learned

For all of us, this was our first experience blending software with hardware, which turned out to be a huge learning curve. On the software front, none of us had ever worked with NextJS or the MapBox API before, so we had to dive in and figure out how to set everything up from scratch. On the other hand, for the hardware we needed to learn how to code an Arduino and understand how it interacts with sensors and motors. By the end of it, we all came away with valuable skills and applied knowledge that we hadn't had before.

What's next for Compakt

We believe our software product would be incredibly valuable in various settings, including busy campus restaurants, large public areas, and major events. It would not only help sanitation workers manage waste more effectively in these challenging environments but also provide valuable data on the status of trashcans. By understanding where and when trashcans fill up most frequently, we can strategically use this information to improve waste management at these busy spots, ensuring cleaner and more efficient operations.
",https://davishacks24-compakt.vercel.app/,https://youtube.com/shorts/M2I2wpifCMQ?si=B3nyPGlHEs0yMRjx,"'	Best Hack for Social Justice, Most Creative Hack, Best Hardware Hack, Best Interactive Media Hack, Best Entrepreneurship Hack","nextjs, tailwindcss, python, c, arduino, firebase",Brandon,Tran,tranbrandon04@gmail.com,,Best Hack for Social Justice,Most Creative Hack,'	Best Hack for Social Justice,"University of California - Irvine, UCI, University of California - Davis",3,Matt,Jamison,matthewjamison56@gmail.com
Kaimmunity (Life of Kai - Find Fido Fast),32,https://hackdavis-2024.devpost.com/submissions/511288-kaimmunity-life-of-kai-find-fido-fast,Submitted (Gallery/Visible),Pending,Submit,04/28/2024 13:28:04,"Inspiration

We wanted to pursue this track because of the mission of The Life of Kai Nonprofit. The mission of not only being empathetic to humans, but specifically towards animals, was compelling to us, and we wanted to give the challenge a try. Keep doing what you are doing! 
In addition, when researching websites of sponsors and nonprofits, we just thought the dogs on the website were cute. We included yolo, snowy and dusty, mama, and quinn on our app :)

What it does

A user can upload pictures and locations of lost pets. It creates markers on a map to show the positions of lost pets.

How we built it

The application is built with React Native and Firebase.
Expo camera for camera taking, FastAPI for testing, 

Challenges we ran into

Implementing Firebase into React Native.
Networking and simulating the emulator 
The multiple features to solve:
    -Pins with google maps was causing import issues
    -Geolocation was hard to understand in the setup
    -Photo taking was not rendering on the emulator

However‚Ä¶‚Ä¶. 

Accomplishments that we're proud of

Created a full user flow for the frontend

We were faced with a lot of unfamiliar features and technologies, however our whole team of three stayed up for the entire hackathon and persevered, only getting 1.5 hours of sleep max. We continued to support each other in implementing feature after feature!

Unexpectedly accomplished features desired for a find fido solution!


üìçReport feature to pin lost location ‚úÖ
üïíFeature of exact timestamp ‚úÖ
üî•Connection to firebase for triggering all users when image reported ‚úÖ
üì∏ Users can take photos with geolocation enabled ‚úÖ
üì° Can place pins to be shared back in the database ‚úÖ


5 technical features accomplished!!

What we learned

-Networking on the LAN at Davis and running an ios app in the tunnel and configuring IP addresses to simulate with a physical mobile device.
-React native with multiple features, uploading images from react native to firebase, firebase tools, and google apis. 

What's next for Kaimmunity (Life of Kai - Find Fido Fast)

Creating a direct message between the Reporters and the Owners of the pets.
","https://github.com/audgeviolin07/lifeofkai.ai, https://audrey-chen.my.canva.site/kaimmunity",,"Best Interdisciplinary Hack, 	Best Hack for Social Justice, Most Creative Hack, Best AI/ML Hack, Most Technically Challenging Hack, Best UI/UX Prototyping, Best Overall Design, Best User Research, Best DEI Hack Sponsored by Fidelity, Best Use of .Tech Domain Name, Best Interactive Media Hack, Best Finance & Tech, Best Entrepreneurship Hack, Best Hack for Life of Kai","google-cloud, google, firebase, react-native",Audrey,Chen,audgeviolin07@gmail.com,,Best Hack for Life of Kai,Most Technically Challenging Hack,Best Interdisciplinary Hack,"Michigan State University, Ohlone College",2,Ryan Riley,Puzon,rrgpuzon@gmail.com
Remote Door Lock,141,https://hackdavis-2024.devpost.com/submissions/511297-remote-door-lock,Submitted (Gallery/Visible),Pending,Submit,04/28/2024 13:38:30,"Inspiration

We were aware that smart home technology is often intrusive and unaffordable for those with disabilities, so we wanted to create a better alternative to one of such technology.

What it does

The Remote Door Lock allows the user to see a live camera feed of their front door (or another door of choice) and remotely lock and unlock the door just with the click of a button, all from their web browser.  The system is composed of a camera unit, a microcontroller that receives lock/unlock commands, and a motor attached to the door lock. The camera feed and remote control are both done over a password-protected local wireless connection, accessible by connecting from any device with WiFi and browser.

How we built it

We used ESP32 microcontroller to control a motor that opens and closes the door.  We built the motor driver circuit with a L293D half-H driver and a power distribution panel to allow bidirectional movement. The ESP32 is programmed with C++ to be a WiFi access point with ESPRESSIF libraries, and allows the user to send lock/unlock commands over WiFi from a web page it serves on its IP address.

Challenges we ran into

One of the biggest challenge we ran into was trying to drive the motor in two different directions. Since we did not have a H-bridge motor controller module, we tried to build our own H-bridge circuit. When that did not work, we tried a circuit using two relays to achieve the dual direction motor drive. As of now, we are using the L293D IC motor drive to with an external power supply to achieve the dual direction motor drive. Another major challenge we ran into was getting the camera feed to stream the real time footage. We ran into a lot of connection issues with the WiFi so we switched to a local WiFi access point to get it to work. 

Accomplishments that we're proud of

We are proud that we are able to get the real time camera feed working as well as getting the dual direction motor drive to work.

What we learned

We learned how to do real time camera feed streamed over the network using a local WiFi access point. We also learned about the different ICs and methods that can be used to drive a motor such as a H-Bridge circuit, circuit with two relays and the current one which uses L293D half H-Bridge IC.

What's next for Remote Door Lock

If we have more time and access to 3D printers or machining tools, we would create a connector between the motor shaft and the door lock spindle. We would also create enclosures for all the electronic components, as well as make a custom PCB to make the device compact, cheaper, and easy to handle.
",https://github.com/MelodyLiu012/HackDavis2024,https://youtu.be/ySaoTAG1BlQ,"Best User Research, Best Hardware Hack","c++, esp32, microcontroller, motor",Melody,Liu,geministarco@gmail.com,,Best Hardware Hack,Best User Research,Best MedTech Hack,"University of the Pacific, Foothill College",2,tun,naing,tunmyintnaing7@gmail.com
FridgeFresh,102,https://hackdavis-2024.devpost.com/submissions/511298-fridgefresh,Submitted (Gallery/Visible),Pending,Submit,04/28/2024 13:40:05,"Inspiration:

We picked this project because we wanted to make it easier for people to know when stuff in their fridge is expiring. We had a desire to reduce food waste, improve nutrition and health by monitoring food quality, through technology.

Learned Lessons:

We learned that developing our project on public wifi wasn't viable. We needed a private network for our project to fully function, but we mustered what we could. However, we learned more about making mobile apps with React Native Expo.

Challenges Faced:

We had trouble dealing with asynchronous calls in React Native. We also had conceptual challenges like designing an intuitive user interface for the user.

Improvements:

We could include better image recognition, a more comprehensive database of food items, and a more sophisticated algorithm for expiration prediction.
",https://github.com/TommyClemenzaChen/FridgeFresh,,"Best Health Hack, Best AI/ML Hack, Most Technically Challenging Hack, Best Statistical Model","react-native, javascript, python, torch",Ryan,Okimoto,ryan.okimoto@hotmail.com,,Best Health Hack,Best AI/ML Hack,Most Technically Challenging Hack,University of California - Santa Cruz,3,AQUAiTE,,francisiwnlschool@gmail.com
Recall,143,https://hackdavis-2024.devpost.com/submissions/511301-recall,Submitted (Gallery/Visible),Pending,Submit,04/28/2024 13:42:36,"Inspiration

We love using flashcard apps like Quizlet and Anki (especially Anki). While they have wonderful algorithms to boost content retention, they have one fundamental flaw: the user has to decide their own comprehension level of a flashcard.

What it does

Our solution is to patch the gap in two ways. The first requires the user to type in answers, so they must formulate their thinking properly into a comprehensive answer. The second way is to utilize an NLP model designed to analyze the answer, score it on similarity, and plug it into our custom spaced repetition algorithm (based on Anki) in order to optimize your learning experience.

How we built it

We decided to use typescript in Next.js to facilitate full-stack development and a Python FastAPI server to host the primary algorithm and NLP evaluation logic. We also use the cloud database Supabase to store all user, deck, and card data.

UI Design

We put special care into the design of our UI. Learning is an immensely valuable skill, so it's important to us that your learning tools work for you, not against you, down to the most minute detail. The interface is designed to be simple and intuitive, with all the essential features a good flashcard app should have. 

In addition to this, we researched the effects of specific colors on the brain in regard to learning. According to this link, studies show that, for adults, both fewer and cooler colors (blue/green) ""tend to boost concentration, lower anxiety/hormones, and promote creativity.""

All of these elements combine into a product you can be sure is working to provide the best experience possible.

Challenges we ran into

The biggest challenge was applying our NLP model (from Hugging Face) to this scenario and tuning the responses to get an integer score output.

Accomplishments that we're proud of

We are proud to say our algorithm works! We've extensively tested the grader and are very happy with the results.

What we learned

Our biggest lesson is never to underestimate the size of the project. No matter how much you plan and plan, there will always be new problems to dodge and weave to make it through to a final product.

What's Next for Recall

We have many plans we plan to implement in the future, among which are:


Utilizing openAI's solutions for extra feedback to the user when they get something wrong
A comprehensive summary report at the end of a session detailing the areas in which the user struggled
Setting up public hosting
Offline support
User/Login system
Custom trained NLP
In-app deck sharing

","https://github.com/nithinsenthil/Recall/tree/main, https://www.figma.com/file/kM7FXPlvOufnf6Idnr7Kdt/Recall?type=design&node-id=0%3A1&mode=design&t=hB9zJZr17P5aBqh3-1",,"Best Interdisciplinary Hack, Best UI/UX Prototyping, Best Overall Design, Best User Research","typescript, python, sql, next.js, fastapi, natural-language-processing, supabase, tailwind, daisyui",Nithin,Senthil,nithin020304@gmail.com,,Best Interdisciplinary Hack,Best Overall Design,Best UI/UX Prototyping,University of California - Davis,2,sidzmani,Mani,siddharthmmani@gmail.com
Lock In O'Clock,6,https://hackdavis-2024.devpost.com/submissions/511306-lock-in-o-clock,Submitted (Gallery/Visible),Pending,Submit,04/28/2024 13:50:13,"Inspiration

To create a platform for UC Davis students to find a compatible study buddy.

What it does

Allows users to create a custom profile and match with others who have similar study habits and classes.

How we built it

Implemented front-end design with React.js and Node.js, created UI/UX design with Figma

Challenges we ran into

Faced multiple setup and git issues, causing us huge setbacks in our project. 

Accomplishments that we're proud of

Creating a full design layout and implementing it into the project.

What we learned

What's next for Lock In O'Clock


Expand the audience from UC Davis students to those all over the world
 Increase the scope of the web app from just finding a study buddy to finding someone with similar hobbies to do those activities with

","https://www.figma.com/file/kOtkhS6yA0dkBqoNxEH1oY/Study-Buddy-Wireframe?type=design&node-id=1%3A3&mode=design&t=1oAqEvyS3LEwZX8D-1, https://github.com/sarayumummidi/LockInOClock",,"Best Beginner Hack, Best UI/UX Prototyping, Best Overall Design, Best Use of .Tech Domain Name","react.js, node.js, figma",Michelle,Yeoh,michellew.yeoh@gmail.com,,Best Beginner Hack,Best UI/UX Prototyping,Best Overall Design,"University of California - Davis, Scripps Ranch High School",2,Sarayu,Mummidi,saru.mummidi@gmail.com
Sentimatic,87,https://hackdavis-2024.devpost.com/submissions/511307-sentimatic,Submitted (Gallery/Visible),Pending,Submit,04/28/2024 13:50:53,"Inspiration

Over the past few years, the excessive workload for mental health workers has caused a number of them to leave their jobs. With the rise of mental health patients and a declining number of professionals, there is a lot of concern regarding the ability to treat these patients. Hence, we wanted to develop a program that is going to help them monitor patients 24/7. 

What it does

We created a web application called Sentimatic. Sentimatic utilizes a webcam and machine learning to analyze the patient's emotions at all times and log them onto our web app. Based on the analysis of the emotions, it will output suggestions on activities they will do. 

How we built it

We leveraged Flask, Opencv, and Deep Face for the Backend Development. Additionally, we used Firebase to store the data we collected from the Backend. With the help of OpenCV, we are able to process the real time images with computer vision. We utilized Next.JS and Tailwind CSS to create an interface that displays the patients, and when we click on each patient, it is directed to a page with their time log and emotions automatically. Finally, we implemented the use of Gemini AI to generate non medical ways of improving their mental state, catered to each patients. We also featured an message output that notifies the health care workers immediately if the patients are in poor mental state. 

Challenges we ran into

We had trouble finding a dataset to analyze the emotions because many of them could not detect the proper emotions. We went through multiple datasets to find an accurate dataset with our project. We also had trouble finetuning the idea that we had during the start of the Hackathon, and we had meetings to discuss about our team's vision. 

Accomplishments that we're proud of

We were able to launch a real time webcam emotion analysis. We were also able to get our main emotions and also accurately detect them. Furthermore, we were able to learn more about Machine Learning, Full Stack Development, and Databases. We feel exceptionally proud that we were able to launch a product as this is our first hackathon all together. 

What we learned

Since none of us had any experience in machine learning prior to this project, it was a fun experience to get to experiment with it. We were also able to enhance our knowledge in computer vision and implement new APIs.

What's next for Sentimatic

In a long term project, we will be able to use multiple webcams to detect patients in a greater scale. We will be able to implement more details and improve the speed of the program especially with better resources and hardware. Also, we would love to implement the idea of text to speech automator AI for every patients so that we will be able to assist them as soon as possible. 
",https://github.com/Nikko-Adrian-Pacleb/HackDavis2024-FinalOutput,,"Best Beginner Hack, Best Health Hack, Most Creative Hack, Most Technically Challenging Hack","python, firebase, next.js, flask, opencv, deepface, tailwindcss",Louisa Anjanette,Auwlia,anjanette.auwlia@gmail.com,,Best Beginner Hack,Best Health Hack,Most Creative Hack,Mt San Antonio College,3,Julyd03,Dong,donghuayu713@gmail.com
SkinScreen,88,https://hackdavis-2024.devpost.com/submissions/511310-skinscreen,Submitted (Gallery/Visible),Pending,Submit,04/28/2024 13:53:50,"Inspiration

While approaching ideation for a software product for social good, we wanted to consider tackling a health issue that is often overlooked but can have serious consequences if not addressed promptly. Every year, millions of patients are diagnosed with skin cancer, yet getting tested for a diagnosis early on can be inaccessible, as screenings can cost up to $300 without insurance. As a result, we developed SkinScreen to lessen this barrier by providing a way for users to receive instant results to help determine potential conditions that they should get checked out by a medical professional.

What it does

Our product allows users to scan their skin and receive results for potential conditions they may have. It also provides additional resources for users concerned about skin health such as daily advice and recommended articles. 

How we built it

We started by creating mid-fidelity wireframes for the main screens using Figma. After incorporating high-fidelity changes into the interface, we handed off the designs to the engineers for development. Our app makes predictions on images of suspicious lesions. A difficulty in training an accurate model is not having enough data, so we used transfer learning, which is taking a pre-trained model that is robust and modifying it to a similar problem with less data (image classification). We used AlexNet, a CNN trained on over a million images, and changed the last two linear layers since AlexNet makes predictions on 1000 categories, while the HAM 10000 dataset only had 7 categories, so we wanted 7 nodes on our output layer. For front end development, we utilized Flutter, a cross-platform mobile app development framework.

Challenges we ran into

This was all of our first experiences competing at a hackathon within a cross-functional team, so there were challenges in ensuring a seamless collaborative workflow. Designers also overestimated the developers‚Äô background with Figma, which resulted in some miscommunication properly translating Figma wireframes into development.

There were also technical challenges in training our model to recognize potential skin conditions.

Accomplishments that we're proud of

We‚Äôre proud that we were able to hack for 24 hours straight and persevere to the end. Regardless of our challenges integrating our designs into the development, we were able to communicate well as a team and supported each other‚Äôs challenges and achievements. We were able to gain more experience using AlexNet and Flutter, as well as a better understanding of the design process. 

What we learned

After this experience, we learned the importance of prioritizing certain parts of the product production process, like creating initial screens for the developers to begin integrating. We also ran into some miscommunication between the designers and developers, so this allowed us to gain more knowledge working cross-functionally for the future. 

What's next for SkinScreen

Our next step is to explore other deep learning models more suitable for our product‚Äôs purpose in order to analyze and generate more accurate and extensive results. We also hope to conduct more usability tests and user research to guide future design iterations for SkinScreen. 
","https://www.figma.com/file/vEEg1RwwWM3TE3iTw2HtFS/HackDavis2024?type=design&node-id=1%3A2&mode=design&t=K4ypIFo32BVcTzxi-1, https://www.figma.com/proto/vEEg1RwwWM3TE3iTw2HtFS/HackDavis2024?type=design&node-id=67-520&t=X7ljhjrM0AIIQ6dK-1&scaling=scale-down&page-id=1%3A5&starting-point-node-id=67%3A520&mode=design, https://github.com/simondgooden/SkinCancer",,"Best Beginner Hack, Best Interdisciplinary Hack, Best Health Hack, Best Overall Design","alexnet, flutter, figma, intel-gpu",Victoria,Vo,victoriaxvo@gmail.com,,Best Interdisciplinary Hack,Best Health Hack,Best Beginner Hack,University of California - Davis,3,Jolina,Huang,jolinahuang05@gmail.com
nomad /\,132,https://hackdavis-2024.devpost.com/submissions/511313-nomad,Submitted (Gallery/Visible),Pending,Submit,04/28/2024 13:55:07,"Problem Statement üôã‚Äç‚ôÇÔ∏è

‚ÄúHow can we effectively address the pressing issues of homelessness and lost animals in our communities, ensuring swift assistance and improved well-being for those in need?‚Äù

Inspiration üí´

As I stroll down the streets of downtown Davis, whether I‚Äôm grabbing boba at Lazi Cow or sitting around the bonfire at Davis Commons, I always run into a homeless person. Homelessness is becoming a rising issue in Davis and we wanted to find a way to support them in any way they need.

On my bike ride home, every now and then I see a stray cat skittering across the street and I wonder if they are frantically trying to find their way home. Even in the apartment complex I live in, there‚Äôs a posse of black cats that always lounge around.
Sometimes, good samaritans would leave food out for these stray animals but that‚Äôs not a stable way for those cats to get the support they need.

Although very different issues, they both ultimately boil down to helping those who are displaced by providing them with the resources they need. Our group aims to find an innovative way to find and support these groups.

What it does üìç

When a user spots a homeless person or a lost animal, they can drop either a person pin or an animal pin respectively, alerting the nearest relevant organization to the pin location. If a homeless shelter or food bank gets a couple of pin notifications for the same area, they can make a trip to the location to provide the individual(s) with food and supplies, while also informing the individual of the organization‚Äôs location if they want additional support. Animal Shelters can use the pin notifications to track down and rescue lost animals. The app also offers features that allow you to volunteer and donate to these organizations and provides you exclusive coupons for Davis businesses for using the app. 

How we built it üõ†Ô∏è

Our User Interface was designed in Figma and further implemented with React Native on the front end and Firebase for the backend/database connection.

We decided to build 3 main pages: the Map page, the Shelter page, and the Profile page. 

On the Maps page (our default home page), we used the Google Maps API in react native to display our map and used custom pins with a geolocator for user location to show pins dropped by other users, pins for the shelters, and a map centered around the user‚Äôs location. We used a Haversine distance algorithm to find the shelter closest to our dropped pin and used the React native Linking library for email functionality. Additionally, we also used reverse geolocation to find the address of the dropped pins from their latitude and longitude to give the shelters as much valuable information as possible. We developed the UI using a stack navigator and had draggable pins to customize the dropped location as well as a field to enter a custom message to be sent to the designated shelter. All of these functions get updated in real time so whenever a new drop is posted, all users are able to see it on their map within seconds.

On the Shelters page, we developed a list of the food banks and homeless shelters in the area on one tab and a list of animal shelters on another tab. We can tap on one of these cards in the list to get a further description view with buttons that allow you to either volunteer or donate.

Lastly, the profile page has the user's basic information about their Avatar(initials), name, dropped pins, volunteer opportunities, and coupons. The coupons provide an incentive for users to continue being aids to their community by giving them deals for their confirmed pins. The volunteer opportunities are there for users to give back to the community in addition to using the app. For the login page, we decided to use Firebase Google Authentication and connected it to the implemented Figma design for a seamless UI.

Challenges we ran into üò∞

One of the biggest challenges we faced is narrowing down the scope of the project. On the development side, figuring out the map functions like dropping pins and getting user locations was very difficult given the time constraint. There were many features we wanted to implement in the ideation phase but as the project progressed, we realized that we have been overambitious in our pursuits. We overcame this by discussing the essence of our project and prioritized the features that aligned with our goal: supporting displaced groups.

Accomplishments that we're proud of üòÅ

We are very proud of how cohesively we worked together, like a well-oiled machine. The team got to learn new things, hone their skill-sets, and get out of comfort zone to progress ourselves not only technically, but spiritually üôè.  

What we learned üìö

We learned how to develop a full mobile application, implemented from a Figma design with a design system in place. We also got to learn more about developing a pitch and learned how to work in a collaborative setting with a PM, Designer, and Developers, creating a unique workflow. 

What's next for nomad /\ üîÆ

nomad is not done yet! We hope to continue by developing the moderator side for the mobile application, allowing shelters to be able to have a view with pertinent information. Furthermore, we hope to implement computer vision and identification models to be able to take a photo from the user when pinning an animal, and classifying the animal, its breed, and features in the picture to help with the search! 
","https://github.com/Yatsz/Nom.a.d., https://www.figma.com/file/O01rTTxycF7Eo6uZTINcos/nom.a.d.-hack-davis-2024?type=design&node-id=0%3A1&mode=design&t=K9KNRexJJSUWFB9u-1",https://youtu.be/TBT2eJWqjDI,"'	Best Hack for Social Justice, Best Overall Design, Best Hack for Life of Kai, Best Hack for DCMH","react-native, firebase, google-maps, geolocator, html/css, javascript, github, expo.io, figma, xcode",Daniel,Kim,hyunkim03@gmail.com,,Best Hack for DCMH,Best Overall Design,'	Best Hack for Social Justice,University of California - Davis,3,Danielle,Koay,ddaniellekoay@gmail.com
MoodMatch,56,https://hackdavis-2024.devpost.com/submissions/511316-moodmatch,Submitted (Gallery/Visible),Pending,Submit,04/28/2024 14:01:38,"Inspiration

Our teammate has worked with people with autism and has noticed how difficult it is to communicate with others not on the spectrum. We hope that this app will help increase their confidence without judgment, ultimately making them feel less frustrated explaining their thoughts to others.

What it does

MoodMatch allows its users to identify and practice facial expressions with the power of AI. Its advanced recognition software using a front-facing camera allows users to look at the guide to try and practice increasing their score matching to the prompt.

How we built it

We used a facial recognition API from Apple and React for the web application portion. 

Challenges we ran into

We spent some time getting the percentage of emotion shown on the screen, as well as some UX functionalities on the front end.

Accomplishments that we're proud of

We are proud of using a facial recognition API to combat an issue that most people overlook. The time spent researching case studies of people on the autism spectrum allowed us to gain a broader perspective of who our audience is. 

What's next for MoodMatch

We hope to allow users to also chat with a chatbot to increase engagement, as well as implementing a tasks functionality to conquer the overwhelmingness of completing tasks. We also hope to add more emotions, or a combination of emotions.
",https://github.com/arianna-y/moodmatch,,"Best AI/ML Hack, Best User Research","react, ai, javascript",Arianna,Yuan,yuan.arianna@gmail.com,,Best AI/ML Hack,Best User Research,Best Entrepreneurship Hack,,0,,,
Resourcely,7,https://hackdavis-2024.devpost.com/submissions/511318-resourcely,Submitted (Gallery/Visible),Pending,Submit,04/28/2024 14:03:34,"Inspiration

Over the past year, California has faced a series of severe winter storms and atmospheric disturbances, leading to widespread flooding, power outages, and critical shortages of essential resources. The limitations of government assistance, largely confined by geographical reach, have often left communities to rely on the mutual support of neighbors and friends to meet their basic needs for food, water, and safety.

What it does

Resourcely is a peer-to-peer platform designed to facilitate the sharing of resources and essential items during emergencies. Our app allows users to request specific resources like medical aid, food, and water and connects them with nearby community members who can provide these necessities. Key features include a real-time news landing page, a local news and requests feed, user profiles, and a map showcasing nearby resources.

How we built it

Throughout development, we encountered several challenges, particularly with the user interface design and backend integration, as our team lacked prior experience with React. To address complex routing issues for a multi-layer, multi-user web application, we incorporated mock data to expedite the MVP development, helping users quickly grasp the value of our product.

Challenges we ran into

Throughout development, we encountered several challenges, particularly with the user interface design and backend integration, as our team lacked prior experience with React. To address complex routing issues for a multi-layer, multi-user web application, we incorporated mock data to expedite the MVP development, helping users quickly grasp the value of our product.

Accomplishments that we're proud of

We are immensely proud of completing the entire user interface despite our initial lack of React expertise. Developing a solution to a problem we've personally experienced has been incredibly fulfilling. Our MVP includes features like resource mapping, alerts, user profiles, and a dynamic news feed with interactive visuals, all designed to maximize user assistance and information accessibility.

What we learned

This project significantly enhanced our skills in front-end and full-stack development, particularly in crafting user-friendly interfaces and tackling complex software challenges. We adopted a problem-solving approach that involved breaking down complex issues into manageable tasks and collaborating effectively to address them.

What's next for Resourcely

We are developing a hardware component that enables peer-to-peer communications via a Raspberry Pi and smartphone connection, creating a mesh network that operates independently of Wi-Fi. This will be crucial for disaster-stricken areas lacking conventional communication infrastructure. Additionally, we are focusing on scaling our backend to accommodate real users and integrate actual data streams for news and resource updates.
","https://github.com/AnwarMP/Resourcely, https://deployedresourcely.vercel.app/",https://www.youtube.com/watch?v=_0IzvlbSVNg,"Best Health Hack, 	Best Hack for Social Justice, Best Overall Design","express.js, react, javascript, html5, css3, node.js, vercel, dns, mapkit",Anwar,Mujeeb,ibnmujeeb2003@gmail.com,,Best Health Hack,Best Hack for Social Justice,Best Overall Design,San Jose State University,1,Russell,Semsem,semsemrussell@gmail.com
Speak Up!,155,https://hackdavis-2024.devpost.com/submissions/511322-speak-up,Submitted (Gallery/Visible),Pending,Submit,04/28/2024 14:13:26,"Inspiration

One of our team members is hard of hearing, and this project would make it easier for her to ask people to speak up without interrupting them. 

What it does

This MCU uses the sound sensor to detect audio levels. If the sound level is about the same as the background noise level, the LED display will let the speaker know that the user cannot hear them. 

How we built it

We used the Arduino IDE to program and upload our code to our Arduino UNO R4 Wifi microcontroller. The program first samples the noise level when the Arduino is booted up to create a baseline sound level. It then continuously compares the current sound level with the baseline. The user can hit the Reset button on the Arduino to recalibrate the microcontroller if things change.

Challenges we ran into

Two of our integral components broke while we were working with them, which forced us to switch directions midway through the project.

Accomplishments that we're proud of

We are proud that we overcame our limitations in hardware and supplies.

What we learned

We learned that if a component never seems to power on no matter who is using it, it is probably broken.

What's next for Speak Up!

We wish to connect the board to a server and make the noise level threshold configurable by the user via a web app. Additionally, the microphone used in this prototype is only capable of measuring sound level, but by using a higher quality microphone, we may be able to isolate voice frequencies for comparison, in the case that there is sudden whirring or rumbling that may affect the functioning of the microcontroller.
",https://github.com/PuffyDucks/hearing-indicator/blob/aa830e6e1aea179282f7a47b6b6e46112b1f9011/hearingindicator.ino,https://youtu.be/GOPTjOk0oTc,"Best Health Hack, 	Best Hack for Social Justice, Most Creative Hack, Best Hardware Hack","c++, arduino, coffee, git, microcontroller, microphone",Victoria,Lam,viclam@ucdavis.edu,,Best Hardware Hack,Best Hack for Social Justice,Best Health Hack,University of California - Davis,2,Naomi,Zhao,ntzhao@ucdavis.edu
LockIN,117,https://hackdavis-2024.devpost.com/submissions/511334-lockin,Submitted (Gallery/Visible),Pending,Submit,04/28/2024 14:25:12,"Inspiration: Half of our team has ADHD and struggle to focus especially during class and doing work. We have a hard time recognizing when we are distracted and are not able to get back on task.

What it does: The app measures heart and respiratory rates and uses a threshold based on an individual's data to detect distractibility. When the threshold is detected, the apple watch will send a small buzz to curb the distraction and get the user back on task.

How we built it: We developed an iOS app using ""XCode"" and collected data on the rates from the Health App available on the watch. Using the data, we compare the heart rate and respiratory rate to the certain threshold we set, determining whether or not the user was ""distracted"" or ""focused.""

Challenges we ran into: Utilizing the new software, ""Xcode,"" proved to be very difficult for our team. All of us were unfamiliar with the language that the software used, and the inner workings of how to connect devices to the software was something that we had to research extensively. But, we persevered, and were able to successfully render a working prototype within the app.

Accomplishments that we're proud of: We are very proud of the idea we came up with and how we executed it through the application. It is a very daunting task to come up with an executable plan from such a broad task, and we are proud of how hard we tried and the dedication we had.

What we learned: We learned so much about Xcode and the inner workings of the application. This is incredibly useful for the team because if any of us want to develop our own applications, we now have the tools and knowledge to do so.

What's next for LockIN: We would like to export the app itself to an actual apple watch, in order to see it work in real time with real data. Additionally, we would like to clean up the display and add UI.
",https://github.com/lianapg/HackDavis24/tree/main,,Best Beginner Hack,"swift, xcode",Liana,PG,lianapg@gmail.com,,Best Beginner Hack,Most Creative Hack,Best Interdisciplinary Hack,University of California - Davis,2,Nelsen,Young,njyouny@ucdavis.edu
CauldronCreates,28,https://hackdavis-2024.devpost.com/submissions/511336-cauldroncreates,Submitted (Gallery/Visible),Pending,Submit,04/28/2024 14:26:37,"Inspiration

As a college student it can be hard to manage time to constantly cook healthy meals. A lot of time I get  hungry, check the fridge, and then instantly closing it after realizing I don't have any food. With this web app, I can get recommended a tasty and nutritious dish to make based off what limited ingredients I have on hand. 

What it does

A user simply inputs all their ingredients they have in their ""fridge."" When ""Brew Something New"" is clicked, AI creates a recipe with instructions based off what ingredients they have. The user can see how many calories the dish has and choose if they want save the recipe to the ""My Recipes"" panel. 

How we built it

We created a web app using react.js, express.js, and mySQL for the backend. We used OpenAI for to create recipes and dishes.

Challenges we ran into

The challenges we ran into were designing the web app because we don't have much design experience.

Accomplishments that we're proud of

We are proud of what we were able to accomplish with our design and implementations with OpenAI

What we learned

We learned how to use react.js

What's next for The Cauldron

Some features that we would have would be for users the be able to create their own recipes. We also had the idea of also adding other user recipes to your own library. Another possible feature would be also to input expiration dates on ingredients and then have a tab that shows what ingredients are expiring soon. If possible, the AI would also prioritize ingredients that are almost expired.  
",https://github.com/wtrantan/HackDavis,,"Best Health Hack, Best AI/ML Hack, Best Use of .Tech Domain Name","javascript, mysql, express.js, react, openai, chatgpt, amazon-web-services",Danny,Kuei,kuei.danny@gmail.com,,Best Health Hack,Best Use of .Tech Domain Name,Best AI/ML Hack,"University of California - Davis, University of California - Merced, San Jose State University, University of California - Berkeley",3,William,Trantan,wtrantan@gmail.com
GrantMe,27,https://hackdavis-2024.devpost.com/submissions/511337-grantme,Submitted (Gallery/Visible),Pending,Submit,04/28/2024 14:27:27,"Inspiration

We are avid users of e-commerce platforms like eBay and Depop, where individuals can list and sell items. However, we noticed a gap in these platforms' offerings‚Äîthere's no straightforward way to trade items directly. That's why we created GrantMe. Our platform revolutionizes the buying process by enabling buyers to propose trades using their own items as currency. Buyers can now send offers comprising one or more items to sellers, opening up new possibilities for exchange and making each transaction uniquely valuable.

What it does

GrantMe is a trading platform for college students that allows them to trade items with each other. We offer two options, trading with an item or offering cash.

How we built it

We used Sveltekit as the framework and supabase for the database.

Challenges we ran into

We had difficulties setting up our database correctly to track trading history.

Accomplishments that we're proud of

We are proud of our UI design.

What we learned

We expanded our knowledge on Sveltekit as well as the process of dividing work into a team

What's next for GrantMe

We will work on adding services instead of items that people can sell, such as offering car washes or cleaning services.
",,,"Best Use of .Tech Domain Name, Best Entrepreneurship Hack","sveltekit, supabase",maxhsieh08,Hsieh,maxhsieh0@gmail.com,,Best Use of .Tech Domain Name,Best Overall Design,Best Entrepreneurship Hack,"University of California - Irvine, San Jose State University",2,gurshan,Warya,rkwarya@gmail.com
DCHM App,18,https://hackdavis-2024.devpost.com/submissions/511340-dchm-app,Submitted (Gallery/Visible),Pending,Submit,04/28/2024 14:30:43,"Seeing all the good that DCMH has done for our community and reading user testimonials really touched us. We were really inspired by the work they do and want to ensure nothing hinders their operations. We want to help DCMH overcome any potential challenges so that they can efficiently continue to distribute aid. We believe in their mission to provide low-income and homeless individuals and families with housing, food, and human services to help them rebuild their lives.

We wanted to create something that could directly and effectively address the main issues they are facing in order to help them make an even bigger difference in our community.
","https://www.figma.com/file/uPaczhDJs8bwBxJbP2OPKN/Community-Meals-App?type=design&node-id=57-687&mode=design&t=VS1v5XnRjg9Of3Ac-0, https://www.canva.com/design/DAGDuDzreos/O_24ItQ-XTMGZZvFQ6yJjg/edit?utm_content=DAGDuDzreos&utm_campaign=designshare&utm_medium=link2&utm_source=sharebutton",,"Best UI/UX Prototyping, Best Overall Design, Best User Research, Best Hack for DCMH","food, figma",Matthias,Gabel,mjgabel@ucdavis.edu,,Best Hack for DCMH,Best User Research,Best UI/UX Prototyping,"University of California - Davis, UC Davis",3,Agnes,Aragones,ataragones@ucdavis.edu
Purrfect Match,33,https://hackdavis-2024.devpost.com/submissions/511344-purrfect-match,Submitted (Gallery/Visible),Pending,Submit,04/28/2024 14:35:31,"Inspiration

Seeing the Life of Kai presentation, we were inspired to do something for animals in need. We explored their website and stumbled upon Snowy and Dusty‚Äôs story, where they were sent to animal rescues and continuously rehomed. To avoid this, we wanted to come up with a solution that could decrease animal rehoming by ensuring that owners knew about their compatibility with a shelter animal and its traits before bringing it home. In addition, we wanted to make it fun in order to encourage people to adopt instead of shopping for their companions, especially when animals who deserve a second chance are being put down in shelters every day.

What it does

Inspired by dating apps which aim to match compatible people based on profile information, our app aims to reduce the number of animals needing to be rehomed by matching them with owners they are more likely to find forever homes with. They will be able to scroll through the different animals in shelters in their area to view their compatibility, traits, and environments they thrive in. They can send them hearts and nudge them to ask the shelter for a playdate before adoption. Our prototype outlines the structure of the app and its main features. 

How we built it

The app prototype was built in Figma. The webpage prototype was coded in HTML and CSS. 

Challenges we ran into

One challenge we ran into was making this a distinct app that solely helped out shelter pets find a home. When we were pitching our idea, a lot of people were stuck on the fact that we were designing a play on a dating app, bringing up issues of only the cutest pets getting adopted. We wanted to curate our app prototype so that it had more of an homage to dating apps and not an exact replica of one. We also ran into issues of creating the code and designing some of the graphic elements, but most of these issues were overcome within the time we had. 

Accomplishments that we're proud of

We‚Äôre all beginners to the technology that we used in this hackathon, so we‚Äôre proud of the learning we were able to do and the product that we were able to put up with time restraints and little experience. 

What we learned

We learned a lot during this process! One of our main takeaways was to be ok with not everything being perfect- we had to scrap a lot of good ideas due to time and ability. We also perfected our Figma skills. 

What's next for Purrfect Match

The majority of our app and the pages/features we wanted to include are still in the prototype phase. We will continue to develop the software for our app to have a fully functioning product. Our prototype also focuses on the pet owner‚Äôs end, so we will continue to develop features for shelter organizers to easily view owner profiles and match their pets with loving owners. To add on, we will implement our Save a Life section, which lets the user swipe through shelter animals that are about to be put down to give them one last chance.
",https://www.figma.com/proto/jCWy1iCHixhaQ21C7BodvG/HackDavis-2024?type=design&node-id=23-26&t=VZuIfwwlLFMpN1m5-1&scaling=scale-down&page-id=0%3A1&starting-point-node-id=23%3A26&mode=design,https://youtu.be/LaPOg60igOI,"Best Interdisciplinary Hack, 	Best Hack for Social Justice, Most Creative Hack, Best Overall Design, Best Hack for Life of Kai","html5, figma, css, github",Manushri,Rane,manushri.rane@gmail.com,,Best Overall Design,Best Interdisciplinary Hack,Best Hack for Social Justice,University of California - Davis,3,Isabel,Wade,isabelwade611@gmail.com
EventSync,108,https://hackdavis-2024.devpost.com/submissions/511345-eventsync,Submitted (Gallery/Visible),Pending,Submit,04/28/2024 14:37:34,"Inspiration

The sheer number of events on a university's campus can be overwhelming to keep track of and it can be hard to find information about events that are going on. Many turn to social media to find out information about campus events, but this makes it so that people who choose not to use social media such as Instagram or Facebook are at a disadvantage when finding on-campus events. 
On top of this, an overwhelming number (close to 50%) of 18-24-year-olds reported having symptoms of anxiety and/or depression in 2023, according to the Census Bureau's Household Pulse Survey. Social anxiety is a specific type of anxiety that many young adults may experience, and it can make it extremely hard to build or maintain friendships and other relationships. From personal experience, I have seen countless people take to an anonymous app called YikYak to share their experiences of being scared to attend events because they didn't have anyone to go with. This is where EventSync comes in.

What it does

This web app focuses on helping provide a simple way for university students to easily be matched with campus events specifically relevant to their interests. After they are given options for campus events, they can optionally select whether they are interested in attending these campus events. This is where the second main feature comes in. Finding people to go with can be a challenge in itself, which is why EventSync aims to help facilitate this process, letting people request to message other people who are also interested in going to the event. Through this messaging, the idea is that people will be able to meet each other prior to an event and attend together if they feel like they may be a good match. 

How we built it

The UI/UX was built using Figma. The backend uses Springboot and is connected to a MongoDB database. The database has 3 collections to hold user profile information, the user's quizzes that detail their preferences for events, and the events collection to hold all events that students can attend. The frontend uses React and is designed to create a seamless user interface that takes in a user's input such as their name and basic information, along with preferences that will be collected via a fun quiz to provide them with a list of events that would appeal to them. 

Challenges we ran into

Our main challenge was to bridge the gaps between the UI/UX prototype, backend development, and frontend development. 

Accomplishments that we're proud of

We are proud of the Figma prototype and the backend functionality.

What we learned

We learned new creative ways of trying to bridge the gaps between UI/UX, backend, and frontend. We also are a very diverse set of people in terms of skills, so being able to work together and help each other with new things was super enriching for us. 

What's next for EventSync

We hope to keep working on EventSync to make it into a fully functioning app that can be implemented on university campuses, such as UC Davis. 
","https://github.com/mrcyrilgoud/EventSync_Backend, https://www.figma.com/proto/N0bfpTmGV6pNiYfIbkmVEo/HackDavis-2024?page-id=2%3A2&type=design&node-id=19-206&viewport=233%2C77%2C0.08&t=PCluzAXhuY2PyT1w-1&scaling=scale-down&starting-point-node-id=40%3A1493&mode=design, http://github.com/radixsh/hackdavis2024",,"Best Interdisciplinary Hack, Most Creative Hack, Best UI/UX Prototyping, Best Overall Design","mongodb, .tech, atlas, figma, anima, java, javascript, react, springboot, postman, xcode, copilot",Melanie,Born,maborn@ucdavis.edu,,Best UI/UX Prototyping,Best Interdisciplinary Hack,Most Creative Hack,University of California - Davis,0,,,
RecycleHub,8,https://hackdavis-2024.devpost.com/submissions/511348-recyclehub,Submitted (Gallery/Visible),Pending,Submit,04/28/2024 14:38:59,"Inspiration

Our passion for environmental sustainability and our frustration with the inefficiencies in current recycling systems inspired us to create RecycleHub. We wanted to make recycling not only more accessible but also rewarding, incentivizing people to contribute positively to the environment.

What it does

RecycleHub is an innovative app that enhances the recycling process by allowing users to quickly identify recyclable items through photo recognition, locate nearby recycling facilities, and earn rewards in the form of EcoCoins. These coins can be redeemed for discounts at local grocery stores, encouraging users to recycle more.

How we built it

We begin by creating a server using MongoDB and Python, which allows us to upload images and download text information. Next, we develop an application using Swift and SwiftUI. Subsequently, we integrate the ChatGPT API with our project backend to enable responses from ChatGPT. Finally, we connect to the server to retrieve the text information for frontend use.

Challenges we ran into

One of the major challenges was ensuring accurate image recognition for a wide variety of waste items, as well as integrating real-time data for recycling locations. Another challenge was creating an engaging yet simple user interface that would appeal to all age groups.

We also encountered several technical issues. For example, integrating the ChatGPT API into our backend and testing our server to ensure its functionality required substantial time. As this was our first project integrating backend and frontend components, we faced numerous challenges, including a lack of familiarity with the underlying principles.

Accomplishments that we're proud of

We are the first-time participants in a hackathon environment and managed to create a fully functional prototype. Our team effectively integrated technologies including AI for image recognition, which was a steep learning curve for us. Additionally, our EcoCoin reward system has already led to a measurable increase in recycling rates among our users. Our ability to forge successful partnerships with local businesses has also been a great achievement.

What we learned

Technically, we learned a great deal about integrating various APIs, managing a backend server, and developing in SwiftUI, which are all skills that will benefit us in future projects.

What's next for RecycleHub

Looking ahead, we plan to expand RecycleHub to more regions and incorporate more advanced AI features to improve item recognition accuracy. We also aim to enhance the reward system to include more partners and diverse incentives. Furthermore, we will explore options for using the collected data to contribute to larger environmental research and advocacy efforts.
",https://github.com/microzen/garbage-classification,,"Best Beginner Hack, Best Interdisciplinary Hack, 	Best Hack for Social Justice, Best Entrepreneurship Hack","swiftui, figma, mongodb, swift, chatgpt, chatgptapi, python, flask, restfulapi",Kayla,Su,kayla04@berkeley.edu,,Best Beginner Hack,Best Interdisciplinary Hack,Best Hack for Social Justice,"University of California - Berkeley, American River College",4,Jiarui,Shu,shujr29@berkeley.edu
Heart Haven,121,https://hackdavis-2024.devpost.com/submissions/511349-heart-haven,Submitted (Gallery/Visible),Pending,Submit,04/28/2024 14:41:01,"What it does

Heart Haven has created a application to assess individuals based on their living factors in order to predict their likely good.

How we built it

We based our development on our Machine Learning Model on a dataset of heart diseases and their contributing factors. To do this we utilized Flask in order to have Python backend and utilized HTML, CSS, JS for our front-end. To assist our front-end development we utilized Figma to draft different logos and web application work flows.

Challenges we ran into

Fine tuning our MLM, such as improving accuracy of our model by 14%. A challenge for setting up the web application was creating the pipeline of information from back-end to front-end in order display information pertaining to the user.

Accomplishments that we're proud of

Creating a 3 Tier Application, that includes a front-end, back-end, and MLM.

What we learned

How to communicate through different roles of the team. We learned to create a workflow such that everyone was given a task to work on, without being too dependent on the output of others. Learned to utilize Flask for a backend so that we are able to use Python code in the back-end.

What's next for Heart Haven

Creating more personalized information of what the individual can do based on their results.
Deploy our application on a server so it can be accessed by a larger population.
",https://github.com/saeenppatil/HeartHaven/tree/main,https://youtu.be/mpRASY6PVuU,"Best Interdisciplinary Hack, Best Health Hack, Best User Research, Best Statistical Model","python, pytorch, html, css, javascript, mlm, flask",Jason,Ma,jasonbma317@gmail.com,,Best Statistical Model,Best Health Hack,Best Interdisciplinary Hack,University of California - Davis,3,Ethan,Chang,ethanchangy29@gmail.com
Newton-Notes,42,https://hackdavis-2024.devpost.com/submissions/511350-newton-notes,Submitted (Gallery/Visible),Pending,Submit,04/28/2024 14:41:40,"Inspiration

Introducing Newton Notes, born from the frustration of missed details in fast-paced lectures and the limitations of traditional note-taking. Inspired by the need for accessible and efficient learning tools, Newton Notes utilizes cutting-edge natural language processing to transcribe lectures in real-time, simplifying the note-taking process. With a focus on accessibility, it organizes content for easy review, allowing users to organize their notes from all classes. Say goodbye to missed moments and hello to streamlined note-taking with Newton Notes.

What it does

""Newton Notes"" enhances academic performance by transcribing spoken lectures in real-time, ensuring no detail is missed. With sophisticated natural language processing, it structures notes for quick access and review, and features smart summaries for efficient study. Its synchronized platform across devices promotes a seamless learning experience. Designed for inclusivity, Newton Notes supports a range of learning styles, streamlining the path to knowledge.

How we built it

Newton Notes leverages Google Cloud's NLP models through its API to revolutionize note-taking, with an added boost from the GPT API to structure transcribed information into Cornell Notes format. Our system integrates Prisma ORM and MongoDB for optimal data management, while the user interface is developed with Next.js and Shadcn/UI for a seamless, interactive experience. State management is streamlined via Zustand, and data retrieval is facilitated through Axios and useSWR. At the end of each lecture, the GPT API compiles three key points to highlight the most crucial takeaways, ensuring that Newton Notes is not only robust but also highly effective in delivering real-time, structured educational content transcription.

Challenges we ran into

Building ""Newton Notes"" presented significant challenges, particularly in full-stack development. Our team worked diligently to seamlessly integrate various APIs into our product, ensuring they functioned harmoniously to deliver real-time transcription and note formatting. Additionally, we faced difficulties with our database system, specifically in storing and retrieving the formatted notes efficiently. These challenges required innovative problem-solving and persistent refinements to enhance the functionality and robustness of Newton Notes.

Accomplishments that we're proud of

We are incredibly proud of the accomplishments achieved with Newton Notes. Thanks to the hard work and dedication of our team, we have developed a fully functional product that not only performs exceptionally but also boasts a visually stunning user interface. 

What we learned

Prisma 
MongoDB 
Next.js (with route handler version) 
Shadcn/UI 
Zustand 
Axios 
useSWR 
Natural Language Processing (NLP) 

What's next for Newton-Notes

Initially, we embarked on training our own model using the open-source DeepSpeech product. Despite our best efforts, we faced significant challenges, particularly with connectivity issues in the Intel Developer Cloud, which hindered our progress. Moving forward, we are excited about the potential of implementing a new feature that would allow audio files to be directly transcribed. This development would significantly enhance the utility of Newton Notes, making it even more versatile and user-friendly.
","http://newton-notes.tech/, https://github.com/rayzhuca/newton-notes",https://www.youtube.com/watch?v=kr3LSOPwRU0&feature=youtu.be,"Best Beginner Hack, Most Creative Hack, Best AI/ML Hack, Most Technically Challenging Hack, Best Overall Design, Best Use of .Tech Domain Name, Best Entrepreneurship Hack","prisma, mongodb, next.js, with, route, handler, version), shadcn/ui, zustand, axios, useswr, nlp)",Dhruv,Sharma,sharma.dhruv268@gmail.com,,Best Entrepreneurship Hack,Best AI/ML Hack,Best Beginner Hack,"University of California - Davis, University of California - Santa Cruz",2,Kyle,Luo,kyle.luo.518@gmail.com
Just Moove!,66,https://hackdavis-2024.devpost.com/submissions/511353-just-moove,Submitted (Gallery/Visible),Pending,Submit,04/28/2024 14:46:06,"Inspiration

According to the National Institutes of Health, about 35% of people over 70 and nearly all people over 85 experience mobility limitations that impact their ability to complete daily tasks with confidence and ease [1]. This loss of mobility significantly reduces elders‚Äô quality of life and puts them at an increased risk for injury. The NIH suggests tackling this loss of mobility by partaking in low-impact, steady-state physical activity. What better way to do this than dance! 

Our dance game generates a choreography representation from a source video. Then, the user‚Äôs movement and form are compared to the original video. Not only can this be used for dance videos, but also weight-lifting and other fitness videos where form and physical movement are key.  

Dancing games break expectations for user interfaces. There are no checkboxes or dropdowns; you Just Moove! We designed this platform to be as accessible as possible, ensuring that there is a high-contrast UI with clutter-free frames so players can utilize the platform to its fullest potential. The scoring component also provides an addictive element to the game that ensures continued engagement and fun!

[1] Freiberger, Ellen et al. ‚ÄúMobility in Older Community-Dwelling Persons: A Narrative Review.‚Äù Frontiers in physiology vol. 11 881. 15 Sep. 2020, doi:10.3389/fphys.2020.00881

What it does

Just Moove! first asks the player to pick a video from a library. While playing, the user will see themselves alongside the video, both with an overlay of a ‚Äúskeleton‚Äù used to track and compare their movements. The game then generates a score by tracking their overall accuracy and form. 

How we built it

Just Moove! is powered by an AI algorithm trained to identify and scale human features, which is what results in the ‚Äúskeletons.‚Äù On top of this algorithm, we designed a scoring system rooted in min-max normalization and cosine similarity. To make our game extendable to other videos on the internet, we also developed a system for scraping, trimming, uploading, and tracing videos with the AI algorithm. 

Challenges we ran into

We wanted to accelerate our game with a GPU, but learned that our underlying ML library, mediapipe was not compiled with GPU support. We changed gears by optimizing the pose-fitting inference for CPUs. We minimized the number of ‚Äúlandmark‚Äù points identified by the model and saved work by processing videos before any real time movement begins.

Accomplishments that we're proud of

We achieved real time motion tracking, even on older laptops! We have an excellent user interface. We devised a scoring system that visibly incentivizes movement that matches the source video. The end product largely provides a self-contained, complete experience. We think that there is real room for social benefit.

What we learned

Figma, OpenCV, pygame, user interaction, troubleshooting GPU hardware acceleration, motion capture paradigms

What's next for Just Moove!

We can allow users to upload any video they want. We got really close to achieving this. Speed control would also be a useful feature. The skeleton rendering is somewhat basic and could be made to look nicer.
",https://github.com/ExtraConcentratedJuice/JustMoove,https://youtu.be/lcBO5l1fiUk,"Best Health Hack, Most Creative Hack, Best Overall Design, Best Interactive Media Hack","python, pygame, skellytracker, mediapipe, figma",nate,buttke,nategb@protonmail.com,,Best Health Hack,Best Interactive Media Hack,Most Creative Hack,University of California - Davis,3,j3llery,,justine.ellery@gmail.com
RecycleThis,86,https://hackdavis-2024.devpost.com/submissions/511355-recyclethis,Submitted (Gallery/Visible),Pending,Submit,04/28/2024 14:46:45,"Inspiration

Recycling is a vital part of the sustainability movement, but confusion often arises about what materials are recyclable. Every day we face dilemmas like ""Is this mango juice bottle recyclable?"" or ""Can this food tray be composted?"" that make sorting trash even more challenging. To address this confusion and make responsible disposal easier, we developed a solution that helps people accurately recycle and compost their waste. This initiative not only simplifies the recycling process but also supports the broader movement towards reducing plastic waste. 

What it does

Our application is a basic web app that allows users to snap a picture. Our AI model then identifies and categorizes the trash items into three broad categories: recyclable, compostable, and landfillable. The app is hosted on a .tech domain and has PropelAuth for authentication. 

How we built it

We built this app using ReactJS, Python FastAPI, and Google's Gemini AI Model. The website is hosted on a .tech domain and user authentication is hosted through PropelAuth. The application is hosted on an Amazon AWS EC2 instance. 

Challenges we ran into


Trouble with nginx configuration for SSL encryption to secure our website 
Trouble with setting up and configuring PropelAuth 
Connecting to the production environment for deployment (Amazon EC2)
Had a lot of difficulty trying to make React Native use the native camera of a mobile phone, so had to migrate to a ReactJS web-app. 


Accomplishments that we're proud of


Secure deployment with SSL to a .tech domain 
Successful image classification using Google's Gemini Pro (tuned using prompt engineering)
Simple and intuitive frontend with 3D graphics


What we learned

We practiced thinking with an entrepreneurial mindset so we could plan and create an impactful product. Our project required us to learn new technologies, including the Google Gemini API, the Propel Auth API, and Fast API, the backend framework.

What's next for RecycleThis

We plan to create a native mobile app version to maximize convenience. We also plan to encourage user engagement with exciting new features like a leaderboard ranking users by items recycled or personal stats summarizing the user's scan history. An improved UI would also increase accessibility and user experience.
","https://recyclethis.tech, https://github.com/nima64/hackDavisFrontend, https://github.com/aashay322/hackdavis-2024-proj",,"Most Creative Hack, Best AI/ML Hack, Best Use of .Tech Domain Name, Best Use of PropelAuth","react, javascript, fastapi, propelauth, three.js, python",Kayla,Le,kaylale2014@gmail.com,,Best Use of .Tech Domain Name,Best Use of PropelAuth,Most Creative Hack,"California State Polytechnic University - Pomona, Cosumnes River College, University of California - Santa Barbara, College of Marin",3,ALLEN,SAETEURN,allensae@outlook.com
Untitled,,,Draft,Pending,Manage team,04/28/2024 14:50:29,,,,,,Edward,Chhun,edwardchhun3@gmail.com,,,,Best Hack for NAMI Yolo,Sacramento City College,0,,,
Trash-Bot,123,https://hackdavis-2024.devpost.com/submissions/511359-trash-bot,Submitted (Gallery/Visible),Pending,Submit,04/28/2024 14:51:17,"After seeing how much labor is put into collecting trash in all corners of life, we decided to make a bot that helps makes the trash collecting/cleaning more easier. This milestone wouldn't have been possible without our struggles with git, hardware and video streaming.
","https://github.com/gutsyguy/trashbot-mobile, https://github.com/gutsyguy/trashbot-server",,"Best Health Hack, 	Best Hack for Social Justice, Most Creative Hack, Best Hardware Hack","flask, ngrok, react-native, raspberry-pi, python, servo, motor, microcontroller, amazon-web-services",Capital,E___,gutsyboi123@gmail.com,,Best Hardware Hack,Most Technically Challenging Hack,Best Health Hack,California Institute of Technology,1,Luis,Cardenas ,luis.cardenas@csedge.org
WasteLess,40,https://hackdavis-2024.devpost.com/submissions/511360-wasteless,Submitted (Gallery/Visible),Pending,Submit,04/28/2024 14:52:45,"Inspiration

We have 6 roommates and one fridge. Stuff goes bad, a lot, so we decided to create an app to solve this in the UC Davis anti-food-waste spirit!

What it does

This app scans your groceries after each trip to the market, and will automatically keep track of the expiration date of each item. We discourage food waste by 1) notifying you when something's about to go bad, and 2) providing a clean UI for you to identify high-priority items to cook.

How we built it

We started by collecting food data from the COCO-dataset, and training it on the YOLO v9 model. Once the model could accurately detect food items, we mapped each item to its shelf life, and created an interface to interact with it using React Native and Expo.

Accomplishments that we're proud of


successfully deploying a Flask server in our first time using it
achieving high food detection accuracy


What we learned


a lot about how one-shot object detection works
ayush lenka and hugo morales infante don't realize that they need to cook what they buy


What's next for WasteLess

We're going to train the model on a lot more grocery items to reduce the amount of manual input required. We'll continue to test WasteLess at our house, and if this significantly reduces the amount of food items that go bad, we'll publish it on the App Store.
",https://github.com/linden0/WasteLess,,"'	Best Hack for Social Justice, Most Creative Hack, Best AI/ML Hack, Most Technically Challenging Hack","python, flask, react-native, expo.io, opencv, javascript",Linden,Wang,linden.wang04@gmail.com,,Most Technically Challenging Hack,Most Creative Hack,'	Best Hack for Social Justice,University of California - Davis,1,Maxim,Saschin,mnsaschin@ucdavis.edu
Untitled,,,Draft,Pending,Manage team,04/28/2024 14:53:07,,,,,,Alex Jr,Chau,achau@ucdavis.edu,,,,Best Interdisciplinary Hack,University of California - Davis,0,,,
VolunTier,4,https://hackdavis-2024.devpost.com/submissions/511362-voluntier,Submitted (Gallery/Visible),Pending,Submit,04/28/2024 14:55:12,"Inspiration

We have a difficult time looking for help when organizing events, so we decided to make an accommodating way to look for volunteers to sign up.

What it does

Allows users to browse a number of organized events in local areas. Organizations can post their future events and allow individuals to sign up as volunteers. 

How we built it

By using react-native, we created a mobile app that simulate the user process. We created a Landing page using Next.Js.

Challenges we ran into

The major challenges we encountered were deploying the app and website, incorporating responsiveness and coming up with the idea in the first place. As well as keeping in mind of time-constraint which resulted in quickly figuring out bugs or brushing pass them.

Accomplishments that we're proud of

We're proud of the fact that we finished the project with an idea that helps communities grow more active. We are also proud of swiftly adapting to a completely unfamiliar technology and creating a website under major time constraints.

What we learned

We learned Javascript, react-native and how to deploy a website. Creating a simple idea comes with a lot of work that users don't see.

What's next for VolunTier

To streamline the application process, we're introducing a feature that displays an example of the prerequisite documents required beforehand, simplifying preparation for the event day. This ensures that applicants are fully equipped and eliminates last-minute scrambles, enhancing overall efficiency and participant satisfaction.
","https://www.voluntier.tech/, https://github.com/Mon-Rico/HD2024, https://github.com/BrandonSandovalS/VolunTierLandingPage",,"Most Creative Hack, Best User Research, Best Use of .Tech Domain Name, Best Interactive Media Hack","html, react-native, javascript",Brandon,Sandoval Sanchez,sandovalbrandon20@gmail.com,,Best Use of .Tech Domain Name,Best Interactive Media Hack,Most Creative Hack,"California State University - East Bay, Chabot College",3,Monica,Rico-Antonio,ricomonica1108@gmail.com
Chopped,59,https://hackdavis-2024.devpost.com/submissions/511364-chopped,Submitted (Gallery/Visible),Pending,Submit,04/28/2024 14:57:49,"Our target audience for this project are college students experiencing food insecurity. We decided to go in this direction because, as college students, we see how prevalent this issue is in our community. 

From our research, we discovered that one of the main concerns college students facing food insecurity experience is time-management because they have to juggle work on top of school and extracurricular activities. Additionally, we found it is common for college students to worry about the stigma around asking for help regarding finding nearby pantries and low-cost recipes. To combat these concerns, we created a page where users can search for pantries in their area. 

Our goal for Chopped is to decrease the stigma around asking for help and allow users to save time when it comes to meal-prepping and buying groceries.
",https://www.figma.com/file/FIzPi4M0dN5OyVd7z9rfF4/Hackdavis?type=design&node-id=38-5&mode=design&t=tnVLRezwhG78itra-0,https://www.youtube.com/watch?v=hmuyW4OxR0E,"Best Health Hack, Best UI/UX Prototyping, Best Overall Design, Best User Research",figma,Alexandra,Litinskiy,amlitinskiy@ucdavis.edu,,Best Overall Design,Best User Research,Best Health Hack,University of California - Davis,2,Sarah,Liang,sarliang@ucdavis.edu
Untitled,,,Draft,Pending,Manage team,04/28/2024 14:59:38,,,,,,Savage,Cabbage,manavgurnani21@gmail.com,,,,Most Technically Challenging Hack,,0,,,
DCMH Donation & Inventory Project,97,https://hackdavis-2024.devpost.com/submissions/511367-dcmh-donation-inventory-project,Submitted (Gallery/Visible),Pending,Submit,04/28/2024 14:59:39,"Inspiration: Hailing from San Jose, a city rampant with homelessness and displaced people, homelessness and structural inequality is something that we work towards solving. After reading about DCMH, we aligned ourselves with their mission and decided to use the prompt that they were looking out for.

What it does: It's an inventory management system for people within DCMH, while for a regular person, it is a robust Donation page that gives them several options on how to donate to the cause.

How we built it: We used React, HTML, CSS, Python, Flask, and Django to build the entire application.

Challenges we ran into: Connecting the two parts of the project: the revamped donation page, along with the inventory management system was one of the main challenges that we ran into. Along with a lot of debugging that came with the dynamic structure of our coding process. Always creating new ideas and making adjustments meant that there was a lot of debugging to do.

Accomplishments that we're proud of: Getting the entire application to align with the vision that we had at the beginning of the process along with actually experimenting and trying out new technologies with Flask and React.

What we learned: How the tech stack works with the frontend working with the backend, grasping new technology like Flask and React, and the development cycle of a new project and what it takes to take the ideas and bring them into reality.

What's next for DCMH Donation & Inventory Project: Adding more features and making it more robust to make it a full-fledged application. Bringing in new components, ideas, and visions so that the application can grow into being a tool that is used by many people.
",https://github.com/sohumtiwary/DCMHProject,,"Best Beginner Hack, 	Best Hack for Social Justice, Best User Research, Best Hack for DCMH","react, django, python, html, flask, css",Sohum,Tiwary,sohum.tiwary@gmail.com,,Best Hack for DCMH,Best Beginner Hack,Best Hack for Social Justice,"San Jose State University, Folsom High",2,Akshitaa,Balasai,akahitaab@gmail.com
Project Stress Test,46,https://hackdavis-2024.devpost.com/submissions/511368-project-stress-test,Submitted (Gallery/Visible),Pending,Submit,04/28/2024 15:00:33,"Inspiration

As everyone in our group is a non-CS major, we decided to work on a topic that overlaps both with CS and the other fields that we're interested in, in this case psychology and mental health, and how that impacts academic success. Our inspiration for this project was due to the collective stress that we've noticed on Davis campus. It feels like there's a disconnect between the professors and students at times and it can be difficult to express concerns to the professor. We wanted to create an effective way for professors to quantify the stress that their students are under, so that they can appropriately adjust their teaching methods/workloads. This is a web app that we feel is beneficial for both professor and student. 

What it does

Our web app provides a code to the professor that they can in turn provide to their classes. The students in these classes can in turn use this code to access the survey that utilizes the Perceived Stress Scale, a psychological assessment of stress. After answering these questions, the student can give feedback to the professor anonymously and receive their score. This information is then saved into a database for students in this class and then processed. By inputting the code into the analytics section of our web app, professors can see the average stress levels of their students and other graphs comparing stress levels among class year. 

How we built it

We built our project using Python Flask, JavaScript, HTML, and CSS for developing the web app and MongoDB for our database. We used Matplotlib for creating graphs and used ChatGPT to analyze the data for our analytics section.

Challenges we ran into

We had a lot of trouble in the beginning because it was our first time working with Flask, JSON, databases, and pandas. Working together we were able to integrate these technologies into our project. In addition, towards the end of our project we ran into issues with integrating LLMs into our feedback and  drawing a histogram from the data we receive and developing special codes for each form.

Accomplishments that we're proud of

All in all, we're really proud of our web app. This was our first big project of this scale that incorporates front end, back end, and databases and we feel like we were able to put something together that we're happy with.

What we learned

We learned a lot about web design and working with databases. All of us were more comfortable with just backend development but from this project we were able to learn so much more and created new found interest and passion for full stack development and web design. 

What's next for Project Stress Test

We'd also like to create an option for professors to create more class specific questions in addition to the questions that we've already provided. This would allow for professors to create more personalized surveys which we think would be very useful.
",,,"Best Interdisciplinary Hack, Best Health Hack","python, javascript, mongodb, html, css, pythonflask, matplotlib, llms, json, pandas",Meghana,Manepalli,mmanepalli@ucdavis.edu,,Best Interdisciplinary Hack,Best Health Hack,Hacker's Choice Award,"UC Davis, University of California - Davis",2,Savage,Cabbage,manavgurnani21@gmail.com
Aggie Reclaim,93,https://hackdavis-2024.devpost.com/submissions/511371-aggie-reclaim,Submitted (Gallery/Visible),Pending,Submit,04/28/2024 15:03:08,"Inspiration
Nothing feels worst than losing an item that is personal to you. There must not always be a way to reclaim your items. In UC Davis, we will have a solution and successor to the system 'lost and found'.

What it does
Aggie Reclaim, connects you back to your beloved items via a user friendly, trustworthy, and efficient website. With the site built for UCD students, lost items submitted by the UCD staff, and time saved from searching all every lost and found system. Aggie Reclaim is the future.

How we built it
The members of Aggie Reclaim developed this site With user friendliness and effectiveness in mind. We used Visual Studio Code to collaborate on the project. Using html, CSS, and JavaScript to get the ideal appearance and functionality of Aggie Reclaim

Challenges we ran into
Obstacles are meant to be overcame. Our team had experienced numerous challenges in coding and website developing. This is our team's first time in hackathon. For some of our members this was their first time coding and for some members it was our first website. We persisted through the struggles and cannot wait to introduce Aggie Reclaim.

Accomplishments that we're proud of
We are proud to introduce aggie reclaim, we believe this site will help many people reclaim their lost items. We thank Hackathon that made this team project possible.

What we learned
Many valuable lessons are learned during this hackathon. Many of us learned how to code, how to develop a website, and how to work in team code environment. We are glad to have persevered through the challenges and disagreement for the ultimate goal of improving UCD's lost and found system.
",https://github.com/InClouseau/Sad-pancake,https://youtu.be/lexLTQW6mnE,,"html, css, javascript",Aryan,Ghiasi,arghiasi@ucdavis.edu,,Best Beginner Hack,Best Hack for Social Justice,Best UI/UX Design,University of California - Davis,3,Alan,Lee,arulee@ucdavis.edu
Criminal Justice Reform,31,https://hackdavis-2024.devpost.com/submissions/511372-criminal-justice-reform,Submitted (Gallery/Visible),Pending,Submit,04/28/2024 15:04:00,"Inspiration

Our journey began with a profound inspiration drawn from an impactful initiative: The Three Strikes Project. This legal clinical seminar, spearheaded by dedicated law students, extends a helping hand to individuals serving life sentences for nonviolent crimes under California‚Äôs Three Strikes Law. Their mission is clear: to seek justice and advocate for those whose lives have been profoundly affected by this law.
Inspired by this, we felt compelled to delve deeper into the intricate web of data surrounding criminal justice reform. Recognizing the vast challenges faced by legal practitioners in navigating the complex landscape of California's prisons, we identified a pressing need for more efficient and accurate methods of identifying eligible candidates for Prosecutor Initiated Resentencing (PIR). As aspiring Data Scientists and Analysts, our curiosity propelled us to explore deeper into the data, seeking patterns and insights to understand the interplay between various factors.

What it does

Our website gives us information on trends in crime in California, specifically focusing on ethnicity, location, reason for sentencing and sentence length in months.  We also conducted statistical analysis to come up with impactful findings and presented it. 

How we built it

We built out website using Javascript, HTML and CSS. To analyze our data, specifically ethnicity and it's correlation with sentence length in months, we used R Studio to create summary tables, boxplots and conduct one way ANOVA testing. Lastly, we used Tableau to create our bar graphs, time series graphs, and map. 

Challenges we ran into

We were unable to get our interactive Tableau graphs onto our website. We also had trouble deciding on what columns to use as we weren't sure what would be the most relevant. However, we overcame this problem ultimately deciding sentence length, ethnicity and reasons for sentencing. Lastly, we had trouble making the website as we were new to HTML and CSS, and have never built a website before. 

Accomplishments that we're proud of

We are proud of building a website, learning how to use Tableau, and applying our statistical knowledge in a real life setting. 

What we learned

We learned how to create a website, create interesting graphs, collaborate well as a team, and developed our technical skills.

What's next for Criminal Justice Reform

We want to find out how to integrate Tableau interactive graphs into our website and transform our data to better analyze and come up with accurate conclusions. 
",https://drive.google.com/file/d/11IPD86ZfcsmemqhyzErPz1yENhV8WEYM/view?usp=sharing,,"Best Beginner Hack, 	Best Hack for Social Justice, Best User Research, Best Statistical Model","javascript, vscode, r, rstudio, tableau, google-docs, googleslides, html, css",Meenakshi,Iyer,meeiyer@ucdavis.edu,,Best Beginner Hack,Best Statistical Model,Best Hack for Social Justice,University of California - Davis,2,Maya,Nordin,mnordin@ucdavis.edu
ECHO,,,Draft,Pending,Additional info,04/28/2024 15:04:42,"Inspiration

In a constantly evolving world where humans have to adapt to technological developments, it can sometimes be challenging to foster relationships, make friends, and form lasting connections. For certain groups of people like the visually impaired, new technologies are often inaccessible due to the need to . One of Echo's co-founder's childhood friends, Bhuvan, falls under this category.  Bhuvan was born able to see as well as any other kid. However, his vision naturally faded due to macular degeneration, an eye disease leading to a loss of vision. Bhuvan's life drastically changed during his time in high school; once a generally outgoing and social guy, Bhuvan started to feel more and more isolated from his friends. Without vision, him and his friends could no longer share the same experiences. 

Bhuvan's story has been our inspiration for this project and we believe our product can help the blind and visually impaired feel more connected to the people around them. With more accessible and inclusive technologies like Echo, we hope to remove any barriers to technology and help individuals experiencing isolation like Bhuvan's.

What it does

Echo is the world's freshest audio-based social media platform that is accessible to the blind and visually impaired. Echo keeps the traditional components of social media while reimagining the way people communicate online. Posts, comments, and even usernames are all in audio form, allowing for users to browse through posts without needing to see the screen. Our design also allows for any user to navigate easily navigate the app using voice commands and audio cues.

How we built it

Frontend and backend was built on Next.js. We maintained two websocket connections at the same time to handle real time STT with Deepgram as well as function calling with a Mistral 7b instruct fine tuned for our case. We also stored all Posts, Users, and Comments on AWS DyanamoDB with all audio files publicly available on S3.

Challenges we ran into

being able to work with real-time voice recognition and being able to fine tune a LLM for function calling specifically to navigate the app. 

Even though we were able to finetune a model in IDC we weren't able to expose an endpoint which was crucial 

To process voice commands,  we intially wanted to deploy our own fine-tuned LLM, but we were not able to get a server to host it on. Additionally, training was a difficult due to a lack of GPUs available on the Intel Developer Cloud. Our fix to this problem was using the OpenAI API to make calls with a custom prompt. 

WORKING WITH AUDIO ON BROWSER SUCKS

Accomplishments that we're proud of

We are most proud of our product ideation - our biggest accomplishment is streamlining our technical abilities and experience in a way that aims to make the world a better place. 

Setting up and fine tuned model with IDC which took a while and had it's challenges, but we were able to fine tune a model for the navigation of our social media web app purely through voice. Though we weren't able to host the expose an endpoint for use in the web app it did provide immense experience with AI training in the cloud.

What we learned

We learned that voice technology is currently very easy to work with and I use of IDC shorten's the fine tuning necessary for making LLM's that perform action.

What's next for ECHO

Currently we are only able to post within Echo but eventually we want to integrate with facebook, instagram, twitter any social media so that we can make any platform accessible to the visually impaired and blind. 

Thank you Bhuvan!!!
","https://github.com/vish-04/echo, https://github.com/vish-04/echo",,"Most Creative Hack, Best AI/ML Hack, Best use of Intel¬Æ Developer Cloud, Best Interactive Media Hack","dyanmodb, next.js, python, tensorflow, intel-cloud-developer, openai, mistral, flask",Nitin,Kanchi,nkanchi@ucdavis.edu,,Best use of Intel¬Æ Developer Cloud,Most Creative Hack,Best AI/ML Hack,"University of California - Santa Cruz, University of California - Davis",3,Vishwa,Akkati,vakkati@ucdavis.edu
Job Scoper,92,https://hackdavis-2024.devpost.com/submissions/511376-job-scoper,Submitted (Gallery/Visible),Pending,Submit,04/28/2024 15:05:19,"Inspiration

As an LGBT+ person who'd rather not drive to work, I can be a bit picky about where I apply to jobs. Our team wanted to make it easy to vibe check each job posting we came across. That's why we came out with Job Scoper.

What it does

Simply find a job on Indeed or LinkedIn and grab a link to the posting. Copy and paste it to our Job Scope site and get some insights! Currently, we display commuting information from WalkScore, information about gender discrimination laws and reproductive rights, and LGBT+ acceptance for the area of the job.

You can also submit your resume as a PDF and get a summary of how well your resume fits with the job description - powered by OpenAI.

How we built it

Our frontend is built from React. We have a flask server hosting an API that gathers all of the information for our front end.

Here's the back end tech:


Selenium is used to scrape the job posting from the web to get raw job description and location data.
Google Maps API and Google's Geocoding API are used to clean up the raw location data.
Databases and APIs such as Equaldex, WalkScore, and the Center of Reproductive Rights are used to provide location based insights.
The OpenAI API is used to compare your resume with the job description.


Challenges we ran into

With such a big tech stack, things seemed really daunting. Luckily, we were able to stay organized and bring everything together.

(It was also difficult creating a web app as a group of backend engineers and business majors.)

Accomplishments that we're proud of

We're really proud to have created an app gives more power to those applying for jobs. We plan to use this app ourselves as we job search after graduation.

What we learned

We went from never touching front end to creating a full-fledged React app. We also learned a lot about various non-profits that provide data for social justice which we plan to use in future projects.

What's next for Job Scoper

We want to improve the resume-helper feature. We'd also like to host this site, as we think it would be a really useful resource for job seekers.
",https://github.com/ajgrant6/HackDavis2024,,"Best Interdisciplinary Hack, 	Best Hack for Social Justice, Most Technically Challenging Hack, Best DEI Hack Sponsored by Fidelity","react, javascript, python, flask, google-maps, walk-score, openai, equaldex, google-geocoding",AJ,Grant,aj.grant6@icloud.com,,Best Hack for Social Justice,Best Interdisciplinary Hack,Most Technically Challenging Hack,University of California - Merced,3,Derek,Stanford,dstan4321@gmail.com
Aggie GeoNest,12,https://hackdavis-2024.devpost.com/submissions/511384-aggie-geonest,Submitted (Gallery/Visible),Pending,Submit,04/28/2024 15:13:51,"Inspiration

Strolling down Central San Francisco in the midst of the Christmas season, I feel pure joy emitting from through the crowded streets; children run around, laughing and playing with their helicopter toys from the ample street-side shops. Despite the seemingly widespread joy, not all on those San Francisco streets are happy during the holiday season. Known for its high population of homeless inhabitants, the streets are lined with hundreds of homeless people hoping to benefit from seasonal generosity. Translating this impact to Aggie House at UC Davis, our team would love to spread this same seasonal generosity through all four seasons to ensure that unhoused populations that are still in school do not have to depend solely on the kindness of strangers to get by. Learning about the struggles that Aggie House volunteers and residents currently encounter inspired our team to build a multi-faceted workflow system that not only helps residents live peacefully, but also preserves the safety of residents as well.

What it does
Our product, Aggie GeoNest, is a thoroughly developed application featuring an advanced automated geo-location tracker. This tracker automatically checks in and checks out volunteers and residents based on their proximity to the Aggie House. It also includes a task manager and shift calendar, allowing volunteers to keep track of their responsibilities and ensure the wellbeing of the residents. Additionally, the app integrates Gunrock AI, a chatbot powered by OpenAI, designed to answer any questions from volunteers or residents using a prompt-response formatted JSONL. There is an in-app chat feature that enhances communication between the administration, volunteers, and residents. Lastly, the app provides feedback forms for both residents and volunteers, helping Aggie House continually improve and enhance the experience for all members. Finally, we also developed an administrative dashboard that takes volunteer hours based on the clock in and clock out time. All tools are easily manipulatable by the administration, making shift and task distribution easy for all.

How we built it

We build our tool with an ample amount of languages, databases, and APIs. We built GeoNest on React-Native, specifically using Expo to develop our app on a mobile app simulator. Our code was primarily in JS and HTML, with our Gunrock AI first written using Python then eventually translated to JS as well. We utilized Firebase for our database, connecting our log-in systems, shift systems, calendar systems, clock in and clock out time, and administrative dashboards between the administration and the users.

Challenges we ran into

Throughout the process of building this project, one of the key challenges we encountered involved testing our geo-location tracker. Testing this tool meant walking a fair distance at least over 150 meters away, in order to guarantee a successful test, which meant that each test would take approximately 5 to 10 minutes. This meant that the creation of this tool was an exhausting process, but one that was definitely worthwhile when we completed it at the end. On top of this, we encountered numerous git push issues, one time unfortunately wiping and invalidating some .js files, forcing us to take multiple steps back.

Accomplishments that we're proud of

Developing an advanced automated geo-location tracker was no small feat. We're proud of creating a robust system that accurately checks in and checks out volunteers and residents based on their geo-location and proximity to the Aggie House. This feature enhances the efficiency and security of our application, ensuring smooth operations. Implementing a task manager and shift calendar within the application was also essential for organizing volunteers' responsibilities effectively. We're proud of developing a user-friendly interface that allows volunteers to keep track of their tasks and shifts effortlessly. This feature promotes accountability and ensures that all necessary tasks are completed in a timely manner, contributing to the overall success of the project. Integrating various functionalities seamlessly within the application posed significant challenges. We're proud of overcoming these hurdles and successfully integrating the geo-location tracker, task manager, and shift calendar to create a cohesive and efficient system. This accomplishment highlights our team's dedication to delivering a comprehensive solution that meets the needs of both volunteers and residents. Ultimately, we're most proud of the potential impact Aggie GeoNest can have on the community. On top of this, by streamlining volunteer management processes and enhancing communication and coordination efforts, our product has the power to improve the lives of residents and volunteers alike. Knowing that our work has the potential to make a positive difference in the community is incredibly rewarding and motivates us to continue striving for excellence. These accomplishments signify not only our technical proficiency but also our commitment to creating meaningful solutions that address real-world challenges. We're excited to see how Aggie GeoNest evolves and positively impacts the community in the future. By streamlining volunteer management processes and enhancing communication and coordination efforts, our product has the power to improve the lives of residents and volunteers alike. Knowing that our work has the potential to make a positive difference in the community is incredibly rewarding and motivates us to continue striving for excellence. These accomplishments signify not only our technical proficiency but also our commitment to creating meaningful solutions that address real-world challenges. We're excited to see how Aggie GeoNest evolves and positively impacts the community in the future.

What we learned

We learned the intricacies of developing and integrating advanced geo-location technologies and AI-driven chat functionalities into a single application. Adapting these technologies to work seamlessly in a real-world, dynamic environment taught us a lot about the practical challenges of software development, including dealing with variability in GPS accuracy and optimizing response times of the chatbot. In addition to this, by interacting directly with the volunteers and residents of Aggie House, we deepened our understanding of user-centered design principles. We learned that truly effective solutions arise from a close collaboration with end-users, involving them in the testing and feedback loops, which leads to more intuitive and useful product features. We constantly collaborated with Virginia and Aggie House, in order to get the most optimal application suited for their purposes.

What's next for Aggie GeoNest

We plan to continue to hopefully work with Aggie House in the future, expanding our product, and assisting them with their requirements in the process. From a development standpoint, we plan to integrate more tools to assist with the needs of both the residents and the volunteers, on top of truly refining the tools we have made so far. We believe that we have achieved an exceptional proof of concept from working on GeoNest, and are excited to be a part of its journey in the future!
",https://github.com/AnunayAkhaury/AggieHouse.git,https://www.youtube.com/@ayushmajumdar6111,"Best Beginner Hack, Best User Research, Best Hack for AggieHouse","javascript, react-native, expo.io, ios, react-native-geolocation, expo-geo-location, openai, firebase, firestore, cloud-messaging, calendar, bar-graph, html",Anunay,Akhaury,aakhaury@ucdavis.edu,,Best Hack for AggieHouse,Best Beginner Hack,Best User Research,"University of California - Davis, univeristy of california davis",4,Ayush,Majumdar,ayushmajumdar14@gmail.com
MealMatch,51,https://hackdavis-2024.devpost.com/submissions/511387-mealmatch,Submitted (Gallery/Visible),Pending,Submit,04/28/2024 15:17:50,"What it does

MealMatch asks the user to select what fast food item they want to eat, and then suggests alternate healthy recipes for the user to make. It connects with local groceries stores to come up with shopping lists, and can give coupons or discounts for using these lists. The user can add also their own dietary restrictions and location settings.

How we built it

We used Figma to create wireframes and prototype the user interface, and then we had our developers do the front end aspect using react native and node js.

Challenges we ran into

Web scraping
Originally, we planned to use Python or JavaScript, specifically libraries like BeautifulSoup, Puppeteer, or Cheerio, to scrape prices, calories, and ideally nutrition information from both grocery store and fast food online menus. However, not all fast food websites provide nutritional data. Our developer encountered a significant challenge when attempting to scrape data using Python due to variations in website loading processes, making a uniform scraping strategy unfeasible across all sites.
We switched to react native because we decided it was better as a phone app.This was our developer‚Äôs first time using react native and some of the issues we ran into was running Expo Go on our phone and trying to connect through the QR code. 

Accomplishments that we're proud of

We are proud of the functionality and that our developers learned a whole new software in just one night when we are all beginners to hackathons and coding. We are also proud of being able to produce our working prototype in Figma after such a short span of time, when we are also beginners in design.

What we learned

The developers learned how to use react native and one of them learned JSX and HTML for front end development. One of the designers also got a better grasp of Figma as this was her first time using it.

What's next for MealMatch

We want to better refine the app idea and make it more customizable as well as incorporate some AI chat elements into it.
",https://www.figma.com/file/WJVzfUXnSrNajwGA6AsEWP/MealMatch?type=design&node-id=22%3A4&mode=design&t=IlcBnynVKNjQGa4O-1,https://youtu.be/mfKM_Uk_bb4,"Best Beginner Hack, Best Health Hack, Best UI/UX Prototyping, Best Overall Design","react, react-native, css, node.js, figma",Nicole,Chen,nicole.ys.chen@gmail.com,,Best Beginner Hack,Best UI/UX Prototyping,Best Health Hack,University of California - Davis,1,Deepa,Bhat,dbhat@ucdavis.edu
SweetSpot,38,https://hackdavis-2024.devpost.com/submissions/511389-sweetspot,Submitted (Gallery/Visible),Pending,Submit,04/28/2024 15:21:18,"Inspiration

Yash, Yahli, Anirudh, and Vikram share multiple things in common, but none more than their passion for taking part in community initiatives. Everyone in the group possessed a passion for an accessible healthcare solution, specifically thinking about people who either were newly diagnosed or did not have an adequate support system.

We were thus motivated to build a resource with the idea that ‚Äúyou‚Äôre not alone‚Äù

Our idea to create a Type I Diabetes app stems from Vikram, who himself is a diabetic. The other three team members have watched in admiration as he diligently manages his sugars on a daily basis, and understand this is not necessarily the norm. Some people don‚Äôt have the resources or just don‚Äôt know how to take care of themselves. This product can fundamentally change that.

What it does

Our product is a mobile application that creates a personalized support center for diabetes management.
The feature set consists of:


Dynamic Graph - View blood sugar level trends, updated with the latest data
Actionable Insights - Armed with tailored information, take action with our recommendation system to keep your sugars in check
Machine Learning Algorithm - Our model projects your sugars for the next 30 minutes, allowing you to stay a step ahead
Chatbot Service - How about some interactive advice? Converse with our chatbot to learn more about how to best manage your blood sugar levels based on your prior history


How we built it

The app is built on the foundation of the Dexcom API, which allowed us to pull all of our users sensor data and actionable events (such as exercise, giving insulin, etc.)

The Open AI API generates meaningful insights from diabetes monitoring data to help users understand their blood sugar patterns and adjust their habits for better health management. WHILE ALWAYS BEING SUPPORTIVE! 

None of this of course would have been possible without the help of Firebase Functions - A serverless framework that let us automatically run backend code in response to event. This let us to make the connection between and backend seamlessly and make several API calls simultaneously or in sequence

We also experimented with a variety of machine learning/statistics techniques in order to ensure that our 30 minute glucose predictions were accurate. These are incredibly important because they are a key piece to our actionable insights and helping a T1D avert a low or high sugar long before it happens.

Finally, we created a Local LLM which is fined tuned. IMPORTANT! We can‚Äôt put P4 level data (HIPPA) into an online chatbot, so we pre-trained it to be able to analyze the users Dexcom data. It can then draw insights and finds patterns in users data. Finally, and perhaps most importantly, it can answer any diabetes related question, and also gives suggestions as to how to improve their overall blood sugar level numbers

Challenges we ran into

There were a number of challenges that we ran into throughout the course of our night. This list does not include everything, but gives a mere idea of what we faced.


Server crashing with multiple firebase functions running simultaneously
Figuring out how to create a trustworthy statistical model
Connecting the Neon Database to the front end client
Excess Memory usage of Google Cloud functionality


Accomplishments that we're proud of

First and foremost, we are proud of the fact that we built something that mattered to US. We could‚Äôve opted to go down the route of building something with the sole intention of winning, but we instead felt motivated to build something that we could all get behind from the very core of what we stand for. The fact that one of our team members is Type I makes it even more special - we built it with his use case in mind. We‚Äôre also proud of the fact that we stuck it through. We stayed at the U Center the entirety of the 24 hours (to be fair, we did take our fair share of football/walk/social breaks) and it was honestly an unforgettable experience. 

What we learned

We learned so much throughout this entire process. From teaching our not-incredibly-technical member how to work with databases and APIs, to building out a local LLM and using Firebase, there was a lot of technical knowledge accumulated over the past 24 hours. Additionally, we learned that we work really well together as a team in a technical setting. The 4 of us are all great friends, but we‚Äôve never built a technical product together. Our technical skills (or lack thereof) really complemented each other and contributed to an environment defined by joyful collaboration and communal growth. 

What's next for SweetSpot

We hope to iterate and pursue this as a product. As we mentioned, one of our team members is a Type I diabetic, so this is a cause near and dear to all of our hearts. We plan on refactoring our code base and then approaching Professor Sam King for advice on product-market fit and next steps. Not only is Professor King an incredibly accomplished entrepreneur, but he‚Äôs also a Type I Diabetic, so we hope to get both advisor and user perspectives from him. 
",https://github.com/yashdesh6/sweetspot,,"Best Interdisciplinary Hack, Best Health Hack, Best AI/ML Hack","python, react, react-native, pandas, numpy, scikit-learn, dexcom-api, openai-api, firebase, neon, cron-job, chatbot, machine-learning, api",Anirudh,Murugesan,amurugesan@ucdavis.edu,,Best Health Hack,Best AI/ML Hack,Best Interdisciplinary Hack,University of California - Davis,2,Vikram,Choudhry,vchoudhry@ucdavis.edu
Emotion Classification of Voice,69,https://hackdavis-2024.devpost.com/submissions/511395-emotion-classification-of-voice,Submitted (Gallery/Visible),Pending,Submit,04/28/2024 15:27:40,"Inspiration

We have seen that there are a variety of people who may seem to be living normal lives but they have plenty of problems that they are hiding from others. However, we understand that their grief from their problems impacts how their speech sounds, but there are people who are unable to understand others' emotions through voice. This could potentially lead to relationship issues, so to promote a friendly community, we decided to develop a machine learning model that can recognize people's emotions from their voice.

What it does

Our model will predict an individual's emotion based on the sound of their voice. It will be able to classify their emotion based on their tone, speed, and intonation.

How we built it

We started by compiling our training data, which consisted of 50 different words/phrases said in 7 emotions apiece. We then uploaded all our files into a Jupyter Notebook and used Librosa audio processing to convert each audio file into an array of sound frequencies, and we added them into a pandas DataFrame to associate the frequencies with certain emotions. We ran drop_duplicates to clean up our data in the DataFrame. We also ran pd.info() to ensure our data doesn't have any missing values. 

Once we ensured our data was clean, we ran train_test_split() with 75% being our training data, and 25% being our testing data. We then trained our model using a neural network with Tensorflow, and our layers consisted of Conv1D, MaxPooling1D, Dropout, Flatten, and Dense. We then compiled the model and fitted it with our trained data, which gave us the accuracy of our model.

Challenges we ran into

We initially trained our model using classification models like RandomForestClassifier, LogisticRegression, and VotingClassifier, but our validation accuracy for each model was very low, 52.8% for RandomForestClassifier, 27.7% for LogisticRegression, and 48.3% for VotingClassifier. We used MatPlotLib to find the maximum validation accuracy of RandomForestClassifier using a plot, but the maximum validation accuracy depicted from the plot was 52%. We used GridSearchCv to find optimal model for LogisticRegression, but the optimal model validation accuracy was still 27.7%. VotingClassifier was not giving an accuracy higher than 48.3% regardless of what models it contained. 

Accomplishments that we're proud of

Our neural network model achieved a validation accuracy of 81.61%, which demonstrates our models ability to identify 81.61% of human emotions that it had never seen before (outside of our training data).

What we learned

We learned that when train Auido Models, using Layers like Conv1D, MaxPooling1D, Dropout, Flatten, and Dense are very helpful. Conv1D is very effective in capturing audio waveforms and frequencies, the latter of which we included in our DataFrame, MaxPooling1D reduces dimensionality so that we only extract the important features from our DataFrame, and the others Layers like Dropout, Flatten have a tremendous impact. It is important to use Deep Learning in Audio Classification.

What's next for Emotion Classification of Voice

We can develop our model into a user-driven app that can allow people to record their voices, and it will  classify their emotion, allowing the model to respond accordingly.
",,,"Best Beginner Hack, Best AI/ML Hack, Best Statistical Model","jupyter, librosa, python, tensorflow, scikit-learn, matplotlib",Atharva,Berde,atharvaberde5@gmail.com,,Best AI/ML Hack,Best Statistical Model,Best Beginner Hack,"San Jose State University, UC Davis",1,Rajeev,Raghuram,rajeev.raghuram2@gmail.com
Caduceus,104,https://hackdavis-2024.devpost.com/submissions/511396-caduceus,Submitted (Gallery/Visible),Pending,Submit,04/28/2024 15:31:29,"Inspiration

In Southeast Asia and many other developing countries, one of the biggest problems that an average citizen may face is getting treated for their injuries, diseases, and more. Healthcare is either too expensive, too inaccessible, or too inefficient. As a group composed of first-generation, low-income students with families still in these home countries, we are often told stories of the many health problems that are families unfortunately have to face due to the healthcare system in place. As a result, we wanted to build an app that focuses heavily on accessibility and utility for users in developing countries, inspired by the heavy fight that our families go through.

What it does

We have built a chatbot powered by Gemini that leverages its text-to-text and computer vision capabilities to help give users more information about their injuries, as well as how to treat and further prevent it. We have also used multiple APIs to ensure that people can communicate with the chatbot in different languages, opening arms to users who do not know how to speak English. 

How we built it

Frontend Stack:


Flutter
Dart


Backend Stack:


Gemini API
Google Cloud Translate API
Langdetect API


Challenges we ran into

Challenges we ran into when creating Caduceus was finding the information necessary to determine the problems that are common within Southeast Asian countries and what steps we could do to help give the people some type of aid. Providing aid other than seeking healthcare professional is difficult, but with the addition of a camera feature to provide a more precise answer, both seeing and describing would make it likely for the chatbot to provide more personal and effective treatments. Another issue arose when finding out that the majority of the database used Android, leading us to use Flutter for the first time in order to cater to that demographic and not just the Apple users.

Accomplishments that we're proud of

While developing our app, some accomplishments we were most proud of was being able to successfully complete our backend using Gemini API and Google Translate API. This task was huge to our purpose because leveraging these new tools can have a huge impact on our users. Developing our front-end was also a massive hurdle that we were proud of overcoming due to its seemingly steep learning curve, however, it was very rewarding.. Being able to put the project together in one uniform concept was our biggest achievement because communication is also key to building a successful project and our goal is to communicate with our users. 

What we learned

Setting up the environment and emulating our app live onto our devices was very rewarding to experience and we learned a lot from our time during this hackathon. Learning to use the flutter SDK was very interesting as its compatibility on both IOS and Android made it a useful tool to have in our back pockets. Along with learning how to implement the challenging Gemini API and its tricky computer vision, we now have a powerful ally at our hands when developing AI-powered projects.

What's next for Caduceus

Caduceus plans to retrieve more data regarding each country to provide better responses to each country‚Äôs common issues or to understand the user‚Äôs personal data and connect the problems they‚Äôre listing in order to possibly identify an underlying problem that may not be seen at first glance. Caduceus will continue to evolve, as improving the application to have more features such as a camera and the chatbot providing responses is an ideal product for our users. 
",https://github.com/matttwh0/Davis-2024,https://youtube.com/shorts/Q9mCHAsCCrc?si=aAsHxXeyC3nMzZ4E,"Best Beginner Hack, Best Interdisciplinary Hack, Best Health Hack, Best User Research","flutter, dart, geminiapi, google-cloud-translate, langdetect",Ryan,Da,rda1@stanford.edu,,Best Beginner Hack,Best User Research,Best Interdisciplinary Hack,"Stanford University, University of California - Davis, San Diego State University",2,Omar,A,omararagon12345@gmail.com
Sounds Good To Me! (SGTM),107,https://hackdavis-2024.devpost.com/submissions/511398-sounds-good-to-me-sgtm,Submitted (Gallery/Visible),Pending,Submit,04/28/2024 15:33:59,"Inspiration

Build a community through similar tastes in music. 
For students who are seeking long-lasting friendships through common interests, music comes from the heart. We have met many good friends through similar music tastes and we want to elevate this experience for others who may be seeking.

What it does

Uses Spotify API to connect users to a central social messaging system where users of Spotify can connect with others and appreciate diverse music genres. Users can follow other community members as well as publicly comment on their playlists. DMs are also a fantastic way to get to know someone!

How we built it

Using full-stack development (python, js, html, css, Node.js), we created a framework that uses data from the Spotify API to centralize suggested accounts based on the logged-in users top songs/artists.
Mainly using the python Flask library, we integrated all website pages into one concise domain.

Challenges we ran into

Working as a team of all first-time hackers, we didn't know what to expect! 


We were unable to connect to the HD2024 wifi.
We do not have full access to necessary Spotify API for collecting user data
Beginner to none web-dev skills
Aimed high!
Using GPT API


Accomplishments that we're proud of

We were able to get a server running with connecting pages and are able to authorize a log-in for one specified user. Despite not knowing much about full stack dev, we managed to create a working environment that completely shocked us! We thought about throwing in the towel but persisted till the end.

What we learned

Full stack web dev!
Using Spotify API
Achieve efficient team work
Time management

What's next for Sounds Good To Me! (SGTM)

We plan to apply for Spotify's full-access API which will grant us the necessary authorization to datasets of songs, users, artists, followers, etc. 
Use GPT API to summarize user accounts into particular genres for suggesting on the main page.
Develop a async messaging system where users will be able to connect through the website.
This project will be expanded to multiple forms of media such as movies, games, fashion, art, etc.
",https://github.com/emiguo/HD2024,,"Best Beginner Hack, Most Creative Hack, Best UI/UX Prototyping","python, javascript, ngrok, css, html, flask, spotify, gpt, github",emiguo,Guo,emiguo@ucdavis.edu,,Best Beginner Hack,Most Creative Hack,Best UI/UX Prototyping,"University of California - Davis, University of California - Santa Cruz",3,Danee,Dang,daneedang03@gmail.com
RUNTH,118,https://hackdavis-2024.devpost.com/submissions/511399-runth,Submitted (Gallery/Visible),Pending,Submit,04/28/2024 15:34:02,"Introduction

RUNTH is a web application designed to enhance the safety and experience of female runners. By allowing users to input their preferences for a running route, Runch tailors suggestions that prioritize safety, scenic value, and appropriate terrain. Our goal is to empower women to run with confidence, knowing they're on a safe and enjoyable path.

Inspiration

The inspiration for RUNTH came from a collective desire to address safety concerns that disproportionately affect women runners. Hearing stories from friends and family about the anxiety associated with finding safe running routes, we saw a need for a solution that integrates safety with the natural desire to explore beautiful and challenging landscapes.

What it does

RUNTH uses user-submitted descriptions of their ideal running conditions to generate personalized running routes through OpenAI: ChatGPT response generation. Utilizing advanced mapping technologies from GoogleMaps API, it assesses factors such as safety, scenery, and terrain steepness to recommend routes that match the user‚Äôs preferences and current location, enhancing both physical and mental well-being.

How we built it

We built RUNTH using Next.js for a functional full-stack web application with Tailwind CSS, integrating Google Maps API for detailed and responsive map rendering. The back-end logic is written in JavaScript, utilizing APIs built in NextJS for OpenAI API to parse user inputs and rate route attributes like safety and scenic views. For designing, we have utilized Figma to illustrate the idea of women's safety while running and having a female designer on our team. We have also used Lottie Animation for interactivity and social boost for female engagement. 

Challenges we ran into

One major challenge was developing an algorithm that accurately interprets subjective descriptions into quantifiable metrics for route selection. Balancing the load between client-side and server-side processing to ensure smooth user experiences was another technical hurdle we had to overcome.

Accomplishments that we're proud of

We are particularly proud of creating an intuitive interface that simplifies complex technologies into a user-friendly platform targeting female runners for SOCIAL GOOD. Achieving a responsive design that adapts to various devices and implementing effective natural language processing to understand user preferences were significant milestones.

What we learned

Throughout this project, we gained insights into the intricacies of geospatial analytics and the power of AI in enhancing user interactions. We also improved our skills in full-stack development, from handling APIs to refining front-end details.

What's next for RUNTH

Looking forward, we aim to expand RUNTH by incorporating real-time safety data and community feedback features to continually enhance route recommendations. Additionally, we plan to explore partnerships with local authorities and fitness communities to broaden our impact.
",https://github.com/l3atjin/Runth,https://www.youtube.com/watch?v=RWouURbfFCE,"Best Beginner Hack, Best Interdisciplinary Hack, Best Health Hack, Best Overall Design, Best User Research","nextjs, openai, chatgpt, tailwind, api, figma, lottie, animation, google, maps, css, html, javascript",Nico,Gankhuyag,enkhjinico@gmail.com,,Best Health Hack,Best User Research,Best Beginner Hack,Minerva,2,Bat,Lamjav,l3atjin@gmail.com
Emply,116,https://hackdavis-2024.devpost.com/submissions/511400-emply,Submitted (Gallery/Visible),Pending,Submit,04/28/2024 15:38:04,"Inspiration

Many computer science students have struggled to find internships in recent years. It feels like you have to apply to at least 100 positions to even score a single interview.  This is a negative feedback loop as if you don't mass apply yourself, you won't have a chance at getting a job. This is exacerbated by the fact that a lot of applicants are applying for positions they are not qualified for. From the employer perspective, they then also have to deal with sorting with ""trash"" applications. 

What it does

We want to mitigate this problem via our website Emply which enforces a limit to how many applications a user can submit to any employer per week. This should hopefully encourage users to make their applications count (selecting a good employer fit, ensuring they qualify for the position, etc.). This should help employers too, as with the reduced volume of applications, they have less ""trash"" to sort through. 

How we built it

We used Figma to draft the UI design. We used flask as a python backend to help interface with the database, and the rest of our backend was javascript through React.js. The rest of frontend was general HTML5 and CSS. For our database, we used MongoDB because of its easy ability to setup cloud hosting. 

Challenges we ran into

We ran into a solid number of challenges, from the standard compatibility and dependency issues to longer and more detrimental attempts to implement a feature that led to failure. The first big challenge was attempting to implement popup windows, which had a persistent bug where they would reinitialize over and over again and rendered it relatively unusable. The other challenge was through our attempt to implement sessions to store user data. Cookies have issues when you are not using HTTPS, and when we did use it MongoDB struggled to pass data through. We solved this by storing local user auth states without cookies.

Accomplishments that we're proud of

As a team, we're proud of how much we were able to accomplish in 24 hours. Although we could use a few more finishing touches, we have most of the core functionality working, and we like how our UI looks and flows. Our integrated multi-faceted backend that works effectively internally and externally with the frontend. 

What we learned

We learned what working in a team under a big time constraint feels like. As a group, we learned version control and how to effectively combine code: Identifying key tasks, defining proper abstractions for them, managing logical dependencies, and merging branches coherently.

What's next for Emply
",https://github.com/mips2/hackdavis2024,,,"react, mongodb, python, flask, figma",Minji,Yun,minjiyun404@gmail.com,,Best User Research,Best UI/UX Prototyping,Best Hack for California GovOps Agency,"University of California - Davis, University of California - Santa Cruz",4,luukjanssen9,,luukjanssen9@outlook.com
DataDoor,157,https://hackdavis-2024.devpost.com/submissions/511401-datadoor,Submitted (Gallery/Visible),Pending,Submit,04/28/2024 15:38:55,"Inspiration

Michelle publishes data on the California Open Data portal as part of her work. She realized that there was a lot of great data on the data portal, but it was hard for people to find out about this data to explore it. There is a need for a tool that empowers people to discover data from a variety of sources.

What it does

DataDoor is a search engine that compiles government data from the municipal, county, state, and federal level that displays the most relevant databases in a user-friendly UI. 

How we built it

Michelle worked on the frontend in Adobe XD, web development using Flask, search algorithm, and zipcode geocoding. Abrar worked on the backend webscraping using Scrapy. All the code is in Python.

Challenges we ran into

Search engines could be slow, different websites had different HTML code and structure that hindered generalizability and automation of webscraping, and some websites were not suitable for webscraping using Scrapy. 

Accomplishments that we're proud of

We are proud that we learned many new tools, libraries, and algorithms for HackDavis and developed a functional end product in our first hackathon.

What we learned

We learned a lot. As neither of us are CS majors (civil engineer and biomed engineer), basically everything we did, from the web scraping, to the web development, is brand new to us! Thank you to the mentors for all your help throughout the weekend.

What's next for DataDoor

DataDoor can improve performance by developing a general Scrapy code and more powerful search algorithm to produce faster, more relevant results. We can implement more of the functionalities of the prototype, including the ability to filter by year and query more results. 
","https://github.com/ms-michelle-zhang/hackdavis-2024-datadoor, https://xd.adobe.com/view/7ba8f304-4ef7-4658-9d77-364792fb2d49-2efb/?fullscreen&hints=off",,"Best Beginner Hack, Best Interdisciplinary Hack, 	Best Hack for Social Justice, Best User Research","python, scrapy, flask, adobexd, geopy, ishell, rapidfuzz, html5, css3, xpath, google, deepnote, locofy.ai",AbrarSadikeen,Sadikeen,atakiyasadikeen@gmail.com,,Best Beginner Hack,Best Interdisciplinary Hack,Best Hack for Social Justice,"University of California - Davis, University of California - Los Angeles",1,Michelle,Zhang,michelleszhang@outlook.com
NeuralSearch,35,https://hackdavis-2024.devpost.com/submissions/511402-neuralsearch,Submitted (Gallery/Visible),Pending,Submit,04/28/2024 15:39:10,"Inspiration

Each and every one of our team members has had a problem with Google Scholar and the way it handles browsing research papers. Although there are filters and you can be as verbose as you'd like to, there's a fundamental flaw in browsing recent papers to keep up with what has been published. Many times,  publishers include 'clickbait' titles, and other times, those titles aren't intriguing enough. This leads to big problems within academia, most notably the amount of effort it takes to keep up with recent papers. These problems can eventually lead to over-extenuation of the brain from reading all of the seemingly nonsensical words that come with detailed research papers and take away from their time doing other, more important things.

What it does

RE Search is a highly unique state-of-the-art search engine that uses AI to both filter and specify search results. It's used to search all research papers to determine what's worth reading and what's not. 

How we built it

Our tech stack includes:
Python
React
Next.js
Google Gemini

Challenges we ran into

Challenges we ran into is that it's hard 

Accomplishments that we're proud of

What we learned

What's next for Untitled

RE Search is at its heart a learning tool designed for fast and efficient analysis of text. We shouldn't limit it to that function, however. Our 5-year plan is to become the quizlet of research papers... whatever
",https://github.com/Akiko0210/arc-research,,"Best Interdisciplinary Hack, 	Best Hack for Social Justice, Most Creative Hack, Best AI/ML Hack, Best UI/UX Prototyping, Best Overall Design, Best User Research","nextjs, python, gemini, flask, react",Elijah,Chen,vividwhispering@gmail.com,,Best AI/ML Hack,Most Creative Hack,Best Interdisciplinary Hack,De Anza College,0,,,
KibbleKeeper,22,https://hackdavis-2024.devpost.com/submissions/511403-kibblekeeper,Submitted (Gallery/Visible),Pending,Submit,04/28/2024 15:40:21,"Inspiration

As pet owners, we were frustrated with existing automatic feeder solutions and wanted to make something that was more affordable and accessible to the public. Through our research, we found that most options on the market (like this smart feeder by PETLIBRO) have a very high price point and fail to even support multiple pets per feeder. This makes them also impractical in settings like pet shelters, where there's a very big need for help feeding and otherwise taking care of animals. We made KibbleKeeper to solve these challenges, making the lives of pet owners easier while hoping to make the lives of pet shelter volunteers easier. We were also inspired by some of the challenge categories and wanted to challenge ourselves with a topic that covers multiple fields.

What it does

KibbleKeeper is an automatic feeder built using Kintone, a raspberry Pi, and multiple peripherals including LEDs, an RFID reader, and a motor. When a pet with an NFC-enabled collar approaches the feeder, it will identify and look up that cat's food schedule with the Kintone backend. If it is time to feed the pet, the feeder will dispense food according to that pets individual needs. This allows the feeder to seamlessly manage the diets of multiple pets, displaying feedback in the form of LEDs so the owner knows which cats have eaten. 

How we built it

Our team had to work together on a wide range of tasks for this project, from 3D printing and assembling the feeder to both programming and interacting with the Kintone API and Raspberry Pi peripherals.

Challenges we ran into

As we are all CS or CSE majors at UC Davis, we had to put a lot of work into creating the actual prototype. We also had to familiarize ourselves with Kintone for the first time, and properly manage linked databases on the backend.

Accomplishments that we're proud of

We are very proud of how we accomplished our challenges, and that we were able to put together such a comprehensive project in 24 hours. This is especially impressive given that 3 of us have never been to a hackathon before, and the 4th had never done so with other programmers.

What we learned

We learned a lot about the aforementioned tools used for this project, as well as proper class structures and coding practices when working as a group. We also peaked the interest of many mentors and other hardware hackers, who helped us secure components and gave us advise towards our project.

What's next for KibbleKeeper

Some stretch goals we were not able to accomplish in 24 hours including having a buzzer as feedback, handling multiple types of food, and a working UI for the pet owner. If this project inspires the judges and other hackers, we would love to accomplish these goals and make KibbleKeeper a great substitute for feeders already on the market.
",https://github.com/flexshure/smart-feeder,https://youtu.be/tVhT93C69hs?si=h1BE4XOVNFgaYNyf,"Best Health Hack, Most Creative Hack, Best Use of Kintone, Best Hardware Hack","kintone, python, raspberry-pi, nfc, cardboard, cheerios",Fletcher,Dube,fdube@ucdavis.edu,,Best Hardware Hack,Best Use of Kintone,Best Health Hack,University of California - Davis,3,Kyle,Pickle,kwpickle@ucdavis.edu
Good Neighbor,139,https://hackdavis-2024.devpost.com/submissions/511405-good-neighbor,Submitted (Gallery/Visible),Pending,Submit,04/28/2024 15:41:42,"

Inspiration üåü

Have you seen those posts on social media about people losing their valuables? How successful do you think they are, where everybody scrolls mindlessly. We wanted to create a platform that gurantees the best chance for the owner to find not only valuables, but pets, and people. 

What it does ‚öôÔ∏è

Most people are unable to help their community due to a lack of awarness, They don't know where their help is needed! Good Neighbor connects local communities, empowering individuals to offer assistance where it's needed most.


Search using interactive map for people who need your help
Post any problem you face instantly on the neighborhood feed
Lost & Found page for users to report their lost valuables and foundings
PropelAuthentication for user Login
MongoDb database to save user data and posts 
Fine Tuned ChatGPT AI assistant to help new users figure things out


How we built it üî®

A Fullstack app powered by the Mern Stack



PropelAuth Login



Google Maps Api for interative Map



Lost and found page


Mongodb to store userdata and Posts



GPT 3.5 turbo for AI assistant


Easily add new posts


Updated Neighborhood report



Challenges we ran into üôÖ


Propel Auth setup , we found it hard to navigate the documentation and set it up at first
Integrating maps API with dynamic user posts


Accomplishments that we're proud of üí™


We are proud of setting a fullstack app with a functioning database and backend API
We are proud of the interactive map showcasing the unique problems around you on Google Maps
Creating dynamic posts and saving them on our database and showcasing it on the posts feed


What we learned üß†


Time management
Not to overaim and keep it simple


What's next for Good Neighbor


Hosting on vercel
Creating chat feature between users to interact

",https://github.com/Saitarun994/Good-Neighbor,,"'	Best Hack for Social Justice, Most Technically Challenging Hack, Best Use of PropelAuth, Best Interactive Media Hack","react, tailwind, mongodb, propelauth, google-maps, node.js, express.js, axios",Sai,tarun,taruns994@gmail.com,,Best Hack for Social Justice,Best Use of PropelAuth,'	Best Hack for Social Justice,"Everest Institute - Rochester, Sacramento City College, California State University - Sacramento",3,Juan,Santelices,jdsantelicesl@gmail.com
Open-Park,140,https://hackdavis-2024.devpost.com/submissions/511406-open-park,Submitted (Gallery/Visible),Pending,Submit,04/28/2024 15:42:32,"Inspiration

Our group members consistently encounter issues with parking during the school week, so we decided to make a service that helps everyone find available parking spots in real time. We also decided to use cheap components, to show that the buy in cost is low for UC Davis and other campuses to integrate a parking service with their home website

What it does

A camera is integrated with a microcontroller, which takes images every few seconds. That data is sent as a base64 encoded file to a firebase realtime database. Then, another computer can pull from that database and perform image processing techniques to determine which parking spots are filled, and which are empty. That is then mapped to a grid representing the parking spots, which is then displayed on a website for users of the parking lot to see.

How we built it

Manoj--
Sayan--
Asad--  Designed the image capture and serial - base64 encoded format to be sent to the database
Dhilan-- Set up the firebase database and designed the sending and receiving functionality for the microcontroller and computer to transfer images over the internet.

Challenges we ran into

We also wanted to do license plate detection functionality, which could check with a database of registered cars to see if they paid for parking that day. We ran out of time and could not implement the hardware correctly to get the detection working.

Accomplishments that we're proud of

We learned how to convert between multiple data types and manipulate them over a server, which is something we have never done before. We also weaved multiple programming languages and libraries together to make a functional system. Our total cost for this project was only 15 dollars for the camera and microcontroller, as everything else was just a free online service. We also used some LEDs for interfacing, but those are pretty cheap and not required for every camera that is installed.

What we learned

What's next for Open-Park

License plate integration, and possibly pitching the idea to TAPS for them to integrate on their main website.
",https://github.com/SayanBhatia/HACKDAVIS-2024,,"Best Interdisciplinary Hack, Best Overall Design, Best Entrepreneurship Hack","python, opencv, matplotlib, firebase, arduino, c",Dhilan,Patel,dhpatel@ucdavis.edu,,Best Entrepreneurship Hack,Best Interdisciplinary Hack,Best Overall Design,"University of California - Davis, UC Davis",2,SrivatsaD,Devaraja,manojsrivatsa26@gmail.com
AllerSense,144,https://hackdavis-2024.devpost.com/submissions/511407-allersense,Submitted (Gallery/Visible),Pending,Submit,04/28/2024 15:42:39,"Inspiration

For those with more common allergies it is very easy to find allergens on food labels, but for those with less common allergies, this information may not be so easily apparent. These allergies may be hidden in a sea of other ingredients, or not even listed because it is a derivative ingredient. We created AllerSense to help those with less common allergies easily identify foods they are allergic to.

What it does

AllerSense utilizes computer vision to parse ingredients lists and alert the user if the item they scanned contains something they are allergic to. AllerSense also uses databasing technologies to allow users to search for certain foods and see if they are allergic to them without uploading images. 

How we built it

We built AllerSense by using Next.js with Typescript and Tailwind CSS for a powerful and dynamic frontend interface. For the backend we used flask to handle all our computer vision related needs, uploading images, and scanning text. For the database we leveraged the power of Google Firebase to have a flexible and adaptive no-sql database for all our data storage needs. Finally, we used Propel Auth for authentication to ensure a secure and reliable user login/sign-up. 

Challenges we ran into

Initially, we wanted to build a search engine to quickly query the user inputted foods from the database to ensure scalability as the user base grows. Despite our ambitions, this was simply too difficult to complete in one day, so instead we opted to use firebase so that we could get the base functionality covered. Another issue we faced was uploading, and cropping the image in the frontend and sending it to the backend to be processed. This was very time consuming and difficult to figure out.

Accomplishments that we're proud of

We are proud that we managed to handle all the database logic, allowing for separate users with their own  individual and personalized data. Another thing we are proud of is managing to upload the images to the backend for processing, since this was a very technically challenging task.

What we learned

We learned to plan out project infrastructure more carefully before we start coding to ensure a smooth developing experience, without having to pivot and change directions too much.

What's next for AllerSense

We want to expand from allergies to other dietary restrictions, such as vegetarian, vegan, kosher, and halal. We also would want to be able to feed the ingredients list into a model to find out more information about derivative ingredients.
",https://github.com/vikram087/HackDavis,,"Best Health Hack, Most Creative Hack, Best AI/ML Hack, Best Use of PropelAuth","python, flask, next.js, firebase, propel",Vikram,Penumarti,vikram.penumarti@gmail.com,,Best Health Hack,Best Use of PropelAuth,Most Creative Hack,"University of California - Davis, Napa Valley College",3,Savio,Esmailzadeh,savio.esmailzadeh@gmail.com
Life of Kai Website,95,https://hackdavis-2024.devpost.com/submissions/511408-life-of-kai-website,Submitted (Gallery/Visible),Pending,Submit,04/28/2024 15:43:43,"Inspiration

We want to help reunite lost dogs with their pet owner. We love dogs and they are dog's owner best friend.

What it does

It is a website that helps pet owners who lost their dog go onto the website and search for their missing dog. The search bar checks the information with the database and find if there missing dog is in one of the animal shelters.

How we built it

We use HTML to create the foundation of the website and CSS to style the webpages. We also use JavaScript to implement the search bar to check the database of the dog shelters to find a match of the missing dog.

Challenges we ran into

We want to implement AI or Machine Learning for searching the database. However, it is challenging for us as we are beginners to the Hackathons and not a lot of experience in those areas.

Accomplishments that we're proud of

The accomplishments that we are proud of is that we attempted many things to implement into our projects such as back-end, front-end. Even though we are not be able to use them into our project, we learn a great experience of this Hackathon and other coding areas in this development

What we learned

We learn that AI and doing full stack can be hard and time-consuming to learn. But with more time, we will be able to accomplish this goal. We also learn how to use HMTL, JavaScript and CSS.

What's next for Life of Kai Website

We are going to improve the website for functionality and a simpler website. Along with improving the search bar for missing dogs with the implementation of Machine Learning and a better database for more accurate search
",https://github.com/celionlyn/HackDavis2024,,"Best Beginner Hack, Best Entrepreneurship Hack, Best Hack for Life of Kai","html, css, javascript",Nicolas,Sukardy,niczop2167@gmail.com,,Best Beginner Hack,Best Hack for Life of Kai,Best Entrepreneurship Hack,"University of California - Davis, Orange Coast College, sobrato highschool",3,Kenneth,Ramos,kenneth.ramos95@gmail.com
MealSnap,82,https://hackdavis-2024.devpost.com/submissions/511409-mealsnap,Submitted (Gallery/Visible),Pending,Submit,04/28/2024 15:44:56,"Inspiration

There are many reasons to track your meals - to lose weight, to go on a bulk, etc. For many people, including myself (Jacob), meal tracking is such a tedious process, having to research into the caloric and nutritional content of a meal, and manually entering them into a spreadsheet. How could we solve this?

What it does

Our software, MealSnap, makes it incredibly easy to track meals. Take a picture with your webcam, and MealSnap will automatically break down the calories and other nutritional content in your meal, and this gets saved to your feed along with all the other meals you've logged. 

How we built it

We were inspired by the multi-modal capabilities of Google Gemini - we specifically used their Vertex AI API to send images to it and break down the nutritional content back as a convenient .json object. 

We used MongoDB to hold our meals collection as .json documents - storing info about a meal's name, description, timestamp, and all the nutritional info. We can't really store images in MongoDB, so we also use the Google Cloud Platform as a way to upload and store images to then display on the feed. 

For frontend libraries, we used Material UI. And ChatGPT was a huge help in figuring out some errors and how to parse inputs. 

For the rest of the tech stack, we used React for the Frontend, and Express for the Backend, and Node.js to run our app.

Challenges we ran into

Between me (Jacob) and my partner (Juan), I am very new to web development, and spent the whole night learning and debugging a ton of backend. There was always new issues arising, from setting up the CRUD routes and URI formatting, to a bunch of parsing and formatting issues with the meal .jsons. 

Accomplishments that we're proud of / What we learned

There were many issues we ran into throughout the night, but we persevered and even for as small of a prototype we have now, we're proud that we have it working to share it for this hackathon - this is my (Jacob) first hackathon I was able to submit :o. Hopefully this inspires other people to keep learning and keep trying!

What's next for MealSnap

We actually really like this idea for personal use and want to expand it further. 


Comprehensive table view; filter by nutritional value, dates, etc.
Dashboard for weekly / monthly views; meeting your nutritional goals
User profiles; share meals with other users : )

",https://github.com/hackdavis-2024/hackdavis-2024,https://youtube.com/shorts/Tg6ZCGqBCLs?si=PvrqOkfWxP26ZCxJ,"Best Beginner Hack, Best Health Hack, Most Creative Hack, Best AI/ML Hack, Most Technically Challenging Hack","node.js, react, google-cloud, mongodb, express.js, material",Jacob,Marinas,jacob1marinas@gmail.com,,Best Health Hack,Most Creative Hack,Best Beginner Hack,University of California - Davis,1,Juan,Alvarez,killopillers@hotmail.com
Untitled,,,Draft,Pending,Manage team,04/28/2024 15:46:22,,,,,,Nicholas,Kim,nskkim@ucdavis.edu,,,,Best Hack for NAMI Yolo,University of California - Davis,0,,,
Spot,111,https://hackdavis-2024.devpost.com/submissions/511414-spot,Submitted (Gallery/Visible),Pending,Submit,04/28/2024 15:46:29,"Inspiration

It was 11:39 PM on a Wednesday morning when I woke up to some unfortunate news. My favorite bike was missing, nowhere to be found. In a surge of desperation, I instantly surfed the web for any possible listings of my bike to no avail. If only there was a website dedicated to posting such listings that were inclusive to UC Davis students to create an efficient search for lost items. And that's when the idea struck me...an app for missing items.

What it does

The app allows UC Davis students to create posts for their missing valuables and provide an incentive for other students to find them. This incentive can range from money to any other form of compensation. Alternatively, students who find lost items can post them on our app for others to see. Each post requires an image, title, location, date, and incentive.

How we built it + Challenges we ran into

For this project, we initially started with Firebase, an unfamiliar technology for all of us. When we weren't successful, we transitioned over to MySQL. However, we still had issues in building our web app so we finally transitioned to SQLite in combination with Flask, Python, HTML, and CSS. We were trying to utilize feature detection for the user to hold their item in front of the camera for the app to automatically detect the item. However, the class sizes we used in Pytorch didn't simply limit to a single-digit number of items but realized that there are hundreds of different categories/items that can be posted on the Spot app. Additionally, creating a dataset that matches a picture with a label was difficult to do apart from the preset Pytorch datasets.

Accomplishments that we're proud of

We had struggles with the databases but we overcame it by focusing on the customer needs and narrowing down the best options.

What we learned

Working in a team is a high-stakes, high-pressure situation where people of different cultures and different backgrounds come together to participate in Hack Davis. It's always important to have an open mind.

What's next for Spot

We are planning to add new features, maybe finally creating an image detection feature, better UI, and a Davis map to pinpoint item locations found.
",https://hack-davis24.vercel.app/,,"Best Beginner Hack, Best User Research, Best Use of .Tech Domain Name, Best Finance & Tech","sql, sqlalchemy, sqlite, html, python, flask",Ashwin,Charles,ajcharles@ucdavis.edu,,Best Beginner Hack,Best Use of .Tech Domain Name,Best User Research,"University of California - Davis, University of California - Santa Cruz",3,Sathvik,Parasa,sathvikparasa007@gmail.com
Project Zero Waste,20,https://hackdavis-2024.devpost.com/submissions/511415-project-zero-waste,Submitted (Gallery/Visible),Pending,Submit,04/28/2024 15:46:33,"Inspiration

We have learned through many different outlets that food insecurity is an issue that is affecting many students and community members. We know many people who struggle to pay for their daily meals and we are also aware of the leftovers in restaurants and dining halls being tossed out and going to waste. We have created this project to address both issues.

What it does

This project aims to recruit volunteers to get in contact with restaurant owners and dining hall workers to collect leftovers and distribute it to those in need. We will conduct periodic surveys on the student and city populations regarding food security as well as workers on the status of food waste.

How we built it

We used Flask as our main tool for server hosting. We worked with HTML and CSS files for formatting and displaying the UI and used Python for backend operations.

Challenges we ran into

In the beginning, our team effort was very disorganized and we ran into a lot of issues and merge conflicts. None of us knew web development stuff beforehand so we all had to learn it very fast.

Accomplishments that we're proud of

Nearing the end of this event, we were able to join all our efforts together and get everything to work the way we wanted to. We were able to effectively split up tasks (two of us worked on the back end, one of us worked on the front end, and one of us worked on designing the webpage).

What we learned

Before this hackathon, we barely knew how to use Git as well as web development, but working on this project together has made us all much better at such tasks. We are now all comfortable with web development as well as with using Git to work on group projects. 

What's next for Project Zero Waste

We plan on expanding our project in the future to include a better database for better security as well as further improving the website's layout to enhance user experience. In addition to our website, we also plan on eventually making an app with similar functionality to make it more convenient for people to access. We still need to learn more about the different tools to create such applications in order to implement our plans, but we will continue our work in the near future.
",https://github.com/ethanysng/hackdavis24,,"Best Beginner Hack, Most Creative Hack, Best Overall Design, Best Hack for AggieHouse","flask, css, html, python",Chris,Liu,wwcliu@ucdavis.edu,,Best Beginner Hack,Best Hack for AggieHouse,Most Creative Hack,University of California - Davis,3,Varsha,Sivaprakash,varsivaprakash@ucdavis.edu
GreenSource Community Garden Finder,81,https://hackdavis-2024.devpost.com/submissions/511416-greensource-community-garden-finder,Submitted (Gallery/Visible),Pending,Submit,04/28/2024 15:46:36,"Inspiration

GreenSource Community Garden Finder was inspired by the need to reconnect individuals with the environment and promote sustainable living through accessible gardening. Observing that many urban dwellers lack the knowledge or means to access local green spaces where they can learn about and participate in sustainable agriculture, we aimed to bridge this gap. The project advocates for food sovereignty and environmental stewardship.

What it does

The GreenSource Community Garden Finder is a web platform that helps users locate nearby community gardens where they can grow their own food, participate in community activities, and learn about sustainable gardening practices. The platform provides detailed information about each garden, such as types of plants grown, volunteer opportunities, and educational workshops, making it easier for users to get involved in local green initiatives.

How we built it

We developed the platform using a combination of modern web technologies and traditional knowledge. The back-end is powered by Node.js and Express, providing a robust API for data management, while the front-end utilizes tailwind for a dynamic and responsive user interface. We integrated Google Maps API for location services, allowing users to find gardens based on proximity. The data about the gardens is crowd-sourced, ensuring that it is comprehensive and up-to-date.

Challenges we ran into

One of the major challenges was integrating various APIs seamlessly, especially in handling real-time data synchronization across the platform. We also faced difficulties in designing a user-friendly interface that could cater to both tech-savvy users and those less familiar with digital platforms. Ensuring the platform was inclusive and accessible to all, regardless of technological expertise, was paramount.

Accomplishments that we're proud of

We are particularly proud of creating a platform that not only facilitates access to green spaces but also fosters community engagement and education. Seeing our users actively participating in gardening activities and sharing their knowledge with others has been incredibly rewarding. Additionally, the positive feedback from community leaders on how our platform has revitalized local green spaces has confirmed the impact of our work.

What we learned

Throughout this project, we learned a great deal about sustainable agriculture, community building, and the technological intricacies of developing a large-scale web application. We gained insights into the challenges of data management and user experience design, and how to effectively address them to create a seamless service.

What's next for GreenSource Community Garden Finder

Looking forward, we plan to expand the platform to include more interactive features such as a gardening tutorial section, a forum for community discussions, and a feature for users to track their gardening progress. We also aim to partner with local schools and educational institutions to promote gardening education. Finally, we will continue refining our data model to include more detailed information about each garden's ecological impact and how it contributes to local biodiversity.
",https://github.com/mjollnir03/HD2024.git,,"Best Health Hack, 	Best Hack for Social Justice","node.js, express.js, tailwind, vsc",Xiaojun,Gong,xgong3@horizon.csueastbay.edu,,Best Hack for Social Justice,Best Health Hack,Best Interdisciplinary Hack,California State University - East Bay,3,Ellmaer,Ranjber,eranjber@horizon.csueastbay.edu
Lock In,84,https://hackdavis-2024.devpost.com/submissions/511417-lock-in,Submitted (Gallery/Visible),Pending,Submit,04/28/2024 15:47:18,"What it does

Due to issues with our original idea, the current iteration is not fully functional. Currently, the back-end and front-end are not meshed. 

The Back-End: Retrieves Professor and University Name through a GUI, the information is passed to the scraper that retrieves average ratings. The project interacts with Google Calendar and suggest study times based off a set of tunable parameters. From there, the events are uploaded directly into the calendar. 

Challenges we ran into

Originally, we were planning to power the website with GPT-4. Unfortunately, we couldn't get the bot to work outside of GPT's domain. Because of this, we had to start from scratch halfway through. 

Additionally, our experience with front-end was extremely minimal. For all members, the first HTML/CSS files we've created were for HackDavis. Because of our limited knowledge in this area, we struggled to integrate front-end functionality. 

Accomplishments that we're proud of

Despite our struggles, we learned a lot about HTML/CSS. While the project is not complete, a lot of the groundwork has been established. 

What we learned

HTML/CSS Fundamentals, Design, Web Scraping. 

What's next for Lock In

Looking forward, we plan to utilize the data gathered from these integrations to enhance our ChatBot interface. This will allow users to interact with the ChatBot to inquire about professor ratings and other academic information. Additionally, we aim to introduce further features such as timers, AI assistants, and other study aids, transforming LockIn into an indispensable studying companion.

Through these developments, we are committed to providing students with a robust platform that empowers them to excel academically.
",https://github.com/dsehsani/LockIn,,,"python, html, css, google",aaross808,Ross,aaross@ucdavis.edu,,NA,Best Beginner Hack,Best Hack for Social Justice,University of California - Davis,3,Enoch,Shen,enoshen@ucdavis.edu
Memento,136,https://hackdavis-2024.devpost.com/submissions/511419-memento,Submitted (Gallery/Visible),Pending,Submit,04/28/2024 15:48:27,"Inspiration

At our first hackathon, driven by the challenge of Alzheimer's within our families, we saw an opportunity for technology to gently intervene. Thus, Memento was born, embodying our belief that AI can restore the threads of memory that connect us.

What it does

Memento is a beacon of remembrance, utilizing Intel's OpenVINO API to harness powerful AI for facial recognition. It brings back the joy of recognition to those with Alzheimer's, reaffirming bonds with loved ones through a glance.

How we built it

Embarking on a journey through uncharted territories of AI at our inaugural hackathon, we merged our technical curiosity with a cause close to our hearts. Intel's OpenVINO API was our choice for its prowess in processing and real-time face matching capabilities.

Challenges we ran into

Balancing emotional sensitivity with technical robustness presented a unique challenge. We wanted Memento to not just recognize faces but to resonate with the user's emotions and memories.

Accomplishments that we're proud of

Implementing Intel's OpenVINO API was a milestone for us. The precision and efficiency it brought to Memento have paved the way for a tool that we hope will bring solace and smiles to many.

What we learned

Every line of code taught us more about the potential of AI to touch lives. The technical skills we've gained are invaluable, but the insight into AI's empathetic use is what truly enlightened us.

What's next for Memento

We envision Memento evolving, growing smarter, and more intuitive‚Äîbecoming a familiar face for those who need it most. This hackathon is just the beginning.
",,,"Best Beginner Hack, Best Health Hack, Best AI/ML Hack, Best use of Intel¬Æ Developer Cloud","python, swift, intel, openvino, ai",Aynan,Kareem,aykareem@ucsc.edu,,Best use of Intel¬Æ Developer Cloud,Best Health Hack,Best Beginner Hack,"University of California - Santa Cruz, UC Davis",3,Adishankar,Pradhan,adishankar@gmail.com
WagWatch,29,https://hackdavis-2024.devpost.com/submissions/511420-wagwatch,Submitted (Gallery/Visible),Pending,Submit,04/28/2024 15:49:42,"Inspiration

We got our inspiration from Life of Kai. We wanted to prevent pets from going homeless by helping pet owners not lose their pets with our device. 

What it does

It is a dog collar attachment that can track your dog by looking at its recent speed and direction. It can also observe environmental conditions, such as humidity and temperature, to see if your dog is in a safe area. A buzzer can also be remotely activated so you can hear your dog when it is close to you.

How we built it

We used a PSoC 6 BLE Prototyping Kit to control our circuits. We also wired individual sensors to the PSoC microcontroller board to measure humidity, temperature, acceleration, and direction.

Challenges we ran into

We ran into several circuit wiring challenges. We had issues with our LCD screen drawing too much current that our laptop's USB port could provide. We fixed this by flashing our code onto the microcontroller board and powering it through a USB power brick connected to an outlet. 

There was also an issue regarding the LCD screen not displaying anything. We resolved the problem by looking at the datasheet for the pin layout for the LCD and rewiring our circuit. 

Accomplishments that we're proud of

We are proud of 

What we learned

We learned that we need to carefully wire our circuits to prevent errors from occurring. 

What's next for WagWatch

We can add 5G compatibility so the device can post its feature results onto a server for us to view easily. 
",https://github.com/nathanllai/Wag_Watch,,"Best Beginner Hack, Best Interdisciplinary Hack, Best Health Hack, Best Hack for Life of Kai","c, psoc",Thomas,Liang,tholiang@ucdavis.edu,,Best Hack for Life of Kai,Best Interdisciplinary Hack,Best Beginner Hack,University of California - Davis,3,nathanllai,Lai,nllai@ucdavis.edu
GeoCycle ,85,https://hackdavis-2024.devpost.com/submissions/511421-geocycle,Submitted (Gallery/Visible),Pending,Submit,04/28/2024 15:51:27,"Inspiration

We took inspiration from all around us, with trash and waste products ending up in landfills when they could've ended up in recycling, being repurposed instead of sent to a landfill. We wanted to make sure that anyone and everyone has the power to participate in our goals, through building this web application! 

What it does

With authentication, server-side communication, and a variety of other technologies, we've created a user-friendly web application that users can sign in and sign up for. There are a variety of features and ideas we wanted to include, but due to the lack of time and resources, we were unable to include them. Some features we set up for but didn't have the chance to fully utilize include geo-fencing plots, dynamic user-profile pages set up with full customization an in-game currency/level up system, and a convolutional neural net to scan images in order to check the validity of the trash that user's pick up as being recyclable or not. 

What we're proud of

Given the extensive of our ideas, our skill-level, and what we implemented, we're really proud of how far we've come, as the brainstorming, implementing, and finishing process all happened within a day, and through it, we've learned about client-side and server-side technologies, responsive design, dynamic web pages, and utilizing pre-trained neural networks, although we didn't have the time to do most of these features we've spoken about. However, the experience is really valuable and we're glad that we're reached where we are at now
",,,"Best Beginner Hack, 	Best Hack for Social Justice, Most Creative Hack, Best AI/ML Hack, Best Overall Design, Sauce Labs Raffle","react, express.js, firebase, python, tensorflow, bootstrap",Rashmit,Shrestha,rashmit.stha@gmail.com,,Best Beginner Hack,Best Hack for Social Justice,Most Creative Hack,University of California - Davis,3,Adrian,Nguyen,aaang@ucdavis.edu
Hitch Hike,73,https://hackdavis-2024.devpost.com/submissions/511422-hitch-hike,Submitted (Gallery/Visible),Pending,Submit,04/28/2024 15:52:21,"Inspiration

HitchHike sprang from a clear need among UC Davis students for a more affordable travel option to the Bay Area, beyond the costly taxis or public transportation. Our platform utilizes a community-driven approach where students can list their travel plans, enabling others to join and share the expenses. This initiative not only helps save money but also fosters connections and promotes sustainability by reducing the number of cars on the road.

What it does

Hitch Hike is a premier car-pooling platform tailored to meet the needs of anyone seeking economical, efficient, and socially responsible transportation. Whether you're planning your journey ahead of time or looking for a last-minute ride, HitchHike connects you with the perfect travel solutions, right at your fingertips.

How we built it

HitchHike is crafted using cutting-edge technologies for a flawless user experience:


Swift for iOS: Delivers smooth, responsive app performance for Apple users.
Figma for UI/UX Design: Our intuitive and attractive design makes ride-sharing a pleasure.
Firebase Backend: Ensures reliable and secure management of user data and ride details.


We also conducted an extensive survey to tailor our app to the needs of the user. Here are the results:


Frequency of Travel: Over 78% of students travel to significant locations at least once per semester.
Desire for a Student-Focused Platform: 84.4% of students prefer a ride-sharing service tailored specifically to their needs.
Top Priorities: Cost efficiency (78%) and safety (62.5%) are the principal concerns for our users, which are also HitchHike's core features.


Challenges we ran into

During the development of HitchHike, we encountered several challenges:


Managing Chatroom Associations: Keeping track of group IDs and associating users in chatrooms by their IDs required meticulous backend organization to ensure seamless communication between drivers and riders.
Map View Integration: Converting user-inputted location strings into geographic coordinates for map display posed a significant technical hurdle, demanding thorough geocoding implementation.
User Addition to Rides: Understanding and implementing the backend functionality behind adding users to rides proved complex. This included tasks such as adding users to associated chatrooms, updating available spots, and recalculating split balances, requiring careful consideration of user interaction and data management.


Accomplishments that we're proud of

Throughout the development journey of HitchHike, we've achieved several milestones that we're incredibly proud of:


User-Centric Design: Crafting an intuitive and user-friendly interface that prioritizes the needs of both drivers and riders, ensuring a seamless experience for all users.
Advanced Scheduling Feature: Successfully implementing an advanced scheduling feature that allows users to plan rides well in advance, providing flexibility and convenience.
Efficient Backend Management: Developing robust backend infrastructure to handle user data, chatroom associations, and ride functionalities, ensuring smooth operation and reliability.
Geolocation Integration: Successfully integrating geolocation services to accurately display user-provided locations on the map view, enhancing navigation and user experience.


These accomplishments reflect our commitment to delivering a high-quality ride-sharing platform that meets the diverse needs of our users and enhances their overall travel experience.

What we learned

Developing HitchHike has been a journey of discovery and growth for our team. Here are some of the key lessons we've learned:


User Empathy: Understanding the diverse needs and preferences of our users has been paramount. We've learned to prioritize user feedback and iterate on our designs to create a platform that truly resonates with our audience.
Technical Challenges: How to overcome technical challenges, such as managing chatroom associations and integrating geolocation services, has deepened our understanding of backend development and geospatial data handling.
Team Collaboration: Effective teamwork and communication are essential for the success of any project. We've learned to leverage each team member's strengths and expertise to overcome obstacles and achieve our goals.


These lessons have not only shaped the development of HitchHike but have also equipped us with valuable insights and skills that we'll carry forward into future projects.

What's next for Hitch Hike

As we look to the future, we have exciting plans to further enhance and expand HitchHike. Here's what's on the horizon:


App Store Launch: Our main goal is to make HitchHike readily accessible everywhere. We're working diligently to launch the app on the App Store, making it easier than ever for anyone to join the HitchHike community and enjoy the benefits of affordable ride-sharing.
Feature Enhancements: We're committed to refining existing features and introducing new ones based on user feedback and emerging trends in the ride-sharing industry. Expect updates that improve usability, increase functionality, and elevate the overall HitchHike experience.
Partnerships and Collaborations: We plan to explore opportunities to collaborate with local businesses, transportation providers, and student organizations to offer exclusive deals, promotions, and events for HitchHike users.
Community Engagement: Building a thriving community is at the heart of HitchHike. We plan to engage with our users through social media, events, and feedback sessions to ensure that HitchHike remains a platform that meets their needs and exceeds their expectations.


The journey doesn't end here. HitchHike is poised for growth, innovation, and continued success as we strive to revolutionize the way students travel and connect.
","https://github.com/rohanmalige/hitchhike, https://www.figma.com/file/PdH6uWUGZamGEDqYe1dtZI/Hitch-Hike?type=design&node-id=0-1&mode=design&t=LiC9ZBtVy7fG48iW-0, https://www.figma.com/file/RsZhW1jD4UEuGJgCXtN9rD/Untitled?type=design&node-id=0-1&mode=design&t=87G92wFfFN8vwrS7-0",,"Most Creative Hack, Best AI/ML Hack, Most Technically Challenging Hack, Best UI/UX Prototyping, Best Overall Design, Best User Research, Best Entrepreneurship Hack, Best Statistical Model","swift, figma, firebase, machine-learning",Pranav,Bhartiya,prbhartiya@ucdavis.edu,,Best User Research,Best Entrepreneurship Hack,Most Creative Hack,University of California - Davis,2,Lena,Ray,lenray@ucdavis.edu
CerebrAlert,,,Draft,Pending,Additional info,04/28/2024 15:52:53,,https://github.com/ssathya30/Hackdavis24,,"Best Interdisciplinary Hack, Best Health Hack, Best Hardware Hack, Best Statistical Model","c, python, swift, cc3200, arduino, i2c, spi",Jonathan,Wang,jonwan@ucdavis.edu,,Best Statistical Model,Best Hardware Hack,Best Interdisciplinary Hack,University of California - Davis,3,Andrew,Fu,adfu@ucdavis.edu
Maple ,10,https://hackdavis-2024.devpost.com/submissions/511424-maple,Submitted (Gallery/Visible),Pending,Submit,04/28/2024 15:53:51,"The inspiration for this project was an additional safety tool to help close friends and family work together to live in the dangerous we exist in today. 
We built this project using node.js and react.js. 
Some challenges we ran into include storing and sending emails to an emergency contact list. The color scheme of the button in according to the app design also gave us difficulties for some time. 
With the app, we are able to accommodate our goal of ensuring extra safety for those who need it while making it simple enough for the older generation to use. Creating an app that would help improve the well-being of the world is the biggest accomplishment in the creation of Maple. 
We learned that in creating an app, just as important as the back end part of creating the app, the general designs and front ends of the app are difficult as well, and collaborating as one team can create an enjoyable work environment while we work on something that will better the situation of the world we exist in. 
Accessibility changes and front and back-end improvements will be made to futher improve the app. 
",http://safeguard-app.tech,,,"node.js, react.js",joel,johnson,coujo.rocks@gmail.com,,Best Beginner Hack,Best Use of .Tech Domain Name,Hacker's Choice Award,"University of California - Davis, UC Davis",3,Harrison,Tan,tan.32harrison@gmail.com
Noise Free MHD Submarine w/ CV,164,https://hackdavis-2024.devpost.com/submissions/511425-noise-free-mhd-submarine-w-cv,Submitted (Gallery/Visible),Pending,Submit,04/28/2024 15:55:11,"Inspiration:

The ocean continuous to remain the most unexplored place on our Earth. With it's vast area and great depth, the ocean's mysteries come to rival the unknowns of space. In order for us to conduct research in Ocean environments we use means of transportations that create noise pollution. This noise pollution makes it hard for sea creatures to hear the natural sounds of the ocean, including predator cues, prey coming by and potential mating partners. So we set out to create a solution that would allow us to explore at greater depths without harming the environments we wish to observe. With ionic wind propulsion systems having their stride in altering the aviation industry, it's causing the magnetohydrodynamic drive could alter the way we travel the seas forever. 

What it does

Magnetohydrodynamic drives utilize the conflicting nature of electric fields and magnetic fields to create thrust. As electric fields have positive ions traveling towards their negative neighbors, they create a ""wind"" or thrust as they pick up on the ionized salt water traveling between them. Magnetic fields create torques in the electric fields, driving the ionized water molecules down the channel to create forward thrust. Such a driving system utilizes zero moving parts and creates virtually no noise pollution. The system is simple, calling for a powerful magnet and as little as 15V to create movement. The center capsule of the submarine houses a raspberry pi and arduino circuit that uses pwm to control the power given to the thrusters. Allowing for forward and turning movement. 

How we built it

We built from supplies we purchased from home depot, including magnets, stainless steel plates, pvc pipes and epoxy. We designed the submarine to be buoyant in its natural state and light enough to overcome the additional weight of the magnet and electrodes. 

Challenges we ran into

We had a couple of challenges that we ran into. Firstly, the amount of salt we added in our trials was not consistent and this led to a lot of variation between our results. The shape and size of our original electrodes and magnets created unexpected difficulties. We ended up trying multiple types of both and had successful and unsuccessful results with both as well.

Accomplishments that we're proud of

We were proud to demonstrate the viability of a MHD even with the limit in material we had. 

What we learned

We learned a lot about materials and their conductivity. Metals like aluminum began to chip and due to the high voltage, every metal we worked with corroded.

What's next for Noise Free MHD Submarine w/ CV

Integrating the subsystems and testing in an actual open space environment, one that has consistent salinity and valuation training targets such as the ocean. 
",,https://youtube.com/shorts/dXW8-0H8pwY?feature=share,"Best Beginner Hack, Best Interdisciplinary Hack, 	Best Hack for Social Justice, Most Creative Hack, Most Technically Challenging Hack, Best Overall Design, Best Hardware Hack","python, c++, raspberry-pi, arduino, resnet, opencv",Giancarlo,Troglio,grtroglio@ucdavis.edu,,Best Interdisciplinary Hack,Best Beginner Hack,Best Hack for Social Justice,"University of California - Davis, Massachusetts Institute of Technology",3,Nicholas,Kim,nskkim@ucdavis.edu
Flood Finder,166,https://hackdavis-2024.devpost.com/submissions/511426-flood-finder,Submitted (Gallery/Visible),Pending,Submit,04/28/2024 15:55:19,"Inspiration

Based on the prompt of ""Social Good"", we wanted to build something around the idea of a disaster (flood) detection system and disaster safety recommendation system all in one place. We started developing it to work specifically on floods but did see the opportunity for integrating more types of disaster warnings in the future.

What it does

We converged on this idea of giving it the capability to detect nearby danger warnings or signs of a flood, then relay a response recommendation using AI generated text. We also wanted to display an embedded map of the nearest flood point to the user to help them gauge their reaction to it.

How we built it

The frontend uses pure HTML, CSS, JS, and used created a custom Python Flask API that used the OpenAI Function-Calling API to implement Retrieval-Augmented Generation system that ensures the coordinates of the given city are accurate, which is then passed to the Google Earth Engine to obtain flood data. The flood data is displayed in a user-friendly manner via the embedded map and AI-generated disaster-response recommendation. 

Challenges we ran into

We got really close to fully implementing the full site but fell behind on finding out how to host our Flask API, ran into issues with animating the site out of a lack of experience, and began running into issues with using the Google Earth Engine to obtain flood probability to coordinate pairings.

Accomplishments that we're proud of

We are proud of the Retrieval-Augmented Generation system that we developed and the UI/UX design that we went with for the site. Even though we did not get it working the way we wanted, are proud of everything we accomplished as far are web design and access to both internal and external APIs. We used a lot of new techniques and elements to piece what we could together and was a first-time experience working with APIs and open-source plugins for some of our team's members.

What we learned

We learned a lot about how difficult it can be to work with so many technologies, especially across three different computers with varying environments. We also found out what we did not know when building something of this scale, as we were unable to host the site anywhere out of an inability to host the Flask API, the backbone of being able to host the site online, among other issues.

What's next for Flood Finder

We would like to expand into other disaster types, and actually get this site running and looking good.
",https://github.com/Iemontine/FloodFinder,,,"python, html, css, javascript, google-earth, openai, retrieval-augmented-generation",Darroll,Saddi,computereality@gmail.com,,Best Beginner Hack,Best UI/UX Prototyping,Best AI/ML Hack,University of California - Davis,2,Rawan,Dirhalleh,rhdirhalleh@ucdavis.edu
PetFinder,21,https://hackdavis-2024.devpost.com/submissions/511427-petfinder,Submitted (Gallery/Visible),Pending,Submit,04/28/2024 15:56:23,"Life Of Kai

What it does

It is a pet finder app with several features including some gamifying aspects to it. For example, we have an interactive map page where people can submit photos of animal sightings and it will automatically pinpoint the location and information on the map. Users can also filter the different animals (based on the info listed in the home pages) and look at the different sightings posted by everyone to ensure that the lost animal will be found quickly. 

Accomplishments that we're proud of

The design models of our app.

What's next for PetFinder

Add more interactive features to engage the community members further as well as help find all the lost pets in the neighborhood. Also, finish coding the app and its functions.
",,,,figma,Grace,Chen,gracechen56607@gmail.com,,Best Beginner Hack,Best UI/UX Prototyping,Hacker's Choice Award,University of California - Davis,3,Charishma,Chandu,cchandu@ucdavis.edu
MooDy,156,https://hackdavis-2024.devpost.com/submissions/511428-moody,Submitted (Gallery/Visible),Pending,Submit,04/28/2024 15:56:41,"Our Motivation

While working in the demanding and fast-paced school environment, many students struggle to care for their health. Resources remain scarce and expensive, and even finding a specialist or counselor can take months. We wanted to create a seamless helper who seamlessly integrates your health history and can help you as soon as you download it.

What is MooDy?

MooDy is your personal health and wellness assistant! MooDy intelligently and adaptively summarizes different aspects of your life like sleep habits, physical activity, and wellness by using data from your health app. 

How MooDy Works

MooDy uses the ReactNative API to interface with users and collect data from Apple Health's API, AppleHealthKit. It synchronizes data between the two apps. MooDy itself lives in the backend as a unique Assistant who makes calls to the OpenAI API. MooDy has the power to scour files for relevant health information and provide health insights.

Future Updates for MooDy

We plan to push MooDy's capabilities by giving it further tools to analyze health data. For example, we're working to implement intelligent sampling, placing greater value on more recent health information and taking fewer samples from old datasets. Soon, MooDy will also be able to point you to useful resources like blog posts and YouTube videos for your areas of focus.
",https://github.com/KyleLombardi/HappyMoo/tree/main,,"Best Interdisciplinary Hack, Best Health Hack, Best AI/ML Hack","python, openai, reactnative, applehealth, javascript",Kirin,Kapoor,kirin.kapoor@gmail.com,,Best AI/ML Hack,Best Health Hack,Best Interdisciplinary Hack,University of California - Davis,3,Maggie,Chen,maggie.qiu2002@gmail.com
Donating in Davis,70,https://hackdavis-2024.devpost.com/submissions/511429-donating-in-davis,Submitted (Gallery/Visible),Pending,Submit,04/28/2024 15:58:19,"Inspiration

As someone who has volunteered at Davis Community Meals for a few months, I see the uncertainty faced by cooks who didn't know what to cook because they didn't know what was in the fridge. Having an intuitive App to check inventory would not only be beneficial to them but also to those who want to donate to DCHM.

What it does

Our app, Davis Donates, contains two logins and an inventory system. Inventory is sorted into categories. Admin can add and delete items along with changing the amount in stock.  If the stock goes lower than 30% of the maximum, also set by the admin, the item is highlighted in red. Regular users can also view inventory. If a user chooses to donate, they can set a time to drop off the donations and get a QR code. This QR code can be scanned by an admin after drop and the user is awarded points for their donations. Speaking of points did we mention that we have a leaderboard system? Top donors will be shown on our leaderboard! 

How we built it

The functionality for Davis Donates was built in React Native while the UI was primarily developed and prototyped in Figma.

Challenges we ran into

Implementing QR codes was a challenge because there were new frameworks we weren't familiar with. Integrating UI from Figma to React Native was a challenge that came unexpectedly but we were able to make progress.

What we learned

For all of us, it was our first time in a Hackathon and a team setting. It was a nice experience learning to use Figma and Figjam for collaboration. For those of us who weren't familiar with React, we were able to get a sneak peak of what the framework has in store.

What's next for Donating in Davis

Given more time we would like to add more to the point system, like badges and redeemable rewards. 
","https://github.com/YungGuam/DCMH, https://www.figma.com/file/zIOkfzsepXhxqOsmY0zZ10/DCHM?type=design&node-id=0%3A1&mode=design&t=kW80aZWRC01Sm1Zw-1",,"Best Beginner Hack, Best UI/UX Prototyping, Best Entrepreneurship Hack, Best Hack for DCMH","react, figma",Adrian,Perez,appperez@ucdavis.edu,,Best Hack for DCMH,Best Beginner Hack,Best UI/UX Prototyping,University of California - Berkeley,3,Arya,Trivedi,arya.trivedi7960@gmail.com
Mad Molecool,160,https://hackdavis-2024.devpost.com/submissions/511431-mad-molecool,Submitted (Gallery/Visible),Pending,Submit,04/28/2024 15:58:31,"Inspiration

It's not uncommon for molecular scientists to express frustration with outdated software tools used to aid their research. Many scientific software applications were developed years ago and may not have kept pace with advancements in technology or the evolving needs of researchers. As a result, scientists may encounter limitations such as poor user interfaces, lack of compatibility with modern operating systems, or inefficient data processing capabilities. Overall, the work of molecular biologists has far-reaching implications for human health, agriculture, industry, and the environment, making invaluable contributions to the advancement of science and the betterment of society; therefore, it's important their technology is on par!

What it does

Our application is an all in one space for molecular biologists! Please see photos

How we built it

Challenges we ran into

Accomplishments that we're proud of

What we learned

What's next for Mad Molecool
",,,"Best Interdisciplinary Hack, Best AI/ML Hack, Best use of Intel¬Æ Developer Cloud, Best Use of PropelAuth","python, react",Sapana,Dhakal,sdhak0004@student.cerritos.edu,,Best use of Intel¬Æ Developer Cloud,Best AI/ML Hack,Best Interdisciplinary Hack,"Cerritos College, California State University - Long Beach, University of Nevada - Reno",3,Prajwal,Sharma,prajwal.sharma01@student.csulb.edu
Anaphora,68,https://hackdavis-2024.devpost.com/submissions/511432-anaphora,Submitted (Gallery/Visible),Pending,Submit,04/28/2024 15:59:34,"Inspiration

We took this idea focusing on modern day problems such as dementia patients.

What it does

Caregivers are able to use the web application to view patients history and help monitor their health status. Through the apple watch our software detects speech recognition and monitors the patients and will summon paramedics if heart rate and repetition reach a threshold.

How we built it

Frontend - react, node.js, figma
Backend - python, javascript
Database: PostGRE SQL

Challenges we ran into

Some of the challenges we ran into are working with intel integration. Finding the right database.

Accomplishments that we're proud of

Backend development of speech recognition and working with APIs

What we learned

With the Anaphora software it is versatile as it can be used on the website and through apple-watch.

What's next for Anaphora
",,,"Best Interdisciplinary Hack, Best Health Hack, Best AI/ML Hack, Best User Research","python, react, json, javascript, node.js",Awen,Li,tigerali98@yahoo.com,,Best Health Hack,Best Interdisciplinary Hack,Best AI/ML Hack,"University of California - Davis, sfsu, University of California - Irvine, University of California - Berkeley",3,Naing,Htet,nainghtet123@gmail.com
Aggie House Portal,153,https://hackdavis-2024.devpost.com/submissions/511433-aggie-house-portal,Submitted (Gallery/Visible),Pending,Submit,04/28/2024 15:59:40,"üëÄ Inspiration
We were inspired by the Aggie House website and Aggie House's mission.

*Mission Statement
Our web app, Aggie House Portal, was designed to create a streamlined product for admin to easily schedule volunteers based on their availability and allow them to be well-notified of their upcoming shifts.

How we built it?
Figma was used for all design processes.
React and Next.js was used as frameworks with Typescript for the front and backend. 
We used MySQL for our database while also displaying volunteer availability data when scheduling a volunteer. As well as, prima as a tool to assist us in querying it. In addition, we used tailwind css to style our front-end components. 

Our biggest challenges?
Time and technical constraints. There was a learning curve in understanding the design to development time ratio. Designing in a way that didn't compromise user-centricism but was also feasible for developers was difficult. We referred to our effort-impact matrix to optimize this process.

üèÜAccomplishments that we're proud of!
We are most proud of the end-to-end nature of our product. 

From extensive user research to ideation and prototyping to a full-stack web app, we have prioritized every step of the design-to-dev process. By providing a solution tailored to Aggie House's needs, we have preserved the simplicity and functionality of our product, 

What we learned?
We learned how to be a cross-functional team and better scope the feature functionality within the given time frame.

What's next?
Implementing Shift swaps in the developed product and maching the design prototype.
",https://www.figma.com/file/joUWXmq5JaEePVvqyMoggV/Hack-Davis-2024?type=design&node-id=164%3A3231&mode=design&t=ExZPF5XHjCPR9GdZ-1,https://youtu.be/FXCqXiC6dbQ,"Best UI/UX Prototyping, Best Overall Design, Best User Research, Best Hack for AggieHouse","next.js, mysql, prisma, react, amazon-web-services",Dheeksha,Mageswaran,dheeksha.magesh@gmail.com,,Best Hack for AggieHouse,Best Overall Design,Best UI/UX Prototyping,University of California - Davis,3,Jess,Fong,jessicajeanfong@gmail.com
Aggie Motivation,148,https://hackdavis-2024.devpost.com/submissions/511435-aggie-motivation,Submitted (Gallery/Visible),Pending,Submit,04/28/2024 16:00:00,"We was inspired by motivational speakers who make us feel better.

The project gives aggies motivation through hard times.

We created an environment to show the image of Gary may, and used an algorithm to print the text in a ""visual novel"" manner.

The algorithm to progress the text had some issues.

We were proud to give inspiration to all aggies.

We learned that hackathons are a great time.

For the next version of Aggie Motivation, I will have more options on what the aggie can hear depending on how they are feeling.
",,https://youtu.be/CoXgJPV9oTE,"Best Beginner Hack, Best Interdisciplinary Hack, Most Creative Hack",matlab,Akram,Bantan,akrambantan2001@gmail.com,,Best Beginner Hack,Best Interdisciplinary Hack,Most Creative Hack,University of California - Davis,1,ABDULLAH,DUBAIS,aboodamd2012@gmail.com
Split-it,64,https://hackdavis-2024.devpost.com/submissions/511436-split-it,Submitted (Gallery/Visible),Pending,Submit,04/28/2024 16:00:36,"Inspiration

Gathering with friends weekly for meals, groceries, or drinks often involves someone picking up the tab. But calculating everyone's share with tax and tip can be more than a hassle - have you ever had to split the grocery bill with roommates? However with Split It, you can say goodbye to those tedious calculations. Just snap a pic of the bill, and let the app do the rest -- You Snap It, We Split It!

What it does

Split-It is a handy web app that automatically calculates the split cost per person, whether paying individually or family-style! Simply upload a picture of your receipt, select your desired options, and split it on the spot!

How we built it

We built Split-It using React and Node.js. Using Express.js, for the backend, and a combination of CSS,  HTML, JavaScript, and MaterialUI for the front end, we deployed a full-stack application that quickly utilizes powerful OCR technology to scan and analyze receipts. Our receipt scanner utilizes Matplotlib, NumPy, OpenCV, PIL, and Pytesseract, all to combine and produce an effective and accurate image-scanner. For our Individual split option, we leverage ChatGPT hosted in llama.cpp to prompt engineer JSON encoded responses to pass back to the frontend.

Challenges we ran into

Connecting the back-end python script to the front-end. Having the image user uploaded correctly go into the python script and running it. Additionally, faced difficulties with version control using Git, encountering conflicts with the main branch.

Accomplishments that we're proud of

We're proud of successfully overcoming challenges as a team, particularly in communication and problem-solving. Each challenge we faced provided valuable learning opportunities, enhancing our teamwork skills and deepening our understanding of programming languages and libraries.

What we learned

Through the challenges we encountered, we learned valuable lessons in teamwork, communication, and problem-solving. We also gained insights into using various programming languages and libraries to build a complex application.

What's next for Split-it

In the future, we plan to further enhance Split-It by adding additional features and functionalities, such as improved receipt reading capabilities, enhanced user interface elements, and integration with additional payment platforms. Simplicity and usability is what we aim for, the easier, the better. 
",https://github.com/yooian/split-it.git,,,"llama.cpp, react, express.js, node.js, openai, numpy, matplotlib, opencv, pil, python, javascript, html, css, materialui, pytesseract, jupyter",Truong,Nguyen,truong.m.nguyen@sjsu.edu,,Best Beginner Hack,Best AI/ML Hack,Best UI/UX Design,"San Jose State University, University of California - Davis",3,wesleykieu,Kieu,wesleykieu13@gmail.com
BloomBot,135,https://hackdavis-2024.devpost.com/submissions/511437-bloombot,Submitted (Gallery/Visible),Pending,Submit,04/28/2024 16:00:37,"Inspiration

The inspiration for BLOOMBOT came from observing the common challenges in plant care and recognizing the profound positive impact that nurturing plants can have on one‚Äôs mental well-being. It was designed to alleviate the stress of maintaining healthy plants while promoting joy and tranquility through successful plant cultivation.

What it does

BLOOMBOT is a smart device that monitors and reports on critical environmental conditions affecting plant health, such as room temperature, humidity, light exposure, and soil moisture. Using Telegram for updates, it provides plant owners with real-time insights and suggestions for optimal plant care directly to their mobile devices.

How we built it

We integrated various sensors including a KY-019 photoresistor for light, a moisture sensor for soil conditions, and a temperature and humidity sensor to monitor the environment. Data from these sensors is processed and stored on an AWS server, with insights pushed to users via Telegram messaging powered by an ESP32 controller.

Challenges we ran into

The hackathon kicked off with significant technical issues, particularly with the humidity sensor malfunctioning, which led to the first three hours being dedicated to finding alternative solutions. One of the primary challenges we faced was collecting accurate and timely data from environmental sensors to offer dependable advice on plant care. Additionally, seamlessly integrating various technologies such as sensors, cloud servers, and messaging platforms presented considerable difficulties.

Accomplishments that we're proud of

Our team can take pride in several key accomplishments: overcoming initial technical challenges with the humidity sensor through creative problem-solving, successfully integrating diverse technologies like sensors, a cloud server, and a messaging platform to create a functional system, and ultimately contributing to easier and more effective plant care. These achievements demonstrate technical proficiency and resilience and highlight your commitment to enhancing plant health and owner well-being. 

What we learned

We also learned a lot as a group since some of us were introduced to new territories that we weren't necessarily comfortable with. We learned a lot about system integration in the sense of different components communicating with each other. 

What's next for BloomBot

Moving forward, BLOOMBOT plans to introduce several significant upgrades and features to enhance its functionality and reach. These include the implementation of advanced AI algorithms for better prediction of plant needs, expansion of the plant database to accommodate a wider range of species, and improvements to the user interface for a more intuitive experience. Additionally, new sensor capabilities will be added to monitor vital factors like nutrient levels and specific light wavelengths. The development of community features will allow users to connect, share tips, and track their plant growth, fostering a vibrant community of plant enthusiasts. Finally, exploring market expansion into different regions and climates will adapt BLOOMBOT to various environmental conditions and gardening practices, aiming to make it a global leader in smart plant care technology.
",https://github.com/BatuhanSA/BloomBot,,"Best Beginner Hack, Best Health Hack, Most Technically Challenging Hack, Best Hardware Hack","ky-019, photoresistor, amazon-web-services, ec2, flask, esp32, temperature, sensor, moisture, gemini, google, ai, python, wifi, react, javascript",Batuhan,Salih,basalih@ucsc.edu,,Best Beginner Hack,Best Hardware Hack,Best Health Hack,"University of California - Santa Cruz, UC Santa Cruz",3,Vaibhav,Honakere,vaibhavhonakere123@gmail.com
Untitled,,,Draft,Pending,Manage team,04/28/2024 16:01:47,,,,,,nathanllai,Lai,nllai@ucdavis.edu,,,,Best Statistical Model,University of California - Davis,0,,,
BinxBud,53,https://hackdavis-2024.devpost.com/submissions/511442-binxbud,Submitted (Gallery/Visible),Pending,Submit,04/28/2024 16:02:53,"According to World Bank statistics, the world's waste output is expected to keep growing. While there are many reasons for this increase, only 19% of the waste is recovered through recycling. Most recycling efforts fail due to an excess of contaminants. To prevent this problem we developed BinBud to reduce the contaminants from the public. BinBud utilized VGG16 algorithm to classify the trash in accordance with the California government recycling program. We sourced data from Kaggle and trained the classification model on 22 thousand images. During this hackathon, we hoped to develop a user-friendly app that lets the user take an image of their trash and label the trash. The app would also include features that would allow farmers in Yolo County to sell their trash in bulk to local refineries however and a chatbot feature to help confused users, but we weren‚Äôt able to deploy these features before the deadline. But, our VGG 16 model outclasses most contemporary models and classifies trash across 14 categories with an average accuracy of 92%. With Bin Bud we give you the power to save the world with every click.
",https://github.com/ria-bhandari/BinBudd_Hack_Davis24,,"Most Creative Hack, Best AI/ML Hack, Best Statistical Model","python, java, android-studio, tensoflow, clip, git, huggingface, keras",Brody,Roberts,brodyroberts2002@gmail.com,,Best AI/ML Hack,Best Statistical Model,Most Creative Hack,University of California - Davis,3,Abhiram,Borra,aborra@ucdavis.edu
Rate My Toilet,63,https://hackdavis-2024.devpost.com/submissions/511443-rate-my-toilet,Submitted (Gallery/Visible),Pending,Submit,04/28/2024 16:03:50,"Inspiration

We struggled with finding the best toilets to go to on campus.

What it does

It is a website that gives reviews on different toilets on campus. Users can also leave a like on the review.

How we built it

We used React in VScode to build the project.

Challenges we ran into

We struggled with how to implement the website search function and the like function.

Accomplishments that we're proud of

We were proud of making a successful prototype of the website.

What we learned

We learned how to make a website using React.

What's next for Rate My Toilet

We will add functionality for users to add their own review, add google map support, etc.
",https://github.com/ethanwithnoe/ratemytoilet,,"Most Creative Hack, Best User Research, Best Entrepreneurship Hack, Best Statistical Model","react, jss, css, alibaba",Ethan,Liu,etliu@ucdavis.edu,,Most Creative Hack,Best User Research,Best Entrepreneurship Hack,University of California - Davis,2,Nathan,Leung,neleung@ucdavis.edu
AbleGrade,34,https://hackdavis-2024.devpost.com/submissions/511444-ablegrade,Submitted (Gallery/Visible),Pending,Submit,04/28/2024 16:04:25,"Inspiration

AbleGrade was inspired by the struggles that ESL learners often face in mastering English. We wanted to create a tool that not only evaluates their writing skills but also actively helps them improve through targeted feedback and clear tracking of their progress.

What it does

AbleGrade utilizes AI, specifically OpenAI's GPT-4, to evaluate the writing of ESL learners. It provides them with detailed, actionable feedback and graphs their writing progression over time, helping them see improvements and areas needing further work.

How we built it

We developed AbleGrade using the MERN stack (MongoDB, Express.js, React, and Node.js), integrating OpenAI's GPT-4 for advanced text analysis. Additionally, we implemented PDF parsing capabilities to allow users to upload and analyze text documents directly.

Challenges we ran into

One of the major challenges was integrating the PDF parsing functionality seamlessly with the rest of the application. Ensuring that our AI feedback was both accurate and helpful required significant tuning and testing of the model.

Accomplishments that we're proud of

We are particularly proud of our application's ability to provide clear and constructive feedback to ESL learners. The positive impact on users' writing skills and confidence has been highly rewarding. Additionally, mastering the integration of complex technologies like GPT-4 and PDF parsing into our MERN stack application was a significant achievement.

What we learned

Throughout the development process, we learned a great deal about building robust full-stack applications and the potential of AI in educational technology. We also gained insights into the unique challenges faced by ESL learners and how technology can be tailored to meet their specific needs.

What's next for AbleGrade

Looking forward, we plan to expand AbleGrade's capabilities by incorporating more languages and offering more personalized learning experiences. We also aim to improve our AI algorithms for even more precise feedback and develop a mobile version of the application to increase accessibility for users on the go.
",https://github.com/ashwinchembu/ablegrade,https://youtu.be/fJbyBP68_eY,"Best Interdisciplinary Hack, 	Best Hack for Social Justice, Most Creative Hack, Best AI/ML Hack, Best UI/UX Prototyping, Best Entrepreneurship Hack","openai, auth0, mongodb, express.js, react, node.js",Gautham,Pandian,gauthampdn@gmail.com,,Best Entrepreneurship Hack,Best AI/ML Hack,Best Interdisciplinary Hack,"University of California - Davis, University of California - Santa Cruz",1,Ashwin,Chembu,ashchembu@gmail.com
Inventaire,71,https://hackdavis-2024.devpost.com/submissions/511445-inventaire,Submitted (Gallery/Visible),Pending,Submit,04/28/2024 16:04:53,"Inspiration

The inspiration behind Inventaire stemmed from a collective frustration with outdated inventory management systems. We envisioned a solution that leverages cutting-edge technology to streamline operations and drive business growth.

What it does

Inventaire automates inventory management processes through advanced features such as Object and Space Detection, Database Integration, and AI-driven KPI tracking. It provides businesses with a centralized platform to efficiently monitor stock levels, optimize replenishment strategies, and make informed decisions.

How we built it

We built Inventaire using a combination of machine learning algorithms for object detection, database management systems for storage and retrieval of inventory data, and custom-developed AI models for KPI tracking. The app was developed using modern software development practices and frameworks to ensure scalability, reliability, and performance.

Challenges we ran into

One of the main challenges we encountered was fine-tuning the object detection algorithms to accurately identify and classify items in various environments. Additionally, integrating different databases and ensuring seamless data synchronization posed technical hurdles that required innovative solutions.

Accomplishments that we're proud of

We're proud to have developed a comprehensive inventory management solution that addresses the diverse needs of businesses across industries. Our team's dedication and collaboration enabled us to overcome complex challenges and deliver a product that empowers businesses to optimize their operations effectively.

What we learned

Throughout the development process, we gained valuable insights into the intricacies of inventory management and the potential of AI-driven solutions to drive efficiency and innovation. We also learned the importance of user feedback and iterative development in refining product features and enhancing user experience

What's next for Inventaire

Moving forward, we plan to continue enhancing Inventaire with new features and functionalities based on user feedback and market trends. We aim to expand its capabilities to support more advanced analytics, predictive modeling, and integrations with other business systems, ultimately positioning it as the go-to solution for modern inventory management needs.
","https://inventaire.tech/, https://github.com/ManojBaasha/inventaire",,"Best Use of .Tech Domain Name, Best Hack for AggieHouse","python, react",Manoj,Elango,melango@ucdavis.edu,,Best Use of .Tech Domain Name,Best Hack for AggieHouse,Best Entrepreneurship Hack,University of California - Davis,3,cho-yujin,,yujincho2002@gmail.com
Gymxiety,43,https://hackdavis-2024.devpost.com/submissions/511446-gymxiety,Submitted (Gallery/Visible),Pending,Submit,04/28/2024 16:06:39,"Inspiration

Brainstorming for this project, one of our group members brought up her fear of going to UC Davis‚Äô gym, the ARC. The ARC‚Äôs busy environment and intimidating persona often leads to hesitation and scares many students out of going entirely. Combined with the numerous intricate machines, and minimal instructions or a how-to guide on how to get started, the idea of looking like you don‚Äôt know what you‚Äôre doing is a crippling fear. 

What it does

In order to address this, our interface is specifically designed to help users get started in the gym by giving them tailored exercises/workouts on the things they want to work on, such as cardio, core, upper and lower body, or even full body! Along with this, the exercise options give catered instructions on how to operate the machines, as well as their locations, so users can be confident in every step of the way! 

How we built it

To begin, we created a LOFI design of our interface website for a basic outline and thus began researching information on workouts that target different areas of the body and the corresponding gym machinery. From there, we found a dataset that addresses how exercise relates to physical health and conducted an ANOVA hypothesis test to see if BMI varies for people throughout different age groups.

Challenges we ran into

One thing that challenged us was learning front-end development to operate in an efficient way as well as expanding our repertoire of tools to accommodate for all the ideas we wanted to get down and working.

Accomplishments that we're proud of

For many of us, this was the first user-web interface we created from scratch. In order to do this, we adapted to learning a lot of new skills such as HTML, CSS, front-end web development, and more which was fulfilling to learn in action and apply in real time. Moreover, we‚Äôre all extremely proud to have completed our first hackathon!

What we learned

Learned how to use new technologies that we hadn‚Äôt known before and how to collaborate on one central idea that we could implement within 24 hours.

What's next for Gymxiety

Looking to the future, we hope to develop a more nuanced user-interface and develop a better user experience by developing a backend and possibly user authentication. 
",https://github.com/dpujaa/hd2024.git,https://youtu.be/bz998aUFNOE,"Best Beginner Hack, Best Health Hack, Most Creative Hack, Best Statistical Model","r, html, css, rstudio, replit, kaggle, github",Janna,Fasheh,jfasheh@ucdavis.edu,,Best Beginner Hack,Best Statistical Model,Best Health Hack,University of California - Davis,3,Nidhi,Deshmukh,npdeshmukh@ucdavis.edu
Davis Community Housing Meals and Housing,67,https://hackdavis-2024.devpost.com/submissions/511448-davis-community-housing-meals-and-housing,Submitted (Gallery/Visible),Pending,Submit,04/28/2024 16:07:02,"Inspiration

Davis Community Meals and Housing needs a user-friendly app to manage their inventory, allowing for clear organization by category and features to incentivize donations, creating a streamlined system that benefits both staff and donors.

What it does

The application consists of two roles Donor and DCMH staff (Admin).

Donor: Logs into the application and can see the critical to minimal inventory items priority-wise for donations these factor is based on the available products metric.

Donors, can take an informed decision based on the data represented once a donation is made the donation request will be in the pending queue until admin receives the donation.

Admin: Admin,  increases or decreases the inventory items based on their requirement. Further, the admin can see the active requests for donations which helps the admin to decide to accept or reject donation requests. Furthermore, admin can see the entire history of donors made on inventory items.

The application provides guidance on helping the admin to check the recent news and relevant articles.

How we built it

-- We want to develop a easy and effective solution which bridges a seamless relationship between donor and DCMH staff. 
-- For inventory management, we have scanned all the items provided in the booklet and configured these records into our database.
--  We have developed mobile application using REACT Native for Front-End and used Supabase for efficient back-end integration.
-- Main emphasis is put on ease of using the software, which helps the donor and DCMH staff to keep track of donations and inventory items by categories.

Challenges we ran into

-- Creating a cross-platform application with responsive UI/UX design.
-- Coming up with the design decisions to connect Admin and Donor parties.
-- Handling Inventory items count once the donation has occurred. 
-- Integrating push notifications to notify users and admins when certain actions triggered.

Accomplishments that we're proud of

-- We have developed a minimal viable product that helps users and donors to accept donations with few clicks. 
-- Successfully, integrated notification system which helps admins and donors to keep in the loop.
-- The audit system helps the users and admins to keep track of donations history and admins can contact donors.
-- The mobile application makes DCMH staff lives easier to keep track of inventory items and donors.

What we learned

-- Teamwork: We have divided our tasks and actively worked on them to complete the application with the critical features with in 24hrs.
-- Tech Stack: We have learned and implemented a new tech stack completely from scratch this is a challenging task for us however our mutual collaboration helped a lot to integrate the work seamlessly.

What's next for Davis Community Housing Meals and Housing

-- We want to make Donors and DCMH staff life easier by keeping track of donation delivery status using tracking metrics.
-- A stats dashboard helps to visualize the donations performed, and inventory utilized in span of days, months and year.

** We see substantial potential in this application which helps to make DCMH staff and its customers life easier and we are proud of what we have built and can offer in long term**
",https://github.com/MaheshtheDev/dcmh,https://youtu.be/KToA_Ale2_c,"Best Beginner Hack, 	Best Hack for Social Justice, Best Overall Design, Best Hack for DCMH","react-native, javascript, postgresql",akhil070,Deshneni,akhilrao199867@gmail.com,,Best Hack for DCMH,Best Hack for Social Justice,Best Beginner Hack,California State University - Long Beach,0,,,
BuzzIn,109,https://hackdavis-2024.devpost.com/submissions/511449-buzzin,Submitted (Gallery/Visible),Pending,Submit,04/28/2024 16:07:07,"Inspiration

We were inspired by our experiences struggling to get help from tutors in our respective majors, both because the tutors often did not know how to answer our specific questions and because of the inconvenience involved. We initially conceived of BuzzIn as a solution to all of those problems, a platform where students could meet a diverse range of people who have extensive experience in the subjects they wanted to learn about, and where they didn‚Äôt have to wait long to get their questions answered. However, we quickly realized that the project had a much broader scope than that‚Äîit could be a valuable tool for anyone looking for detailed advice or even just trying to meet new people in a low-stakes environment. The best part about BuzzIn is its increasing returns‚Äîthe more users it has, the more people who could benefit from using it. 

What it does

BuzzIn is a progressive web app designed for people to make spontaneous connections and get help from people who are guaranteed to know what they are talking about. When people first sign up for the app, regardless of their intent to mentor or be mentored by others, we ask them about the fields (if any) that they are experts in, from app development to personal finance to Russian. Then every time they log on to the app, they can choose whether they want to answer a question or ask one. People who ask a question are asked to identify the closest related topics to their question, and experts in those topics are then offered a selection of questions from random people and given the opportunity to choose whichever one they‚Äôd prefer to answer. Once a mentor chooses a question, they are matched with the mentee on a voice call that can last for as little or as much time as both parties want. After the call, if the mentor was not able to sufficiently answer the mentee‚Äôs question, the mentee can rate their mentor and ask the same question again.

How we built it

We used the Django ecosystem for the backend components, using Django and Django Rest Framework for creating the api and using the Django ORM for database access and management. We also used Django Channels to implement websockets for real time communication. We also used React for our frontend to build an aesthetically pleasing UI presented to users as a Progress Web App. We also leveraged the power of PropelAuth to implement our User Authentication and ensure that our service is secure. Additionally, we used a nicely designed API Architecture to be able to ship many small yet connected features to the user with a sleek frontend interface. 

Challenges we ran into

Some of the challenges that we ran into was in the usage of PropelAuth. It seemed that at many times the documentation was slightly outdated and required some investigative work to be able to be used properly. Another challenge we encountered was incorporating real time communication between our frontend and backend using websockets. It required quite a bit of setup and going through documentation to get up and running. We also faced many challenges in initializing our environments. We first tried using React Native with expo, but faced problems with UI components not working and the expo tunnel taking a ridiculous amount of time to load that made our workflow extremely inefficient. Then we pivoted and decided to use Flutter, but had many issues with flutter compatibility with xcode, and we faced many unique challenges with that. After those failed attempts, we decided to implement a Progressive Web Application using React to be able to make our ideas come to life.

Accomplishments that we're proud of

We‚Äôre proud of our use of PropelAuth. We are also proud that we were able to pivot from our initial idea of creating a mobile app to a progressive web app after we ran into difficulties with installing or porting different platforms, and that our designs were so sleek and feature-rich.

What we learned

We‚Äôve learned the importance of adequate preparation, particularly when going into unfamiliar tools like Flutter. Having the appropriate tools and background knowledge at hand can significantly streamline our workflow and prevent wasted time, as evidenced by the hours spent setting up our environment. Moving forward, ensuring that we‚Äôre properly equipped and informed will for sure lead to more efficient and productive outcomes.

What's next for BuzzIn

Should we have had more time we would develop for a more user friendly design. Due to complications that we had during the beginning of HackDavis that ended up eating up our time, we had to cut back on many of the features that we originally planned on implementing. This also restricted the application‚Äôs design to hold users fully at the center when actually developed. If we had more time, we also would have tried to match people with mentors by using an LLM, which would increase the potential of our app to ensure that people meet with mentors who are competent in the subject material.
","https://github.com/mythrikulkarni/HackDavisApp, https://www.figma.com/proto/FyYgFbPiJkUYwR50nnKwIQ/HackDavis?type=design&node-id=69-3934&t=7UkIeMPhZ1ClhNX0-1&scaling=scale-down&page-id=6%3A153&starting-point-node-id=69%3A3934&mode=design",,"Best Interdisciplinary Hack, Most Technically Challenging Hack, Best UI/UX Prototyping, Best Use of PropelAuth","django, django-rest, django-orm, propelauth, react",Mythri,Kulkarni,mvkulkarni@ucdavis.edu,,Best UI/UX Prototyping,Best Use of PropelAuth,Best Interdisciplinary Hack,University of California - Davis,3,Diego,Rafael,drafael@ucdavis.edu
PatientSimAI,49,https://hackdavis-2024.devpost.com/submissions/511450-patientsimai,Submitted (Gallery/Visible),Pending,Submit,04/28/2024 16:07:42,"üí° Inspiration

Medical students aren't getting the training they want and need to feel confident in interacting with patients. We've spoken to a PhD student at the Stanford School of Medicine who teaches many students currently struggling with this issue, not just here in the USA, but also in various countries around the world (like Chile, Ireland, Singapore, and Brazil) where students lack the same access to patients and practice.

‚úèÔ∏è What it does

PatientSimAI is a web app that simulates patient interactions using AI and GPT4, to train clinical reasoning, improve medical education, and build skills for practical application. We built a platform where professors can input parameters around which AI can craft a conversation, utilize the scenarios we have crafted, and provide a lesson for students.

üõ†Ô∏è How we built it


Technology Integration: We combined AI with GPT-4 to simulate authentic patient interactions, enhancing the educational modules in our web app.
Development Journey: We began with a basic prototype to test the AI‚Äôs conversational capabilities and iteratively refined both the user experience and functionality based on feedback.
Collaboration: We engaged with medical professionals extensively to ensure the scenarios we created were accurate and educational.


üöß Challenges we ran into


Text-to-Speech Integration: We faced significant challenges integrating effective text-to-speech capabilities, which were essential for realistic patient interactions.
Deployment Setbacks: Deploying the application on a scalable server was tough and caused delays in our testing and feedback phases.
Managing Time: Balancing the complexity of the project within our deadlines was a substantial challenge.
Creating/Deleting Data: Fetching and adding new courses caused a significant amount of failed API requests in the server.


üèÜ Accomplishments that we're proud of


Successful Launch: Despite the hurdles, we successfully launched the app, providing a functional and educational platform for medical students.
Integration Achievement: We effectively connected the front end with the back end, allowing for seamless user interactions and efficient data management.## üìö What we learned


üîÆ What's next for PatientSimAI

We have a few roadmap items for PatientSimAI, to monetize it enough to continue providing this service and making it accessible for as many medical students as possible.


Feature Expansion: We plan to introduce more advanced diagnostic tools and more varied patient scenarios.
Pilot Rollout: We are excited about a potential phased pilot rollout at the Stanford School of Medicine, aiming to collect extensive user feedback and further refine the platform. We aim to partner with professors to add the software as an in-class resource, for students to purchase (B2B targeting).
Enhancing Accessibility: We are focusing on user research to ensure the web application is accessible on various devices, incorporating best healthcare practices and inclusive design to maximize accessibility. We want to verify instructors from areas with fewer resources or have an appeal process, to provide free licenses and improve resource accessibility.
Gamification Elements: We plan to implement gamified features to make the learning process more engaging and informative.


üë®‚Äç‚öïÔ∏è Best Health Prize

We focused on the ""service accessibility"" aspect of the Health track, and created a tool that can be used anywhere with an internet connection. This is particularly important for countries with fewer resources, where students cannot often practice with human patients in controlled yet flexible spaces that are as inducive to learning.

üó£Ô∏è Best Interactive Media

We utilized speech-to-text to make the interactions feel more challenging (where students have to think on their feet and verbalize their thoughts succinctly) in an almost realistic-yet-gamified environment.

‚ù§Ô∏è Final Notes

Endorsement from Marcos, Medical Surgeon:
""PatientSimAI will revolutionize medical education by enabling realistic, interactive scenarios that significantly enhance clinical reasoning skills. This AI-driven platform's ability to customize cases to local specifics, from epidemiology to desired learning outcomes, prepares future healthcare professionals to effectively manage the complexities of patient care.""

Technology and medical research is improving constantly.
It's time medical education improves with it.

Thank you to all the organizers for the opportunity to participate in HackDavis 2024!
","https://docs.google.com/presentation/d/1pS0IU-ZS7w98MlQObGDsw3zPIZ6LUJ84oBMvE2S3pPM/edit?usp=sharing, https://github.com/cyu60/patient-sim-ai.git",,"Best Interdisciplinary Hack, Best Health Hack, Best User Research, Best Interactive Media Hack","gpt4, next.js, tailwind, css, neon, clerk, deepgram, drizzle",Chloe,Wang,chloewang.rs55@gmail.com,,Best Health Hack,Best Interactive Media Hack,Best Interdisciplinary Hack,"University of California - Davis, Johns Hopkins University, University of California - Berkeley",3,Chinat,Yu,chinatchinat123@gmail.com
Midas Green,159,https://hackdavis-2024.devpost.com/submissions/511453-midas-green,Submitted (Gallery/Visible),Pending,Submit,04/28/2024 16:12:11,"Midas Green, Democratizing Agriculture, Nurturing Growth

Inspiration

We got inspiration for this project from our experience volunteering with the Santa Cruz Fruit Growers. Growing densely planted fruit crops proliferated disease, and we spent days diagnosing powdery mildew, mite damage, and anthracnose on the plants we grew. 

What it does

Midas Green helps democratize access to agricultural technology by identifying plant diseases

How we built it

Midas Green utilizes a Convolutional Neural Network (CNN) and fine-tuned Gemma model optimized with Intel INT8 quantization and RAG to ensure accurate responses. With our CNN, we currently can  classify 32 plant diseases from images captured in any garden. The backend, hosted on Intel Cloud VM, efficiently processes the data, while the development environment on Intel Cloud ensures seamless integration and scalability. The model outputs disease classifications, which are then analyzed through a Recommendation Action Generator (RAG) to suggest effective treatment options for farmers.

Challenges we ran into

Creating our own CNN and fine tuning the Gemma model was difficult

Accomplishments that we're proud of

We're really proud of how well Midas Green uses modern AI technology, and how much we've learned about LLM's and deep learning along the way

What we learned

Each developer embarked on a journey of learning and growth, as we all worked with technology that we hadn't previously React, Node.js, and Large Language Models. Our exploration led us to discover the remarkable capabilities of React and Node.js in building robust, scalable web applications. With React's component-based architecture and Node.js's event-driven, non-blocking I/O model, we found ourselves empowered to create dynamic and efficient user experiences.

What's next for Midas Green

Moving forward, we envision expanding the capabilities of Midas Green to cover a broader range of crops and diseases. Furthermore, we aim to partner with agricultural companies by verifying quality products to recommend to gardeners.
",https://github.com/inkyant/GrowTogether,,"Best Interdisciplinary Hack, Best AI/ML Hack, Best use of Intel¬Æ Developer Cloud, Most Technically Challenging Hack","intel-cloud, python, pytorch, react, flask, node.js, torchvision",Ethan,Bernstein,eebernstein@ucdavis.edu,,Best use of Intel¬Æ Developer Cloud,Best Interdisciplinary Hack,Best AI/ML Hack,"University of California - Davis, University of California - Berkeley, ucsc",2,Aarav,Singh,asingh28@berkeley.edu
Fake News Detector,17,https://hackdavis-2024.devpost.com/submissions/511454-fake-news-detector,Submitted (Gallery/Visible),Pending,Submit,04/28/2024 16:12:25,"Inspiration

As technology develops, it gets easier and easier to create convincing CGI or articles filled with misinformation. With the continuing growth of social media platforms and the rapid spread of information, distinguishing between true and false has gotten harder. Our inspiration stems from this need to combat the spread of fake news in the interest of public safety.

What it does

Our Fake News Detector is a sophisticated tool powered by machine learning algorithms such as Decision Tree Classifier, RandomForestClassifier, and GradientBoostingClassifier from scikit-learn. Our project analyzes the text from an article, then runs it through an extensive algorithm to discern between genuine news articles and those containing fabricated information. By utilizing advanced natural language processing techniques, our system evaluates the linguistic patterns and semantic features of news articles, enabling it to make accurate predictions regarding their authenticity.

How we built it

We meticulously crafted our Fake News Detector by employing a multi-step approach. First, we aggregated a diverse dataset comprising both authentic and fabricated news articles. Next, we performed extensive data preprocessing, including text normalization, removal of irrelevant characters, and feature extraction using TF-IDF vectorization. We then trained multiple classification models, fine-tuning their hyperparameters to optimize performance. Through repeated experimentation and trials, we refined our system to achieve high levels of accuracy and reliability.

Challenges we ran into

Developing an effective fake news detection system presented several challenges along the way. One significant obstacle was the imbalance in the dataset, with a disproportionate number of fake news articles compared to real ones. Addressing this imbalance took careful sampling techniques and modifications to the evaluation metrics to ensure proper model assessment. Additionally, optimizing the classifiers' parameters and managing computational resources posed logistical challenges, necessitating efficient algorithms and infrastructure.

Accomplishments that we're proud of

We take pride in our Fake News Detector's robustness and effectiveness in distinguishing between genuine and fabricated news articles. By leveraging learning techniques and feature-rich representations of textual data, our system achieves great performance in identifying misinformation with high accuracy and minimal false positives. Furthermore, we're proud of our collaborative efforts in designing a scalable and adaptable solution that can be deployed across various platforms to combat the spread of fake news.

What we learned

Our journey in developing the Fake News Detector provided invaluable insights into the complexities of natural language processing and machine learning. We gained a deeper understanding of text preprocessing techniques, feature engineering strategies, and the nuances of different classification algorithms. Moreover, we learned the importance of interdisciplinary collaboration and the ethical implications of deploying AI systems for societal impact, underscoring the need for responsible innovation in AI.

What's next for Fake News Detector

Looking ahead, we envision further enhancement of our Fake News Detecton, such as through the exploration of advanced deep learning architectures to capture more realistic-sounding text. Additionally, integrating real-time monitoring and verification capabilities could empower individuals to critically evaluate information and combat misinformation in their communities. Ultimately, our goal is to continue innovating and collaborating with stakeholders to foster a more informed and resilient society in the digital age.
",https://github.com/adiseshvsanklapur/FakeNewsDetector/tree/main,,"Most Creative Hack, Best AI/ML Hack, Best Statistical Model","python, scikit-learn, nltk, pandas",Adisesh,Venkatesh Sanklapur,adivenkatesh@ucdavis.edu,,Best AI/ML Hack,Best Statistical Model,Most Creative Hack,University of California - Davis,0,,,
chckn+wafl,83,https://hackdavis-2024.devpost.com/submissions/511455-chckn-wafl,Submitted (Gallery/Visible),Pending,Submit,04/28/2024 16:14:20,"Reimagining Innovation and Flavor once again at HackDavis 2024! üçî‚ú®

Inspiration

Building on last year's ""burgr+icerem,"" our new submission, ""chckn+wafl,"" is inspired by the enthusiastic feedback we received. We've refined our approach, integrating advanced technology to better capture the essence of these iconic dishes in a single, appealing image. After partaking in an intensive iterative design and development process, we are happy to announce that we've achieved our goal of combining the essence encapsulated from our last year's HackDavis project to a single image that encapsulates the essence of both sweet and savory. 

What it does

""chckn+wafl"" is more than just a static image‚Äîit's a visual feast that marries the rustic charm of chicken and waffles with a sleek, modern design. This project aims to encapsulate the comfort of home-cooked meals while showcasing the potential of digital art to elevate everyday experiences. Like its predecessor, it blends sweet and savory elements, offering a new and innovative take on combining contrasting flavors.

How we built it

Using upgraded graphic design software and enhanced artistic techniques, we crafted an image that emphasizes the textures and allure of chicken and waffles. We focused on improving the visual impact through more realistic detailing, ensuring that each element of the meal is vivid and inviting.

Challenges we ran into

Our main challenge was surpassing the success of last year's submission. We needed to ensure that ""chckn+wafl"" not only matched the appeal of ""burgr+icerem"" but also offered a fresh perspective, while ensuring the same blend of creativity. Achieving the right balance between authenticity and artistic expression was crucial.

Accomplishments that we're proud of

We are proud of how ""chckn+wafl"" has turned out‚Äîa visual representation that truly resonates with the audience. It's a testament to our team's ability to evolve and adapt, utilizing technology and art to create something that is both beautiful and meaningful.

What we learned

This project deepened our understanding of the intricate relationship between technology and art. We learned that careful adjustments and attention to feedback are key in crafting images that not only draw the eye but also tell a story.

What's next for chckn+wafl

Moving forward, we plan to explore interactive elements for our next projects, potentially creating a digital experience where users can engage with the food images in innovative ways, such as customizing their meal presentations or exploring the ingredients in virtual reality.

This year's submission, ""chckn+wafl,"" reflects our commitment to combining culinary arts with digital innovation, providing a platform for creativity and connection through food. It continues the theme of blending sweet and savory in a novel way, pushing the boundaries of what can be achieved in digital gastronomy.
",,,,"hackdavis, stripe, chatgpt, minecraft, iphone11, khanacademy",Alex,Le,le.alex101@gmail.com,,NA,Best Beginner Hack,Best Statistical Model,University of California - Davis,1,Ethan,Thai,eethai@ucdavis.edu
Glucosmart,158,https://hackdavis-2024.devpost.com/submissions/511456-glucosmart,Submitted (Gallery/Visible),Pending,Submit,04/28/2024 16:15:42,"Inspiration

Family

What it does

How we built it

Challenges we ran into

Accomplishments that we're proud of

What we learned

What's next for Glucosmart
",,https://youtu.be/VG59xZsuDDU?si=9g3TGtfNSoQ_80B1,"Best Interdisciplinary Hack, Best Health Hack, Most Technically Challenging Hack, Best Hardware Hack","react-native, python, javascript",Harsh,Karia,hnkaria@ucdavis.edu,,Best Hardware Hack,Best Health Hack,Best Interdisciplinary Hack,University of California - Davis,2,Aarav,Urgaonkar,aurgaonkar@ucdavis.edu
Where's my Waldo?,125,https://hackdavis-2024.devpost.com/submissions/511457-where-s-my-waldo,Submitted (Gallery/Visible),Pending,Submit,04/28/2024 16:16:57,"Inspiration

According to ""Bring Jackson Home"", 10 million dogs are lost per year. 70% of dogs that go missing are actually within a one-mile radius of their homes. As a dog owner myself, I can understand the pain that other dog owners go through when they lose their loving family member.  I wanted to create an app that brings neighbors together in helping their dogs find their homes again. 

What it does

Where's Your Waldo is an interactive and community uniting technology which help lost pet owners find their pet. Simply upload a photo and the last known location of your pet. Meanwhile, our community of 'Spotters' can post real-time sightings with photos and locations whenever they spot a lost pet.

Our smart system immediately gets to work, comparing these sightings against your pet‚Äôs details. As matches pop up, you swipe through them, right if it‚Äôs a maybe, left if it‚Äôs not a match. Your responses fine-tune the search process, thanks to our advanced machine learning, making each suggestion more accurate than the last.

How we built it

Using Node.Js, React, Javascript, and Figma, I went through the prototyping, and then created a interactive React web-based framework. I deployed a Google Maps API into sending the current locations of the owners and neighbors that spot their dogs. 

Challenges we ran into

A big challenge was getting the Google Maps API to deploy properly into our React framework, but in the end, it all paid off. 

What's next for Where's my Waldo?

Towards the future, I hope to deploy a machine learning recognition model onto the matching between the spotters' pictures and the owners' dogs. I also hope to convert from a web to an app-based framework as I had planned to do in the beginning. 
",https://github.com/kavirajesh22/findwaldo,https://youtu.be/ZE5RsFFPju8,"Best Beginner Hack, 	Best Hack for Social Justice, Most Creative Hack, Best AI/ML Hack, Best UI/UX Prototyping, Best User Research, Best Interactive Media Hack, Best Hack for Life of Kai","node.js, react, google-maps, api, javascript, css, figma",Kavi,Rajesh,krajesh@ucdavis.edu,,Best Hack for Life of Kai,Best Beginner Hack,Best Hack for Social Justice,,0,,,
Xplore,11,https://hackdavis-2024.devpost.com/submissions/511458-xplore,Submitted (Gallery/Visible),Pending,Submit,04/28/2024 16:17:51,"Inspiration

We were inspired to work on this project because a lot of people nowadays are more anti-social, or have difficulty finding reasons to leave home. We wanted to create an app that gives people a fun reason to be able to go out and explore the world with their friends or family, thus helping them regain their social skills as well as improving their health via the exercise that comes with it. 

What it does

This app will tack the location of the user and keep a collection of points for them based on various landmarks or unique locations they may have visited. They can accumulate points by checking in when they reach a new landmark, providing photo verification using the phone camera to take a picture, and in return an AI generates an interesting fun fact, as well as some other useful information about where they have arrived to. After collecting a certain amounts of points users will be able to level up and compete in leaderboards.

How we built it

We build this app using react-native and firebase. We created the front end pages of the app using react-native to represent each of the pages the user would be able to access, and connecting it to a firebase database system to be able to store location information as well as the photos uploaded.

Challenges we ran into

2 of the 3 members of our team are brand new to working with react-native and as such ran into issues early on learning how to set up the main pages. Over time those issues became less present but there were others such as errors when attempting to access the phone camera to take and store the picture, an issue that took a decent chunk of time to fix. 

Accomplishments that we're proud of

We are proud of being able to create a functional app in react-native, particularly since most of us have little  to no experience using it and have had prior exposure that did not go as well. We are also proud of getting the camera to operate correctly. 

What we learned

We learned a lot about how react-native operates and the rules that need to be followed for it. For example in order to use fonts it is a much more complicated process involving lots of importing compared to using fonts with other programming languages.

What's next for Xplore

We hope to continue working on fine tuning the app and perfecting the system in order to properly generate the experience levels and other game-like features of the app into a more full fledged experience. 
",https://github.com/BustosAndrew/xplorer,,"Best Health Hack, Best AI/ML Hack, Most Technically Challenging Hack, Best Overall Design","react-native, firebase, gemini",Andrew,Solbjor,s0lbjorandr3w@gmail.com,,Best AI/ML Hack,Most Technically Challenging Hack,Best Health Hack,"San Joaquin Delta College, California State University - East Bay",2,Cody,Kneale,codykneale@yahoo.com
Untitled,,,Draft,Pending,Manage team,04/28/2024 16:19:24,,,,,,Neerja,Natu,neerjanatu@gmail.com,,,,Best Statistical Model,University of California - Davis,0,,,
Untitled,,,Draft,Pending,Manage team,04/28/2024 16:20:07,,,,,,Karan,Binning,ksbinning21@gmail.com,,,,Best Beginner Hack,University of California - Davis,0,,,
Zenly,72,https://hackdavis-2024.devpost.com/submissions/511462-zenly,Submitted (Gallery/Visible),Pending,Submit,04/28/2024 16:20:57,"Inspiration

There has been a rise in mental health awareness in the past couple of years and the market has responded with a boom in mental health application that focuses on one or two niches. Our app will be a one stop mental health app that consolidates all the different niches such as meditation, mood trackers, and journal logs. 

What it does

Zenly app will ask the user how their day has been going and will allow you to log your mood. Either happy, neutral, sad, or angry and the user will be able to see an weekly and monthly overview letting them know how their mental health has been. The app also guides you through techniques to de-stress such as meditation guides and meditation tracker. User is also able to enter journal logs. 

How we built it

Our project is focused on the UI/UX and utilized Figma to create the different features and pages.

Challenges we ran into

We are a group of beginners on our first hackathon. Learning and navigating through new design tools as well new frameworks. Our project mainly focuses on the design but we also tried to incorporate backend and produce an app, hence, learning another framework and language of React Native and JavaScript. 

Accomplishments that we're proud of

We were able to translate our ideas into a viable app that will manage, and track the user's mental health in their day-to-day lives. We were also able to create the basic homepage of a mobile app. 

What we learned

Learned how to navigate through Figma and really dive into the complex features. We also learned a new framework React Native even through this was not our focus.

What's next for Zenly

We will be looking to implement the design into an actual working mobile app.
","https://www.figma.com/file/XhxUjKpzQnhpJ00Rjjmv3T/Smart-Watch-App%2FProduct?type=design&node-id=132%3A1133&mode=design&t=pyGtSFM5B50QlnOv-1, https://github.com/Annnamarie/Zenly_MentalHealth",https://vimeo.com/940502552?share=copy,,"figma, reactnative",Annamarie,Cortes,cortes.annamarie@gmail.com,,Best Beginner Hack,Best Health Hack,Best UI/UX Design,University of California - Davis,2,Annie,Huynh,anihuynh@ucdavis.edu
EduParse,24,https://hackdavis-2024.devpost.com/submissions/511464-eduparse,Submitted (Gallery/Visible),Pending,Submit,04/28/2024 16:21:14,"Inspiration

Inspired by the need for more interactive and personalized study tools, EduParse was conceived to transform traditional studying into a dynamic and customized experience.

What it does

EduParse is a Chrome extension that instantly converts PDF lecture notes and study materials into tailored practice tests. Users can choose the quantity and type of questions, making studying more efficient and tailored to their needs.

How we built it

We built EduParse using Python for backend operations, including PDF parsing and interfacing with HuggingFace models for question generation. The front-end was developed as a Chrome extension, utilizing HTML, CSS, and JavaScript to provide a user-friendly interface.

Challenges we ran into

We faced challenges in handling diverse PDF formats and optimizing AI response times to ensure a seamless user experience. Integrating complex functionalities into a simple, intuitive interface also tested our design and development skills.

Accomplishments that we're proud of

We're proud of creating a tool that not only meets the needs of learners but does so in a way that is both intuitive and impactful. Overcoming the technical challenges to deliver a useful educational tool has been incredibly rewarding, especially under the span of 24 hours.

What we learned

Throughout this project, we gained deeper insights into PDF data extraction, AI-driven content generation, and the intricacies of Chrome extension development. We also learned a great deal about user experience design and the importance of responsive performance.

What's next for EduParse

Looking ahead, we aim to expand EduParse's capabilities to include more diverse question types and support for additional document formats. We're also exploring the integration of analytical tools to provide learners with insights into their study habits and progress.
",https://github.com/mfaizannn/EduParse,,"Best Beginner Hack, Most Creative Hack","html, css, javascript, python, ai",Mariam,Faizan,mfaizan@ucdavis.edu,,Best Beginner Hack,Most Creative Hack,Best Hardware Hack,UC Davis,1,Vedant,Patel,vsxpatel@ucdavis.edu
Pet Finder AI ,122,https://hackdavis-2024.devpost.com/submissions/511465-pet-finder-ai,Submitted (Gallery/Visible),Pending,Submit,04/28/2024 16:21:58,"Inspiration

All of us understand the grief of losing a pet and know how hard it can be to find your lost pet with just word of mouth. 

What it does

Our app uses AI to predict for lost pets are.

How we built it

We built the app using React.js, FastAPI, and python.

Challenges we ran into

Setting up the database and conceptualizing what information users need to enter to train our machine learning model well.

Accomplishments that we're proud of

We made github accounts and pushed code. Also we learned about React and python.

What we learned

We learned the power of teamwork. Teamwork is dreamwork and we all brought in different strengths.

What's next for Pet Finder AI

Improve our AI training model so it is more accurate and also the user interface so it looks more clean.
",https://github.com/CalculusSlayer/pet-finder,https://youtu.be/QJ2hAztz5HA,"Best Beginner Hack, Most Creative Hack, Best Hack for Life of Kai","python, react, fastapi",Nayeel,Imtiaz,nayeelimtiaz11@gmail.com,,Most Creative Hack,Best Beginner Hack,Best Hack for Life of Kai,University of California - Davis,1,ktjli,,ktjli@ucdavis.edu
DCMH Inventory Helper,,,Draft,Pending,Manage team,04/28/2024 16:22:40,,,,,,Kim Han,Nguyen,n.kimhan19509@gmail.com,,,,Best Hardware Hack,University of California - Davis,0,,,
SafeDose,162,https://hackdavis-2024.devpost.com/submissions/511468-safedose,Submitted (Gallery/Visible),Pending,Submit,04/28/2024 16:23:44,"Inspiration

Synthetic opioids are common in pharmaceutical medications such as pain killers, however more than 150 people die from synthetic opioid overdose, including fentanyl which is 50 times stronger than heroine. We wanted to make an app that would tackle the opioid crisis and help users watch for the signs of a potential overdose. 

What it does

SafeDose helps people monitor their opioid intake by allowing users to log their medication intake. SafeDose charts their dosage intake over a week time interval and notifies users if they have taken a higher dosage than the recommended amount. Users can also log their symptoms if they experience any symptoms of an opioid overdose, and SafeDose will recommend them to see a doctor based on what they report.

How we built it

SafeDose was built using Swift and the SwiftUI, SwiftCharts, and Vision frameworks.

Challenges we ran into

One of our biggest challenges was integrating Firebase as our backend as we had to figure out how to save information without users having to create accounts. We also had trouble connecting the backend to the frontend. We also ran into issues with GitHub such as keep tracking of branches and GitHub not displaying updated code at times.

Accomplishments that we're proud of

We are proud to have been able to put an iOS app together in a short amount of time. We experimented with Apple libraries such as SwiftCharts and Vision, exposing us to the vast possibilities of mobile app development. We also had a lot of fun making memories from singing the Mickey Mouse clubhouse song to playing extraneous amounts of badminton at 1 am :)

What we learned

We learned how to use Apple frameworks that were relatively new to us such as Swift Charts and Vision. We also learned how to work as a team and, most importantly have fun at a hackathon! One of us had never played badminton before and learned for the very first time at HackDavis! ü•≥

What's next for SafeDose

In the future, we would like to chart dosage intake across hourly and monthly time intervals with SafeDose. We would also like to utilize the CoreML and CreateML frameworks to measure the risk of overdose over the aforementioned time periods.
",https://github.com/macintAsh1984/SafeDose.git,,"Best Health Hack, 	Best Hack for Social Justice, Most Technically Challenging Hack, Best Entrepreneurship Hack","swift, swiftui, swiftcharts, vision, firebase, github, git",Ashley,Valdez,ashh.valdez@gmail.com,,Best Health Hack,Best Hack for Social Justice,Most Technically Challenging Hack,University of California - Davis,3,Shubhada,Martha,smartha@ucdavis.edu
Spotifind,89,https://hackdavis-2024.devpost.com/submissions/511469-spotifind,Submitted (Gallery/Visible),Pending,Submit,04/28/2024 16:24:18,"Inspiration

The idea for Spotifind originated from our shared passion for music and the desire to make the process of discovering new tracks more enjoyable and interactive. Inspired by the highly popular and effective apps that utilize swiping interfaces to generate personalized recommendations for users, we set out to create a platform that seamlessly combines the excitement of exploration with the magic of personalized recommendations. 

What it does

When using Spotifind, users can effortlessly explore a curated selection of tracks tailored to their tastes, simply by swiping left or right. With each swipe, Spotifind learns from user preferences, refining its recommendations to deliver a personalized playlist of new and exciting tunes. Whether searching for the next chart-topper or a hidden gem, Spotifind makes music discovery an efficient and enjoyable experience.

How we built it

We decided to create both an app and a website. The web version of Spotifind was built using a combination of Python, Flask, and the Spotify API on the backend, and HTML, CSS, and JavaScript for the frontend. On the other hand, the iOS app was built using Swift. Our team collaborated closely, leveraging each member's expertise to bring the project to life.

Challenges we ran into

One of the main challenges we encountered was integrating the Spotify API seamlessly into our app while ensuring a smooth user experience. Additionally, optimizing the swiping functionality and handling API rate limits posed significant obstacles.

Accomplishments that we're proud of

We're proud of successfully implementing the swiping feature, fine-tuning the recommendation algorithm, and creating a visually appealing interface that enhances the user experience. Additionally, overcoming technical hurdles as a team reinforced our collaboration skills.

What we learned

Through building Spotifind, we gained valuable experience in working with APIs, handling asynchronous requests, and refining front-end design. We also deepened our understanding of user interaction and engagement in app development.

What's next for Spotifind

In the future, we envision expanding Spotifind's features to include social sharing options, personalized playlists, and collaborative discovery features.
",,,,"swift, spotifyapi, javascript, python, html, css",Neerja,Natu,nmnatu@ucdavis.edu,,Best Use of .Tech Domain Name,Most Creative Hack,Best Hardware Hack,University of California - Davis,0,,,
DCMH Inventory Helper,152,https://hackdavis-2024.devpost.com/submissions/511470-dcmh-inventory-helper,Submitted (Gallery/Visible),Pending,Submit,04/28/2024 16:24:25,"Inspiration

We met one of the sponsors, DCMH, who presented us their needs for the homeless shelters with food and hygienic items. What inspires us was helping people and the community.

What it does

The app is interactive so a user can press a button and type an input to the prompt.

How we built it

We first used Figma to make a prototype where we can see what the layouts would look like. We have sign-up pages, inventory page and confirm page. Using Android Studio, we designed the layouts and implemented code to make other elements in our app to work properly and in accordance with our design specifications. 

Challenges we ran into

Being beginners and steep learning curves.

Accomplishments that we're proud of

Designing a prototype!

What we learned

we learned API and elements of designs.

What's next for DCMH Inventory Helper

We are going to implement the app to make it usable and useful.
","https://www.figma.com/proto/SQVz623VkIaUNTsiBQhsqZ/DCMH-Inventory-Helper?type=design&node-id=53-2378&t=tdBO3s3x3xtwrurz-1&scaling=scale-down&page-id=0%3A1&starting-point-node-id=29%3A247&mode=design, https://www.figma.com/file/SQVz623VkIaUNTsiBQhsqZ/DCMH-Inventory-Helper?type=design&node-id=0%3A1&mode=design&t=xiBzh0pcQIAVx9IK-1, https://github.com/poppychan21/MyApplication.git",https://youtu.be/fGgbFVvrgic,"Best Beginner Hack, Best UI/UX Prototyping, Best Overall Design, Best Hack for DCMH","figma, android-studio, java",Joanne,Tai,jotai@ucdavis.edu,,Best Beginner Hack,Best Hack for DCMH,Best UI/UX Prototyping,University of California - Davis,1,Kim Han,Nguyen,n.kimhan19509@gmail.com
Image Stegosaurus,9,https://hackdavis-2024.devpost.com/submissions/511471-image-stegosaurus,Submitted (Gallery/Visible),Pending,Submit,04/28/2024 16:24:36,"Inspiration

We were both really interested in image steganography and it's wide array of applications. It can be used for simple social media posts or games, but it can also be used by people who have to hide information. For example, journalists or protestors that are subject to surveillance and searches could use image steganography to hide valuable information. While encryption makes communication secure, adversaries still might know that information is being communicated. Steganography can help keep communication completely secret, which can allow you to avoid being tracked by an adversary in the first place.

What it does

The user can upload an image that they want to encode with a secret message or they can upload an image that is already encoded to retrieve the secret message.

How we built it

We used python to write the code for the steganography tools and we built the web app using the django framework, which uses python, html, and sqlite.

Challenges we ran into

Two big features we wanted to implement but were unable to due to time were the ability to embed an image within an image (we were able to write code for this but did not have the time to integrate it within our web app) and having friend groups. The idea of groups is that you can choose which people can access the key that is used to encode your images, so only those people can decode your images. Similarly, you can only decode someone's images only if you are in their group.

Steganography involves places bits of data in between pixels of the image, which can be very difficult for high quality images, so it took us a while to figure out how to implement this.

Also, we wanted to make our web app more user friendly and have better design, but we had to prioritize other tasks.

Accomplishments that we're proud of

We are proud that we were able to get a functional product. Anyone can easily encode/decode an image using our tool. Despite not knowing a lot about steganography and having little experience with building web apps, we were able to make a lot of progress.

What we learned

We learned a lot about steganography and the challenges within the field, and how it could be used. Also we gained a lot of experience with building web apps and how to make a product for users.

What's next for Image Stegosaurus

It would be really cool to complete the big features we talked about and turn the web app into a fully functional, good-looking piece of software that could eventually be deployed.
",https://github.com/rs0919/HackDavis_2024,,"Best Interdisciplinary Hack, 	Best Hack for Social Justice, Most Creative Hack, Best Interactive Media Hack","django, python, html",Rohith,Saravana,rsaravana@ucdavis.edu,,Best Hack for Social Justice,Best Interactive Media Hack,Best Interdisciplinary Hack,University of California - Davis,1,Jonathan,Chang,jchang@ucdavis.edu
Predicting Stock Movements from Historical Data,113,https://hackdavis-2024.devpost.com/submissions/511472-predicting-stock-movements-from-historical-data,Submitted (Gallery/Visible),Pending,Submit,04/28/2024 16:25:23,"Project Inspiration

Inspired by my courses I have taken at UC Davis, ECN 141: Economic & Financial Forecasting and STA 137: Applied Time Series, I wanted to harness ARIMA models for forecasting stock prices. These classes provided the foundational knowledge that fueled my desire to apply statistical techniques to real-world financial data.

Learning and Methodology

Time series analysis is inherently challenging, requiring a deep understanding of temporal data behaviors, such as trends, seasonality, and stationary. To tackle this complexity, I revisited and reinforced my learning from both courses, focusing on the intricacies of ARIMA models. The project involved segmenting the data into training and test sets‚Äîa technique often associated with machine learning‚Äîto evaluate the predictive power of our models reliably.

Challenges

""The main challenge was the steep learning curve associated with time series analysis. Time series data can be unpredictable, and ensuring the model captures all underlying patterns without overfitting or underfitting was particularly challenging due to the inherent volatility of stock prices. Moreover, preparing the data, selecting the right model parameters, and interpreting the results necessitated a thorough re-education on topics covered in my previous coursework.""

Conclusion

This project not only allowed me to apply theoretical knowledge in a practical setting but also deepened my understanding of financial forecasting. By comparing the predicted stock prices against actual historical data, I was able to gauge the accuracy of our models and gain valuable insights into the potential and limitations of economic forecasting using ARIMA models.
",https://www.canva.com/design/DAGDvPcbaz4/mdJD2kbMN5a5xYBzLBbGhg/edit?utm_content=DAGDvPcbaz4&utm_campaign=designshare&utm_medium=link2&utm_source=sharebutton,,"Best Interdisciplinary Hack, Best AI/ML Hack, Best Finance & Tech, Best Statistical Model","rmarkdown, r",Ethan,Dang,ehdang@ucdavis.edu,,Best Statistical Model,Best Finance & Tech,Best Interdisciplinary Hack,,0,,,
Happy Tracker,14,https://hackdavis-2024.devpost.com/submissions/511473-happy-tracker,Submitted (Gallery/Visible),Pending,Submit,04/28/2024 16:25:27,"Inspiration

The inspiration behind Happy Tracker comes from recognizing the unique challenges faced by parents of children with disabilities. Observing that these parents often need immediate guidance and a way to manage and understand their child's behaviors and medical needs, we envisioned an app that not only supports the child but also empowers the parent. In a world where these parents are often unsung heroes, Happy Tracker serves as a vital tool to lighten their load and enhance their caregiving capabilities.

What it does

Happy Tracker is a comprehensive mobile application designed to assist parents of children with disabilities and/or disorders. It offers four key functionalities: a daily log-in to track the child's and parent's emotions, an acute behavior input tool for immediate advice during stressful situations, a calendar for tracking patterns over time, and a detailed medical records tab that can be crucial in emergencies. This app ensures that parents have the necessary tools to manage daily challenges and provides quick access to essential information, making caregiving more manageable.

How we built it

Happy Tracker was developed using a combination of modern technologies tailored to provide a seamless and robust user experience. The frontend of the app was built using React, chosen for its efficiency and flexibility in creating interactive UIs. This allows the app to be responsive and intuitive, which is crucial for parents needing quick access to information and functionality.

For the backend, we utilized Django REST Framework. This powerful toolkit helped us build a clean, well-organized backend, capable of handling requests efficiently and securely. It supports our application‚Äôs needs for data processing, user authentication, and seamless communication between the frontend and the database.

The core of Happy Tracker's functionality is powered by Anthropic‚Äôs AI model, which analyzes user inputs to provide smart, context-aware advice. This AI model helps in predicting behavior patterns and offering personalized guidance, making the app not just a tool but a knowledgeable companion for parents.

Together, these technologies ensure that Happy Tracker is not only functional and reliable but also equipped to handle complex data operations and provide real-time, data-driven advice to its users.

Challenges we ran into

One of the main challenges was implementing the AI component that accurately predicts and interprets behavior patterns to provide actionable advice. Ensuring data privacy and security, especially with sensitive medical information, was another significant challenge. We also worked on optimizing the app for different devices, ensuring it is equally functional and responsive on tablets, phones, and computers.

Accomplishments that we're proud of

We are particularly proud of the app's ability to provide real-time, personalized advice to parents, which has the potential to significantly ease the stress of caregiving. The integration of AI for behavior analysis and the secure handling of sensitive medical records are key accomplishments. Additionally, creating an intuitive user interface that parents can navigate easily during stressful times stands out as a major achievement.

What we learned

Throughout the development of Happy Tracker, we gained deeper insights into the complexities of caregiving for children with disabilities. We learned about the importance of privacy and security in handling medical data. Technically, we advanced our skills in AI integration, data security, and cross-platform app development. We also learned the value of user feedback in refining our application to better meet the needs of our target audience.

What's next for Happy Tracker

Looking ahead, we plan to incorporate voice-command features to enhance accessibility further. We aim to expand our database to include more behavior patterns and coping strategies based on user feedback. Another goal is to partner with medical professionals and therapists to enrich the resources available to parents through the app. Additionally, we're considering expanding our service to include multilingual support, making it accessible to non-English speakers worldwide.
",https://hd-2024-ui.vercel.app/,,"Best Beginner Hack, Best Health Hack, 	Best Hack for Social Justice, Best AI/ML Hack, Best Overall Design, Best User Research","django, react, anthropic",Ernika,Rabiei,brabiei@ucdavis.edu,,Best Hack for Social Justice,Best Health Hack,Best Beginner Hack,University of California - Davis,3,Ken,Taniguchi,taniguchi.ryusei@gmail.com
MedCloud,131,https://hackdavis-2024.devpost.com/submissions/511475-medcloud,Submitted (Gallery/Visible),Pending,Submit,04/28/2024 16:25:55,"Inspiration

We aimed to create a medical database to enable healthcare professionals worldwide to access patient records quickly, thereby simplifying information processing time. Our goal is to develop an app that facilitates rapid diagnostics on-site for injuries, eliminating the need for patients to visit a hospital for diagnosis.

What it does

Our project compiles patient data from all across the country and combines them all into one central database. Through the power of machine learning, our application can predict potential diseases and other health risks that patients may have. 

How we built it

We found a database off of Kaggle, then used VSCode to train a model to predict potential diseases based off of patient data. We then used SQLite to create a database to contain all the information, and built a simple interface on Figma. 

Challenges we ran into

It took us a while to find suitable datasets that we could use to test our model, as a lot of them were incomplete or had strange inputs that wouldn't have been reliable to use. Another challenge was being able to train a model to reliably predict certain risks, as we didn't want our project to tell users that they had a serious health risk based on a small probability. 

Accomplishments that we're proud of

What we learned

What's next for MedCloud

We want to add more predictive models to make more diagnostic for other chronic diseases and make an app for all users.
",,,Best Beginner Hack,"python, vscode, figma",Kyle,Fong,khfong@ucdavis.edu,,Best Beginner Hack,Best AI/ML Hack,Best Statistical Model,University of California - Davis,1,jkwong12,,jdkkwong@ucdavis.edu
Aggie House Volunteers Timesheet - KARS,41,https://hackdavis-2024.devpost.com/submissions/511478-aggie-house-volunteers-timesheet-kars,Submitted (Gallery/Visible),Pending,Submit,04/28/2024 16:28:45,"Inspiration

The inspiration behind Aggie House Volunteers Timesheet - KARS stemmed from the desire to streamline and enhance the volunteer experience at Aggie House. Recognizing the importance of efficient time management and effective communication in volunteer organizations, we set out to create a comprehensive solution that would benefit both volunteers and administrators alike.

What it does

Aggie House Volunteers Timesheet - KARS is a sophisticated platform that revolutionizes volunteer management. For volunteers, it offers seamless event sign-ups, personalized profiles, and real-time updates on upcoming shifts. Administrators, on the other hand, gain access to intuitive event management tools, robust analytics, and streamlined communication channels.

One of the standout features of Aggie House Volunteers Timesheet - KARS is its synchronized calendars for both admins and volunteers. This ensures that everyone is on the same page regarding event schedules and availability. Additionally, the platform includes a leaderboard to recognize top volunteers, a management system for time slots, a resource page for important documents and guidelines, and much more. Along with that, only volunteers and admins will have access to this application using PropelAuth with Google Authentication, providing a peace of mind and convenience.

How we built it

Aggie House Volunteers Timesheet - KARS was built using cutting-edge technologies and best practices in web development. We leveraged React.js for the frontend to create a smooth and responsive user interface. The backend was built using Node.js and Express.js, with MongoDB serving as the database to store time slot and user information. PropelAuth was integrated to handle user authentication and authorization.

We utilized DevExtreme React components for the calendar functionalities, ensuring a seamless experience for both admins and volunteers. The emailing system was implemented to send notifications to users a day and week before their scheduled shifts, enhancing communication and reducing no-shows.

Challenges we ran into

Building Aggie House Volunteers Timesheet - KARS presented several challenges, including integrating the synchronized calendar feature, ensuring data consistency between the frontend and backend, and implementing logic to limit sign-ups for available time slots to only two volunteers. Additionally, fine-tuning the emailing system to deliver timely notifications posed its own set of challenges.

Accomplishments that we're proud of

Despite the challenges, we're proud to have developed a comprehensive and user-friendly platform that addresses the unique needs of volunteers and administrators at Aggie House. The synchronized calendars, intuitive management tools, and seamless integration with PropelAuth are accomplishments that we take pride in.

What we learned

Throughout the development process, we gained valuable insights into frontend and backend integration, user authentication, and email notification systems. We also honed our skills in React.js, Node.js, and MongoDB, further expanding our technical expertise.

What's next for Aggie House Volunteers Timesheet - KARS

Looking ahead, we have exciting plans to further enhance Aggie House Volunteers Timesheet - KARS. Our future roadmap includes making every page editable for administrators, improving the design to enhance UI/UX, and incorporating any new features or functionalities that Aggie House requires. We are committed to continuously improving and evolving the platform to meet the evolving needs of the volunteer community.
","https://github.com/RyanNg20/aggie-house-frontend, https://github.com/kellyhp/aggie-house-backend, https://www.figma.com/file/BjlTvlhx6TKnTAqSXeCccn/HD24-AggieHouseVolunteers?type=design&node-id=151%3A5835&mode=design&t=BagZsbAi0rHDfqqV-1, https://www.figma.com/proto/BjlTvlhx6TKnTAqSXeCccn/HD24-AggieHouseVolunteers?page-id=10%3A92&type=design&node-id=151-5801&viewport=880%2C-536%2C0.07&t=UzVbNdNDvsRqdZEL-1&scaling=min-zoom&starting-point-node-id=151%3A5801&mode=design",https://youtu.be/HgF2lo-Kg9A,"Best UI/UX Prototyping, Best User Research, Best Use of PropelAuth, Best Hack for AggieHouse","figma, propelauth, javascript, react, node.js, mongodb, nextjs, tailwindcss, express.js",Kelly,Phan,kellyphan159@gmail.com,,Best User Research,Best Hack for AggieHouse,Best UI/UX Prototyping,University of California - Davis,3,Ryan,Ropher,ropher20@gmail.com
SafeSwan,25,https://hackdavis-2024.devpost.com/submissions/511481-safeswan,Submitted (Gallery/Visible),Pending,Submit,04/28/2024 16:29:43,"SafeSwan ü¶¢

Inspiration üåü

The idea behind SafeSwan was heavily influenced by our desire to create an informative website for people to feel secure in their daily lives. By providing a dedicated platform to inform people about the crimes in places they wanted to visit we aim to help people in how to prepare if they wanted to visit a certain city. 

What it does üìä

The key features in our website are: pie chart showing ratio of crimes and type of crimes in a certain city, ranking out of five to show how safe a city is, displaying resources and non profit organizations for those who are victims or for those who want to help prevent crimes, as well as an AI-integrated chat bot, Sage, for users to ask questions about safety tips, cities, or anything else. 

Built with üõ†

Design üé®


Figma


Languages üë©üèΩ‚Äçüíª


Python
React
TypeScript
HTML/CSS
Tailwind CSS


APIs ü§ñ 


OpenAI

",https://github.com/peeoke/SafeSwan/blob/master/README.md,,"Best Beginner Hack, Best Overall Design, Best Interactive Media Hack","figma, python, react, typescript, html/css, tailwindcss, openai",Harsita,Keerthi,harsita.keerthikanth@gmail.com,,Best Beginner Hack,Best Interactive Media Hack,Best Overall Design,San Jose State University,3,Ysabella,Dela Cruz,ysabelladelacruz2022@gmail.com
Untitled,,,Draft,Pending,Manage team,04/28/2024 16:30:42,,,,,,anng-y,Yip,anngyip59@gmail.com,,,,Best MedTech Hack,University of California - Davis,0,,,
HackDavis DCMH,5,https://hackdavis-2024.devpost.com/submissions/511483-hackdavis-dcmh,Submitted (Gallery/Visible),Pending,Submit,04/28/2024 16:31:28,"Inspiration

The DCMH website leverages a competitive analysis of Elfster, a popular gift exchange app, to inform strategies for encouraging support for wish lists and donations. By studying successful features and engagement tactics employed by Elfster, the DCMH website aims to replicate and adapt these strategies to foster greater community involvement and generosity towards fulfilling the organization's mission.

What it does

The redesign of the DCMH (Donation Community for Mental Health) website aimed at maximizing user accessibility, engagement, and impact. A deliberate choice was made to develop a website rather than an app, considering the realistic user behavior of reluctance to download an app solely for donating. Additionally, a website offers greater intuitiveness and security for donation transactions.

How we built it

We used Supabase as the database to hold the all of the inventory data and react as the main framework.

Challenges we ran into

We struggled to complete the front-end in time and in general, combining all the components in 24 hours. Developer and designers also took a lot of time to discuss and reiterate for the final project.

Accomplishments that we're proud of

As the 2nd HackDavis and 1st HackDavis for half of the members, we are proud of our progress in this project. 

What we learned

We learned more about teamwork and more about our own respective abilities.
","https://github.com/jack00z/HackDavis2024, https://www.figma.com/file/jwDyMIb1kSPh9Q5tpcrqU2/HackDavis-Master-File?type=design&node-id=158-1722&mode=design&t=Syu6LwvDBVGHv2s0-0",,"Best Interdisciplinary Hack, Best UI/UX Prototyping, Best Overall Design, Best User Research, Best Interactive Media Hack, Best Hack for DCMH","react, css, figma, supabase, javascript",Jack,Zheng,jackzheng274@gmail.com,,Best Hack for DCMH,Best Interdisciplinary Hack,Best UI/UX Prototyping,University of California - Davis,3,Nanette,Ta,nuta@ucdavis.edu
test,,,Draft,Pending,Additional info,04/28/2024 16:31:51,,http://google.com,,,test,HackDavis,Team,hello@hackdavis.io,,Best Use of PropelAuth,Best Use of PropelAuth,Best Beginner Hack,,0,,,
PlayerProps,50,https://hackdavis-2024.devpost.com/submissions/511486-playerprops,Submitted (Gallery/Visible),Pending,Submit,04/28/2024 16:32:25,"This project was created for the 2024 HackDavis competition and this web application intends to give insight on the game of basketball and analyze in depth, the significance of scoring and how scoring is measured in the NBA. Through looking at different stats within the game of basketball, we figured out a way to predict a player's points based on the previous few seasons as well as thier playoff performance

Analyzing NBA statistics to predict future points per game for players can have positive social impacts in several ways:

By understanding which statistics correlate with higher points per game (PPG), teams can tailor their training programs and strategies to enhance player performance. Coaches can identify areas for improvement, such as shooting accuracy, assists, or free throw percentage, leading to better player development. Teams can make informed decisions during drafts, trades, and contract negotiations. Predictive models help teams assess a player's potential impact on PPG, aiding fair compensation and team-building decisions. Futhermore, Accurate predictions enhance fan engagement by creating excitement around player performances. Finally, Fans enjoy discussing stats, predictions, and fantasy leagues, contributing to the overall enjoyment of the sport.
",https://github.com/ChiefGuap/PlayerProps,,,"python, flask, html, css, scikit-learn, numpy, pandas, matplotlib",Raquib,Alam,raquib.alam2023@gmail.com,,Best Beginner Hack,Best Statistical Model,Best Hack for Social Justice,"University of California - Davis, UC Davis",3,Armin,Irvije,armin.v2001@outlook.com
Vivek's Very Cool Project,,,Draft,Pending,Additional info,04/28/2024 16:32:55,"Inspiration

cool

What it does

How we built it

Challenges we ran into

none

Accomplishments that we're proud of

everything

What we learned

What's next for Vivek's Very Cool Project

being even more cool
",http://hackdavis.io,,"Best Beginner Hack, Best Health Hack, 	Best Hack for Social Justice, Most Technically Challenging Hack, Best Overall Design, Best DEI Hack Sponsored by Fidelity, Best Hardware Hack",idk,Vivek,Shome,vivek@hackdavis.io,,Best Hardware Hack,Best Interdisciplinary Hack,Best Beginner Hack,,0,,,
Welcome to Davis!,13,https://hackdavis-2024.devpost.com/submissions/511489-welcome-to-davis,Submitted (Gallery/Visible),Pending,Submit,04/28/2024 16:33:39,"Inspiration

As newly admitted students tour the campus in spring, we were reminded of our anxieties and uncertainty when we were in their position. We wanted to make an interactive horror game touring the campus to symbolize the fears of new students coming to an entirely new area and living a new way of life. We hope that this game can help new students process their fears in a fun and thrilling manner as well as remind current students and alumni of the challenges current new students face. We hope you enjoy our game!

Make sure you download both .exe files!
",https://drive.google.com/drive/folders/15Sgj8x4mCzah2ODsUiJmaX3VY0_hDMMc?usp=sharing,,"Best Beginner Hack, Most Creative Hack, Best Overall Design, Best Interactive Media Hack","unity, c#",Aidan,Chiang,atchiang@ucdavis.edu,,Best Interactive Media Hack,Best Beginner Hack,Most Creative Hack,University of California - Davis,1,Andrew,Lov,aklov@ucdavis.edu
Untitled,,,Draft,Pending,Manage team,04/28/2024 16:33:44,,,,,,flash,Gobaco,audrey@gobaco.com,,,,Best Hardware Hack,,0,,,
CodeForces Guru,60,https://hackdavis-2024.devpost.com/submissions/511492-codeforces-guru,Submitted (Gallery/Visible),Pending,Submit,04/28/2024 16:35:41,"Inspiration

Desire for a service to provide CodeForces functionality such as recommendations, duels, daily problems (and campaigns, more gameification to follow in LeetCode's footsteps), and a better search engine for finding problems with a certain name

What it does


Recommend problems based on a user's submission history, or topic tags and ratings
Initiate duels with other users on Discord
Primitive search engine for finding problems based on their name/title
Offer problem sets (campaigns) of problems within the same tag


Challenges we ran into


CodeForces API being a problem (working with limited set of methods)
Creating and hosting an API for the website


Accomplishments that we're proud of

First-time working with external API's as beginners, successfully set up website and Discord bot

What we learned

CodeForces API, Discord API, Flask, SQL, PropelAuth, JSON, Python, JS, CSS

What's next for CodeForces Guru

Offering functionality for LeetCode, HackerRank, Kattis, and other platforms
","https://github.com/nindroid945/cfrec/tree/main, https://discord.gg/vdhaQGrv",,"Best Beginner Hack, Most Technically Challenging Hack, Best Use of PropelAuth","python, javascript, flask, html, css, codeforces, discord",Audrey,Gobaco,acgobaco@ucdavis.edu,,Best Beginner Hack,Best Use of PropelAuth,Most Technically Challenging Hack,"University of California - Davis, University of California - Santa Cruz",3,Evan,Liang,evan.liang@gmail.com
F&R Cycle,137,https://hackdavis-2024.devpost.com/submissions/511493-f-r-cycle,Submitted (Gallery/Visible),Pending,Submit,04/28/2024 16:35:57,"Inspiration

The inspiration behind our app is the wasteful of restaurants and storefronts and helping individuals in need of a free meal. From working in the restaurant industry we can see the food going to waste that could be donated and help provide a meal or recyclables an individual can use for money. 

What it does

Our app allows businesses to register and put that they have a select number of food available that any individual can come and pick up the food. The food will be the left over food or food that was going to be thrown away. We also have another section where the business can list their recyclables so an individual can come and pick up their recyclables for them to recycle. For an incentive for the businesses we plan to keep track of the information and the estimated price of the items the business so that they can use it for a tax write off, while also providing money and food for those in need.

How we built it

We were designing our app on figma. After we starting developing it using react native and on visual studio code. We also used expo to run and simulate on our phones what are app currently looks like.

Challenges we ran into

Setting the environment, it was very time consuming. The formatting and trying to create a responsive mobile app.  

Accomplishments that we're proud of

Implemented the maps API to visualize the map, also just setting up the app in general and all the pages. It was all our first times. 

What we learned

How to use react native and develop a mobile app. Learning how to design a app on figma. We utilized our programming skills to help society. 

What's next for F&R Cycle

To actually implement it, having a fully functioning app. Explore the possibilities and get actual businesses and those in need. We also want to create a profile for volunteers where they can get volunteering hours for either their school or just for good Samaritans. 
",https://github.com/Yowzel/RecycleApp,,"Best Beginner Hack, Most Creative Hack, Best Hack for DCMH, Best Hack for AggieHouse","react, react-native, javascript, visual-studio, figma, expo.io, google-maps",Chiu-Ssu,Hsieh,chiussu.hsieh@gmail.com,,Best Hack for DCMH,Best Beginner Hack,Most Creative Hack,"Northeastern University, California Polytechnic State University-San Luis Obispo",1,Edson,Munoz,emunoz23@calpoly.edu
Tumor radar,163,https://hackdavis-2024.devpost.com/submissions/511494-tumor-radar,Submitted (Gallery/Visible),Pending,Submit,04/28/2024 16:36:25,"Inspiration

Cancer is one of the biggest leading causes of deaths in the world nowadays. Early detection of tumors is very crucial to save the patients. However many times tumors are detected in the very last stages which is a big problem. Manual interpretation of medical images such as x rays can lead to many human errors. Identifying these small signs is often impossible.

What it does

TumoRadar is an innovative tool that we have developed which is in its early stages as of now. TumoRadar uses the power of machine learning and makes cancer detection way more efficient. TumoRadar addresses these challenges by analyzing X Rays and providing medical officials with actionables insights about the X Ray.

How we built it

We built this project using R studio

Challenges we ran into

As bio majors none of us are too fluent in programming hence this event was a massive challenge for us

Accomplishments that we're proud of

I am just happy we got a project done as this is not a event I was too hopeful for

What we learned

We learnt how image detection is a rather difficult task and overall we just learnt how to code

What's next for Tumor radar

We are gonna work on a front end to make this program more user friendly
",https://drive.google.com/file/d/1QbyxWK7PwnF9fEQaaJyQwHAXo91Gd2ys/view?usp=share_link,,"Best Beginner Hack, Best Health Hack, Most Creative Hack, Best AI/ML Hack, Best User Research",r,Kushal,Cholasamudram,kcholasam@ucdavis.edu,,Best Health Hack,Best Beginner Hack,Most Creative Hack,University of California - Davis,1,Maanit Himanshu,Shah,mshah@ucdavis.edu
Slate,127,https://hackdavis-2024.devpost.com/submissions/511495-slate,Submitted (Gallery/Visible),Pending,Submit,04/28/2024 16:36:56,"Inspiration

We were inspired to create Slate by the need for a centralized platform where students could collaborate, share notes, and access study materials effortlessly.

What it does

Slate simplifies studying by facilitating collaboration, providing personalized recommendations, and fostering community engagement among students.

How we built it

Using Next.js for the frontend with Firebase for the backend, we crafted Slate's infrastructure. A fine tuned model based off of Gemini powers the personalized recommendations for study materials.

Challenges we ran into

Integrating AI seamlessly, optimizing performance, and ensuring a user-friendly experience in such a short time.

Accomplishments that we're proud of

We're proud of creating a platform that addresses a genuine need in education and the collaborative effort that brought Slate to life, with most of the important workflows fully functional.

What we learned

Developing Slate taught us valuable lessons in teamwork, problem-solving, and user-centric product development.

What's next for Slate

We plan to enhance collaboration features, refine AI algorithms, and fully complete the website to be ready for use by students and instructors.
",https://github.com/varun22/HD-2024,,"Best Beginner Hack, Best AI/ML Hack, Best UI/UX Prototyping, Best Overall Design","next.js, gemini, firebase, tailwind, typescript",varun22,Thakkar,varunthakkar31@gmail.com,,Best AI/ML Hack,Best UI/UX Prototyping,Best Beginner Hack,University of California - Davis,3,Namra,Shah,nmrshah@ucdavis.edu
Redu,61,https://hackdavis-2024.devpost.com/submissions/511497-redu,Submitted (Gallery/Visible),Pending,Submit,04/28/2024 16:38:03,"Inspiration

A huge barrier to entry for underrepresented communities and active learners is the inaccessibility of finding key information from textbooks and large amount of text. Even if textbooks are open to the public, which many are not, users cannot find the information they are looking for. 

If users can access textbook information in constant time, it will allow for democratization of information - allowing under represented groups to learn, students to learn from beginner to expert research papers, and continuous learners to continue growing. 

What it does

We are aiming to redefine education by allowing users to ask our bot a question, and we will pull up the exact sentence from a textbook with the answer. After, you can interact with our bot to ask more questions about the text - trained exactly on that data. If the chatbot cannot answer the question, our discussion form will allow experts and beginners to communicate by selected topic. Finally, the platform will work in multiple languages. 

How we built it

We used React to build our front end and we hosted our model using amazons s3 instance for Flask. To implement the semantic search on the textbooks, we used np net transformer model from hugging face, which we fine-tuned it to embed it in our application and ensure accurate. Afterwards, we enlarged the search queries using the open-ai api. Additionally, the chatbot used open ai api, and on the enlarged search queries, we ran the nearest neighbor algorithm.Finally, the user database is personal database we made it from scratch on top of sql and JWT tokens were used for all user and database auth. The discussion section was done in is react js, with no external libraries, all from scractch. 

Challenges we ran into

Our server was giving a CORS error as the server was not secure so it cannot access the port. We opened the port with jwt tokens to fix this. 

Accomplishments that we're proud of

Being the worlds first semantic search for textbooks using inferance is something our team is really proud of! Finetuning our model on textbooks and having it pull up the exact sentence will revolutionize education. 

What we learned

We learned how to finetune an embedding model for textbook semantic search, and pull up the exact sentence. Additionally we are proud of being able to provide quick inference of the material and hollistic learning.

What's next for Redu

We would like to implement multiple languages and improve on the amount of textbooks and information offered. Continue to improve the UI/UX. 
","https://github.com/Shaurya-Srivastav/REDU, https://github.com/Shaurya-Srivastav/Redu-Backend-Code",,"Most Creative Hack, Best AI/ML Hack, Best use of Intel¬Æ Developer Cloud, Most Technically Challenging Hack","react, python, sql, json, huggingface, accelerate, youtube, open-ai",Shaurya,Srivastav,ssrivastav@ucdavis.edu,,Most Technically Challenging Hack,Best AI/ML Hack,Most Creative Hack,University of California - Davis,3,Aditya,Singh,adi22113@gmail.com
aiDent,37,https://hackdavis-2024.devpost.com/submissions/511498-aident,Submitted (Gallery/Visible),Pending,Submit,04/28/2024 16:38:30,"Inspiration

The foundations for building an application that detects misdiagnosis in the orthodontal industry came when one of our teammates (who had a prior experience in the industry) noticed that dental industry although being huge, was heavily saturated which kept the door shut for the use of modern tools (AI and image detection). During modern times, every industry across the world is benefitting by the use of AI. The dental industry being the biggest healthcare industries suffers heavily due to the lack of new models and resources which in turn affects the insurance providers, patients and the dentist. According to National Library of Medicine, general dentist misdiagnosed 45.9% of the patients during research. Additionally, according to ADA Member Advantage, a person from the age segment of 20-70 spends minimum $51,000 in their life; if 45.9% of the detected diseases are misdiagnosed an average person spends $23409 dollars in their lifetime in waste. This expense is indirectly paid by the insurance companies for the treatment, which creates a huge waste of patient‚Äôs time resources and insurance‚Äôs along with customer‚Äôs billions of dollars in vain.
This number being huge heavily motivated us to develop a solution which could lower the misdiagnosis caused as these misdiagnoses induces a mental instability in patients. Getting into a greater depth regarding misdiagnosis helped us realize that root canal along with some other diseases was one of the most operated procedures in the world, with about 15 million people getting the treatment every year in the United States. Viewing the gravity of the situation, deeply inspired us to break this stigma and give the patients as well as the dentist a good experience while their dental treatments.

What does it do?

aiDent is a personalized orthodontist which prevents misdiagnosis in the dental industry by leveraging the use of advanced machine learning models for detecting various diseases using X-Ray images. Our web app is user and business focused application which uses a simple easy to use API and breaks down the image into its individual diseases by individual tooth.
Running advanced machine learning algorithms in the backend helps us ensure that the product is scalable over time. When a customer visits a dental clinic and their orthodontist defect‚Äôs a disease during their appointment; they click and X-RAY to ensure that the teeth is infected usually by themselves or by private players. After receiving an X-RAY, the user can visit our website and make an account. The online X-RAY images could be later be uploaded into the model and the backend machine learning algorithm and extract an image that can detect specific diseases into specific teeth on the X-RAY.
If there is a misdiagnose present, our model will help the patient recognize that there is a disease present on a specific tooth in the X-RAY. After knowing about the exact cause, they can communicate effectively to their orthodontist and figure out their exact cause. This helps the insurance agency‚Äôs as they do not have to spend money on misdiagnose treatment which enables them to save their money and resources effectively. Furthermore, the patents do not have to go through the pain and the mental trauma of going through a misdiagnose surgery.

Tools involved in building it

We used YoloV8 and YoloV6 pretrained models to train our machine learning models in google collab and using basic open cv framework in Jupiter notebook. In additionally, for frontend we used React.js framework for designing and TailWindCSS for integration. Backend we used Flask and TailWindCSS.

Accomplishments that we're proud of

aiDent has the power and potential to revolutionize the dental industry owing to it‚Äôs clean and scalable machine learning algorithms and easy to use friendly UI for the user. Thousands of people all across United States and numerous people around the world struggle because of misdiagnosis every single day. Misdiagnosis not only creates a physical threat on a both but also create a negative impact on the patient‚Äôs mind regarding treatments due to their prior experiences. If a patient gets treated on a misdiagnosis, the amount of mental trauma on the patient after the medical procedure is unbelievable. Our product can solve this issue completely and give the patient the adequate treatment that they deserve and prevent the mental trauma altogether.‚Äô
Our product will also prove to be a huge boom for the insurance industries as they could use it as an verification model. Additionally, if we collaborate with the insurance companies; we would be able to collect additional data set and further increase the precision and accuracy of our models. This could prevent important resources like money and man power to significantly reduce and ensure that people get the right treatment for their disease. 
In addition, creating this idea within 24 hours in a hackathon was a dream come true for us. After working continuously throughout the entire duration of the hackathon nonstop and not regretting a part of it portrays our pride and passion towards building it. Our mentors really helped us integrate all of our model along the way and we really appreciate the help and valuable advice that they gave us which resulted into such a cutting-edge software with a strong UI foundation. 

Challenges we ran into

A major challenge that we ran into was collecting data for training our Machine Learning models and integrating our machine learning algorithms, backend architecture and frontend interface. While searching for data on the internet, we faced a challenge of collecting reliable and well formatted data as our classification machine learning model dependent highly on the data used. Additionally, due to privacy reasons medical colleges and clinics could not share us the datasets to us and were very supportive about the mission although did not have the permission to share the data outside their organizations. 

Secondly, after creating and heavily testing our machine learning models, back-end framework and fronted interface; we struggled to integrate them together in order to create a complete web app. After talking and gaining valuable advice from our mentors, we finally figured out an API‚Äôs which enabled us to integrate all the individual parts together into one tight knit environment.

Thirdly, we have a couple of cases where our machine learning model is unable to classify the images; though very less amount of time, it is caused due to limited data and lack of advanced filtering system (which is very difficult to implement in 24 hours). We can fix this using advanced classification on our data set, getting additional data set and further enhance the accuracy of the model.

Future Plans

After attending this hackathon, every one of us has understood of launching and deploying this software in the industry as it could benefit millions of people around the world and could help them prevent misdiagnosis which creates a metal instability, severe trauma and phobia of getting treatment caused due to their negative experience; on the other hand it could help dentists to ensure that their patients are getting the right treatment, avoid potential lawsuits and give their end customers (patients) a very fluid experience throughout their treatment. This creates a win-win situation for both the doctors and their patients. 
We strongly think that this has a wide application in the insurance space as they are paying billions of dollars every year for their clients respective treatments. If I algorithm ideally works, the insurance companies can save up to 45.9% of its total money and resources spent which can furthermore help them control their cost and ensure that their clients are getting the right treatment necessary. Additionally, we could provide insurance companies with a verification modular system which requires to run the patients X-Rays using our application. This will not only help the insurance companies save their valuable finance but will also help us collaborate with the companies to extract additional data set from them to train and increase accuracy of our model.
In future, we would like to collaborate with a dental organization which could provide us additional and reliable data set helping us scale our product and increasing the reliability and usability. Additionally, we would be able to further collect additionally data set from our users which we could use to further enhance our neural nets and create a scalable product. We strongly think that people all across the world are in need for our product and we strongly want to help them prevent misdiagnosis and leave millions of people with a smiling face!
","https://github.com/arnavakula/ai-dent, https://github.com/SujashB/aiDent-front",https://youtu.be/68yhc_thOGM,"Best Health Hack, Most Creative Hack, Best AI/ML Hack, Most Technically Challenging Hack, Best Overall Design","flask, python, yolo, machine-learning, ai, googlecollab, jupiter, mernstack",Dev,Rathod,dev-rathod@hotmail.com,,Best Health Hack,Most Technically Challenging Hack,Most Creative Hack,University of California - Davis,4,Sujash,Barman,barmansujash4@gmail.com
Untitled,,,Draft,Pending,Manage team,04/28/2024 16:39:16,,,,,,WhenPterodactylsAttack,Yue,mrmeepers322@gmail.com,,,,Most Technically Challenging Hack,UC Davis,0,,,
US Stocks Search-Engine,47,https://hackdavis-2024.devpost.com/submissions/511500-us-stocks-search-engine,Submitted (Gallery/Visible),Pending,Submit,04/28/2024 16:39:22,"Inspiration

One of our team members is a Business major. The other team member is currently working in the finance sector. Together, we thought we would do something relating to finance

What it does

This web-based app allows you to search for any US stocks. It shows relevant data regarding the stock on a daily timeframe.

How we built it

Challenges we ran into

Accomplishments that we're proud of

What we learned

What's next for US Stocks Search-Engine
",,,"Best Beginner Hack, Best Interdisciplinary Hack, Best Finance & Tech","html, python, css, javascript, ajas",ChlioP,Pham,chliopham@gmail.com,,Best Beginner Hack,Best Finance & Tech,Best Interdisciplinary Hack,"California State University - East Bay, Mission College, De Anza College",2,Jade,Nguyen,bnnguyen0912@gmail.com
Fetch Finder,119,https://hackdavis-2024.devpost.com/submissions/511501-fetch-finder,Submitted (Gallery/Visible),Pending,Submit,04/28/2024 16:39:23,"Inspiration

The inspiration for Fetch Finder came from the desire to leverage technology to help reunite lost pets with their owners efficiently and effectively.

What it does

Fetch Finder allows users to upload images of lost pets or report unidentified pets. Using AI, the platform helps identify pets and connect them with their owners or find them new homes.

How we built it

etch Finder was built using a combination of web development technologies, AI algorithms for image recognition, and database management systems. Front-end technologies like HTML, CSS, and JavaScript were used for the user interface, while Python and frameworks like Flask were used for the back-end development. AI algorithms for image recognition were integrated to help identify lost pets.

Challenges we ran into

Some of the challenges encountered during the development of Fetch Finder included integrating AI algorithms effectively, managing large amounts of user-generated data securely, and ensuring seamless communication between the front-end and back-end components of the platform.

Accomplishments that we are proud of

We are proud of implementing the AI algorithms for pet identification, creating a user-friendly interface for easy interaction, and ensuring the platform's reliability and scalability.

What we learned

Through building Fetch Finder, we gained valuable experience in AI integration, web development, database management, and project management. I also learned the importance of user feedback and iteration in improving the platform continuously.

What's next for Fetch Finder

In the future, Fetch Finder aims to expand its features to include more advanced pet identification algorithms, enhanced community engagement features, and partnerships with animal shelters and rescue organizations. Additionally, ongoing updates and improvements will be made based on user feedback to ensure Fetch Finder remains a valuable resource for pet owners and animal lovers alike.
",https://github.com/Fatimah520/davis_hackathon_2024.git,,"Most Creative Hack, Best UI/UX Prototyping, Best Hack for Life of Kai","sql, python, javascript, html5, css3, flask",Fatimah,Abdolcader,fatimah.abdolcader@gmail.com,,Best Hack for Life of Kai,Best UI/UX Prototyping,Most Creative Hack,San Francisco State University,0,,,
Vision AI,48,https://hackdavis-2024.devpost.com/submissions/511502-vision-ai,Submitted (Gallery/Visible),Pending,Submit,04/28/2024 16:39:26,"Inspiration

social community

What it does

Our app aids visually impaired shoppers by providing real-time audio descriptions of scanned products, promoting independence and inclusivity.

How we built it

using machine learning or trained YOLOv8 model and streamlit 

Challenges we ran into

time limit and shortage of the datasets 

Accomplishments that we're proud of

we are able to tackle most of the challenges with in the given time.

What we learned

image processing using deep learning model.

What's next for Vision AI


Continuous prediction with video input is a possibility, offering advantages over analyzing individual image frames.
The integration of this application into mobile devices could enhance user experience and accessibility.
Currently, our model is tailored to specific products, but we aim to expand its capabilities by training it with a broader range of classes in the future.

",https://github.com/SudarshanC00/VisionAI-HackDavis,,"Best Beginner Hack, Best Interdisciplinary Hack, Best Health Hack, 	Best Hack for Social Justice, Most Creative Hack, Best AI/ML Hack, Most Technically Challenging Hack, Best User Research",python,Sudarshan,Chikkathimmaiah,sudarshan.c1326@gmail.com,,Best Beginner Hack,Best Hack for Social Justice,Best Interdisciplinary Hack,San Jose State University,2,Prithvi,Elancherran,prithvi.elancherran@sjsu.edu
MoodMonitor,145,https://hackdavis-2024.devpost.com/submissions/511503-moodmonitor,Submitted (Gallery/Visible),Pending,Submit,04/28/2024 16:41:21,"Inspiration

The inspiration behind MoodMonitor stemmed from the recognition of the immense stress and pressure faced by students during midterm season. We wanted to create a solution that could empower individuals to better understand and manage their emotions, ultimately promoting mental well-being and resilience.

What it does

MoodMonitor utilizes facial recognition technology to analyze users' facial expressions and determine their current emotional state. Based on the detected emotion, the app provides personalized support and resources to help users navigate through challenging times.

How we built it

We built MoodMonitor using Flutter for the front-end development and integrated camera functionality for facial recognition. The back-end processing was implemented using Python libraries for facial recognition and emotion detection.

Challenges we ran into

One of the main challenges we encountered was optimizing the performance of the facial recognition algorithm to ensure real-time processing without compromising accuracy. Additionally, integrating the front-end and back-end components posed some technical hurdles that we had to overcome.

Accomplishments that we're proud of

We're proud to have developed a functional prototype of MoodMonitor within the timeframe of the hackathon. Seeing the app accurately detect and respond to users' emotions was a significant accomplishment for our team.

What we learned

Through the development of MoodMonitor, we gained valuable insights into facial recognition technology and its applications in mental health support. We also honed our skills in cross-platform app development and project management.

What's next for MoodMonitor

In the future, we envision expanding MoodMonitor to include additional features such as mood tracking, mindfulness exercises, and personalized mental health resources. We also plan to conduct further testing and refinement to enhance the accuracy and effectiveness of the emotion detection algorithm. Additionally, we aim to explore partnerships with mental health organizations to reach a wider audience and make a positive impact on student well-being.
",https://github.com/BoiPlex/HealthScan,,"Best Beginner Hack, Best Health Hack, Most Creative Hack, Best Interactive Media Hack",flutter,Sky,Zhao,skyzhao04@gmail.com,,Best Beginner Hack,Best Health Hack,Most Creative Hack,"UC Davis, University of California - Davis",2,WhenPterodactylsAttack,Yue,mrmeepers322@gmail.com
Relocate,94,https://hackdavis-2024.devpost.com/submissions/511505-relocate,Submitted (Gallery/Visible),Pending,Submit,04/28/2024 16:41:52,"Inspiration

Growing up in a low-income community, the homeless community was always large. Although homeless people won't cause any harm, they are always removed from public sidewalks, parks, or even abandoned buildings. I hope this app allows people to acknowledge their privilege and help the homeless community find a safe area to shelter.  

What it does

If someone wants a homeless encampment removed, they could go on this app to research where it is safe for the homeless and where the risk of removal is low. After they search their local area on this app they can call the police to move the homeless encampment to the new location since legal enforcement is required to offer a safe shelter for them. 

What's next for Relocate

I need to research where it is safe for homeless people to shelter and incorporate it into the app.
",https://www.figma.com/proto/9RffqDVxGEZOLH3tg1Bca4/hackdavis?type=design&node-id=2-2&t=MnchVrAzbJe80OGq-0&scaling=scale-down&page-id=0%3A1&starting-point-node-id=2%3A2&show-proto-sidebar=1,,,figma,Jenny,Nguyen,ljnguyen@ucdavis.edu,,Best UI/UX Prototyping,Best Overall Design,Best Interdisciplinary Hack,University of California - Davis,0,,,
Test,,,Draft,Pending,Project details,04/28/2024 16:42:36,"Inspiration

What it does

How we built itb;a
",,,,java,Fawziyah,A.,fawziyah.alebiosu@gmail.com,,,,Best Hardware Hack,,0,,,
MindScape,54,https://hackdavis-2024.devpost.com/submissions/511508-mindscape,Submitted (Gallery/Visible),Pending,Submit,04/28/2024 16:43:01,"Inspiration

Project: MindScape - Nurturing Mental Wellness for a Thriving Workforce

Inspiration:

The inspiration for MindScape stemmed from a collective recognition of the increasing significance of mental wellness in professional environments. We observed a growing awareness of mental health issues among employees and employers alike, acknowledging the profound impact these issues can have on productivity, job satisfaction, and overall organizational success. Witnessing this trend, we were inspired to develop a proactive solution that could address these challenges head-on, fostering a workplace culture that prioritizes mental well-being.

What We Learned:

Throughout the development of MindScape, our team gained invaluable insights into the complexities surrounding mental health in the workplace. We deepened our understanding of the multifaceted nature of mental wellness, exploring the interplay between individual experiences, organizational culture, and external stressors. Additionally, we learned about the power of real-time data analysis in providing actionable insights, enabling organizations to intervene promptly and effectively when necessary. From a technical standpoint, we expanded our expertise in machine learning, particularly in the fields of audio analysis and emotion recognition. Furthermore, we refined our skills in full-stack development, ensuring that our solution could seamlessly integrate into existing workplace systems while maintaining usability and scalability.

Building the Project:

MindScape was the culmination of a collaborative effort, bringing together individuals with diverse backgrounds and skill sets. We leveraged our collective expertise in machine learning, software development, and user experience design to create a comprehensive solution for mental wellness in the workplace. Central to our approach was the utilization of advanced machine learning techniques, including Convolutional Neural Network (CNN) and Long Short-Term Memory (LSTM) models, to analyze emotions from audio data. This allowed us to capture subtle nuances in speech patterns and intonation, providing a more nuanced understanding of employee well-being. Complementing our machine learning algorithms was a full-stack platform developed to streamline data collection, analysis, and visualization. By prioritizing user accessibility and data privacy, we ensured that MindScape could be seamlessly integrated into diverse workplace environments, empowering organizations to nurture a thriving workforce.

Challenges Faced:

The development of MindScape presented several challenges that we had to overcome along the way. One of the primary challenges was ensuring the accuracy and reliability of emotion analysis from audio data. This required extensive experimentation and iteration to fine-tune our machine learning models and address potential biases or inaccuracies. Additionally, integrating our solution into existing workplace systems while adhering to strict data privacy and security standards posed a significant challenge. We had to navigate complex regulatory frameworks and ensure robust encryption protocols to safeguard sensitive employee information. Furthermore, effectively communicating the value proposition of MindScape and overcoming potential skepticism or resistance from stakeholders required strategic communication and advocacy efforts.

Overall, the journey of building MindScape was marked by both challenges and triumphs, reinforcing our commitment to advancing mental wellness in the workplace.

What it does

How we built it

Challenges we ran into

Accomplishments that we're proud of

What we learned

What's next for MindScape
",https://github.com/Parag000/HackDavis2024-MindScape,,,"llms, fastapi, machine-learning, fullstack",Parag,Deshpande,itsmeparag14@gmail.com,,Best AI/ML Hack,Best Health Hack,Best Beginner Hack,San Jose State University,2,Karthik,Ganesh,karthikganesh710@gmail.com
RedBullPlane,1,https://hackdavis-2024.devpost.com/submissions/511509-redbullplane,Submitted (Gallery/Visible),Pending,Submit,04/28/2024 16:45:54,"Inspiration

Too much redbull

What it does

Flies around uncontrollably

How we built it

Hot glue, 3d printed props, speed controls, cardboard, zip ties, soldering, ESP32's, and loooots of redbull. Ground station was written in rust and operated by a Nintendo switch controller from best buy.  

Challenges we ran into


Not enough redbull (just kidding we had too much)
Too much redbull
Lost collet for the spindle. Resolved by soldering holes through our propellers and using set screws
Crummy radios 
Broken microcontrollers with apparent out-of-order execution leading to serial communication to radios. We isolated it deep inside library code, and will contribute a fix after the hackathon. Decided to port code to a new mcu platform


Accomplishments that we're proud of


See video


What we learned


Bring a 3d printer.
Stuff breaks, move on.
Iterate fast
Don't lost hope.


What's next for RedBullPlane

https://github.com/dgramop/hackdavis
",,,"Most Creative Hack, Most Technically Challenging Hack, Best Hardware Hack","3d-printed-props, speed-controls, cardboard, zip-ties, soldering, esp32's, rust, c++, redbull, pla, esp32, rfd900x",Dhruv,Gramopadhye,dgramopadhye@gmail.com,,Best Hardware Hack,Most Creative Hack,Most Technically Challenging Hack,"George Mason University, University of California - Davis",1,Nicholas,Martinez,nicholasmartinez372@gmail.com
airchat ripoff,146,https://hackdavis-2024.devpost.com/submissions/511511-airchat-ripoff,Submitted (Gallery/Visible),Pending,Submit,04/28/2024 16:46:00,"we use OpenAI's Whisper model for speech recognition and Twitter's API to post a tweet using only our voice!
",https://github.com/echo4eva/hackdavis24,,,"python, twitter, whisper",Jericho,Imperial,jeri.imperial@gmail.com,,Best Interactive Media Hack,Best AI/ML Hack,Best UI/UX Design,California State University - East Bay,1,David,Kim,dvkim@ucdavis.edu
MediB,79,https://hackdavis-2024.devpost.com/submissions/511514-medib,Submitted (Gallery/Visible),Pending,Submit,04/28/2024 16:48:21,"MediB

Inspiration
The healthcare industry has greatly benefited from recent advancements in artificial intelligence, particularly through the development of Large Language Models (LLMs). These models have improved communication between humans and machines, making interactions more seamless and effective. Our goal is to tailor these models specifically for healthcare to meet unique clinical needs and enhance the patient-physician relationship.
We are developing a robust LLM application that promotes better health management and adherence to medical guidance, minimizing miscommunication and improving self-care. This is particularly valuable in remote areas with limited medical facilities, where our application can bridge the gap by leveraging widespread internet access to bring healthcare closer to those in need.

What it does
MediB is an advanced healthcare consultation application that offers intelligent and convenient communication for patients with medical queries. With this app, users can interact with a machine much like they would with a doctor, sharing their concerns and seeking advice and suggestions. The app processes patient queries by gathering information such as age, previous medications, and current symptoms. It then identifies the potential medical condition affecting the patient and provides recommendations for home remedies or suggests a doctor or hospital visit. Additionally, MediBee tracks previous conversations to monitor symptom progression, which helps in identifying if the condition has evolved or led to other diseases.

How we built it
To develop this healthcare application, we began by researching clinical specifications to select an appropriate dataset. We used this dataset to extract features, such as symptoms and resolutions, from each entry. For storing the extracted vectors and weights, we utilized Pinecone. Next, we used the Streamlit framework to create a user interface. Through this interface, users can submit their queries, which are then matched with similar content stored in Pinecone. We combined this matched data with the user's query and forwarded it to ChatGPT via the OpenAI API.
The responses generated by ChatGPT are more refined and accurate compared to typical queries processed through the OpenAI API. This method of enhancing a large language model's output is known as Retrieval-Augmented Generation (RAG). Furthermore, we incorporated Langchain technology to link previous conversations, allowing for improved responses in future interactions.

Challenges we ran into
One of the challenges we faced was finding a dataset containing conversations between patients and doctors that included symptoms. Once we found this dataset, we extracted the symptoms and results from these conversations. It was even more challenging to match these extracted vectors with the patient queries from our interface and then combine them to send to OpenAI's ChatGPT. However, through diligent research and the use of reliable resources, we were able to successfully overcome these challenges and ultimately produce the results we wanted.

Accomplishments that we're proud of
While working on this project, we were able to complete our research, select the necessary components, design an efficient system to reduce delays in the recommendation process, and ultimately produce results that help people with limited access to healthcare services.

What we learned
During the 24-hour hackathon, we attended several workshops where we learned about various Large Language Models (LLMs) and their specific applications. This knowledge led us to discover Langchain, which we later implemented in our project. Langchain helps our system remember previous conversations and generate current responses by analyzing past queries and results. 

What's next for MediB
The next steps for MediB involve fine-tuning larger datasets to achieve even better results. We were previously limited by not having access to more powerful computational resources. Additionally, we plan to start accepting and analyzing images from patients, such as pictures of wounds and rashes, as well as medical reports like ECGs and X-rays. Furthermore, we aim to obtain the locations of patients and provide them with a list of nearby doctors or hospitals tailored to their specific medical needs. Finally, we are seeking medical accreditation and doctors‚Äô approval to ensure the application's safety and reliability for public use.
",https://github.com/srinivas1698/HackDavisSrcDeb_2024,,"Best Beginner Hack, Best Interdisciplinary Hack, Most Creative Hack, Best AI/ML Hack","users-can-interact-with-a-machine-much-like-they-would-with-a-doctor, sharing-their-concerns-and-seeking-advice-and-suggestions.-the-app-processes-patient-queries-by-gathering-information-such-as-age, previous-medications, and-current-symptoms.-it-then-identifies-the-potential-medical-condition-affecting-the-patient-and-provides-recommendations-for-home-remedies-or-suggests-a-doctor-or-hospital-visit.-additionally, medibee-tracks-previous-conversations-to-monitor-symptom-progression, python, pinecone, openai, gpt, stream-line, pytoch",Debasish,Panigrahi,debasish.panigrahi@sjsu.edu,,Best Interdisciplinary Hack,Best Beginner Hack,Most Creative Hack,,1,Srinivas Rao,Chavan,srinivasrao.chavan@sjsu.edu
Airline Ticket Reseller Website,91,https://hackdavis-2024.devpost.com/submissions/511515-airline-ticket-reseller-website,Submitted (Gallery/Visible),Pending,Submit,04/28/2024 16:49:39,"Inspiration: From story of CEO Kayak

What it does: Buy airline ticket

How we built it: We use Java in the backend, and Javascript in the frontend.

Challenges we ran into: Connect backend and frontend together by Spring boot.

Accomplishments that we're proud of: We know how to use the database in MySQL.

What we learned: MySQL.

What's next for Airline Ticket Reseller Website: We are still thinking about it.
",https://github.com/tannguyen072704/HackDavis-2024.git,,,"java, javascript, html, css",Tan,Nguyen,nguyennhattan2707@gmail.com,,Best Beginner Hack,Best Overall Design,Best Hack for NAMI Yolo,San Joaquin Delta College,2,terah,209,gang8055@gmail.com
Online gambling awareness,,,Draft,Pending,Additional info,04/28/2024 16:50:23,,,,,,Jack Yiu Lok,Xiang,jylxiang@ucdavis.edu,,Best Beginner Hack,Most Creative Hack,Best Statistical Model,University of California - Davis,0,,,
Calendote,,,Draft,Pending,Additional info,04/28/2024 16:51:17,"Inspiration

My teammate and I were inspired by the optimality of apps that students use, like google calendar, but recognized that there was a need to simplify the interface.

What it does

The app simply brings to view the events laid out for the day for the user. 

How we built it

We used an android studio skeleton and implemented CalendarContact api to interact with the device's native calendar app.

Challenges we ran into

Implementing the api was very difficult in Android Studio. 

Accomplishments that we're proud of

We tried to use a google api for goole calendar, but found it was not making an optimal interface with our code. We decided to stick to the native calendar api, and restarted out entire project, and still came up with a prototype.

What we learned

We learned a lot about app development, Android Studio, and API implementation. 

What's next for Calendote
",,,"Best Beginner Hack, Most Creative Hack","android, api",Yash,Pradhan,yspradhan@ucdavis.edu,,Best Beginner Hack,Best Interdisciplinary Hack,Most Creative Hack,"University of California - Davis, UC Davis",1,Ryan,Ffrench,rffrench@ucdavis.edu
MediB( A healthcare companion),142,https://hackdavis-2024.devpost.com/submissions/511520-medib-a-healthcare-companion,Submitted (Gallery/Visible),Pending,Submit,04/28/2024 16:53:36,"Inspiration

To help under priviledges people

What it does

healthcare chatbot

How we built it

using langchain, RAG, stream lit, pinecone, open ai api

Challenges we ran into

RAM and Memory

Accomplishments that we're proud of

Successfully deployed the app

What we learned

many new technologies

What's next for MediB( A healthcare companion)

more finetuning
",https://github.com/srinivas1698/HackDavisSrcDeb_2024,,Best Health Hack,python,Srinivas Rao,Chavan,srinivasrao.chavan@sjsu.edu,,Best AI/ML Hack,Best UI/UX Prototyping,Best Health Hack,,0,,,
Voguify,52,https://hackdavis-2024.devpost.com/submissions/511521-voguify,Submitted (Gallery/Visible),Pending,Submit,04/28/2024 16:53:48,"Voguify - Fashion Inventory Management App

Introduction

Voguify is a React Native-based fashion inventory management app designed to help users organize and track their clothing items, create outfits, and manage their fashion expenses. The app provides a seamless and intuitive user experience for fashion enthusiasts to streamline their wardrobe management.

Key Features


Clothing Inventory: Users can add, edit, and delete clothing items with details such as name, price, purchase date, and category.
Outfit Creation: Create and save outfits using items from your inventory, allowing for quick and easy outfit planning.
Expense Tracking: Track spending on clothing items to manage fashion budgets effectively.
Data Visualization: Visualize data trends such as spending patterns, most worn items, and outfit combinations.
User Profile: Personalize the app experience with user profiles and preferences.


Technologies Used


Frontend: React Native, Redux for state management, React Navigation for navigation between screens.
Backend: Firebase Firestore for real-time database storage and retrieval.
UI/UX Design: Custom styling using React Native components, Material-UI icons for visual elements.


Development Process

Our team followed an Agile development approach, focusing on iterative development cycles to deliver features incrementally. We conducted regular user testing and feedback sessions to refine the user interface and improve user experience continuously.

Future Enhancements


Social Sharing: Integration with social media platforms for sharing outfit ideas and fashion trends.
AI-Powered Recommendations: Implement machine learning algorithms to provide personalized clothing recommendations based on user preferences and past purchases.
Multi-Language Support: Expand the app's reach by adding support for multiple languages to cater to a global user base.


Conclusion

Voguify aims to revolutionize the way fashion enthusiasts manage their wardrobe, offering a comprehensive solution for inventory management, outfit planning, and expense tracking. With its user-friendly interface and robust features, Voguify empowers users to stay organized, stylish, and budget-conscious.
",https://github.com/GitYaw/Voguify-GDSC,,"Best Beginner Hack, Most Creative Hack, Best Overall Design","react-native, firebase",Yaw,Mireku,ymir8091@gmail.com,,Best Beginner Hack,Most Creative Hack,Best Overall Design,University of California - Davis,2,Sambhav,Agarwal,sambhavagarwal4@gmail.com
Accessify,,,Draft,Pending,Project overview,04/28/2024 16:58:18,,,,,,Hung-Ta,Chen,htcchen@ucdavis.edu,,,,Best UI/UX Design,University of California - Davis,0,,,
FluentDocs ,167,https://hackdavis-2024.devpost.com/submissions/512230-fluentdocs,Submitted (Gallery/Visible),Pending,Submit,04/30/2024 04:24:55,"Inspiration

Our entire team has immigrant parents, and have had experiences translating complicated documents for them. We decided to make an app that does the translation for them, whenever they need to.

What it does

It parses through uploaded papers, and then clearly answers any questions the user has regarding the PDF.

How we built it

We used flask for our backend server, React for the frontend, and Intel VM (XEON) to access the hardware to run our AI models.

Challenges we ran into

Fine-tuning the model was very difficult. On top of taking forever, after fine-tuning we noticed that a lot more work was to be done, which is difficult during a hackathon.

Accomplishments that we're proud of

We are proud of learning so much about fine-tuning models and integrating intel technologies into our project. We started this project knowing nothing about the two, but emerged fourth place for the intel award in a hackathon of 598 people.

What we learned


Integrating open-source AI models using Intel Technologies
Workflows for developing a full-stack app
Debugging techniques used by industry professionals


What's next

We hope to implement two big features next. These include the ability for text voiceovers, and the ability to translate between languages. Doing so further the demographic we are able to help, aligning ourselves with the HackDavis 2024 theme of social good.
",https://github.com/manik-sethi/FluentDocs,,,"css, flask, intel-developer-services-beta, intel-xeon, javascript, langchain, machine-learning, powershell, python, react, shell",Mario,Miranda,mmirand@ucdavis.edu,,Best use of Intel¬Æ Developer Cloud,Best AI/ML Hack,Best User Research,University of California - Davis,2,Manik,Sethi,sethi.manik03@gmail.com
